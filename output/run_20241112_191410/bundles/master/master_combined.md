# Bundle: master

## https://medium.com/gitconnected/what-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00

Title: What Is The Best Therapy For a Hallucinating AI Patient?

URL Source: https://medium.com/gitconnected/what-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00

Published Time: 2024-11-11T02:50:06.029Z

Markdown Content:
What Is The Best Therapy For a Hallucinating AI Patient? | by Salvatore Raieli | Nov, 2024 | Level Up Coding
===============
 

[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Facf0cb9b3e00&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---top_nav_layout_nav----------------------------------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[](https://medium.com/?source=---top_nav_layout_nav----------------------------------)

[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav-----------)

[](https://medium.com/search?source=---top_nav_layout_nav----------------------------------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

![Image 1](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)

Top highlight

Member-only story

|LLM|AI|HALLUCINATION|PROMPT ENGINEERING|BENCHMARK|
---------------------------------------------------

What Is The Best Therapy For a Hallucinating AI Patient?
========================================================

Exploring the Art and Science of Prompt Engineering to Cure LLM Hallucinations
------------------------------------------------------------------------------

[![Image 2: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:88:88/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=post_page---byline--acf0cb9b3e00--------------------------------)

[![Image 3: Level Up Coding](https://miro.medium.com/v2/resize:fill:48:48/1*5D9oYBd58pyjMkV_5-zXXQ.jpeg)](https://levelup.gitconnected.com/?source=post_page---byline--acf0cb9b3e00--------------------------------)

[Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page---byline--acf0cb9b3e00--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--byline--acf0cb9b3e00---------------------post_header-----------)

Published in

[Level Up Coding](https://levelup.gitconnected.com/?source=post_page---byline--acf0cb9b3e00--------------------------------)

·

10 min read

·

1 day ago

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Facf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---header_actions--acf0cb9b3e00---------------------clap_footer-----------)

631

16

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=---header_actions--acf0cb9b3e00---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Dacf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=---header_actions--acf0cb9b3e00---------------------post_audio_button-----------)

Share

![Image 4: Discover how Large Language Models (LLMs) handle language tasks and the methods to reduce AI inaccuracies known as hallucinations. This study evaluates different prompt engineering strategies, revealing that simpler techniques often outperform complex ones. It also explores how tool-calling agents, which augment LLMs with external tools, can increase hallucination rates, emphasizing the importance of balanced prompt design for optimal performance in NLP tasks.](https://miro.medium.com/v2/resize:fit:700/1*iozTEShq70i8p46b-BvjzQ.jpeg)

image generated by the author using AI

> Without execution, ‘vision’ is just another word for hallucination. — Mark V. Hurd
> 
> A hallucination is a fact, not an error; what is erroneous is a judgment based upon it. — Bertrand Russell

[Large language models (LLMs)](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=Large%20Language%20Models,-What%20is%20a) are ubiquitous today, especially because of their [ability to generate text](https://www.ibm.com/topics/large-language-models) and adapt to different tasks without being trained. In addition, there has been debate about their reasoning capabilities and being able to apply them to solving complex problems or making decisions. Despite what seems like a success story, LLMs are not without flaws and can sometimes generate inaccurate or misleading information, often referred to as [hallucinations](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20does%20it%20mean%20LLM%27s%20hallucination%3F). Hallucinations are dangerous because they can produce factual errors, bias, and misinformation. [Hallucinations](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20does%20it%20mean%20LLM%27s%20hallucination%3F) and lack of understanding can be a serious risk for sensitive applications (medical, financial, and so on).

Create an account to read the full story.


---------------------------------------------

The author made this story available to Medium members only.  
If you’re new to Medium, create a new account to read this story on us.

[Continue in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Facf0cb9b3e00&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=regwall&source=-----acf0cb9b3e00---------------------post_regwall-----------)

Or, continue in mobile web

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00%3Fsource%3D-----acf0cb9b3e00---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----acf0cb9b3e00---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00%3Fsource%3D-----acf0cb9b3e00---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----acf0cb9b3e00---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00%3Fsource%3D-----acf0cb9b3e00---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----acf0cb9b3e00---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=-----acf0cb9b3e00---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Facf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---footer_actions--acf0cb9b3e00---------------------clap_footer-----------)

631

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Facf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---footer_actions--acf0cb9b3e00---------------------clap_footer-----------)

631

16

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=---footer_actions--acf0cb9b3e00---------------------bookmark_footer-----------)

[![Image 5: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:144:144/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=post_page---post_author_info--acf0cb9b3e00--------------------------------)

[![Image 6: Level Up Coding](https://miro.medium.com/v2/resize:fill:64:64/1*5D9oYBd58pyjMkV_5-zXXQ.jpeg)](https://levelup.gitconnected.com/?source=post_page---post_author_info--acf0cb9b3e00--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--post_author_info--acf0cb9b3e00---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F596074279287&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&newsletterV3=f1a08d9452cd&newsletterV3Id=596074279287&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---post_author_info--acf0cb9b3e00---------------------subscribe_user-----------)

[Written by Salvatore Raieli ---------------------------](https://salvatore-raieli.medium.com/?source=post_page---post_author_info--acf0cb9b3e00--------------------------------)

[12.4K Followers](https://salvatore-raieli.medium.com/followers?source=post_page---post_author_info--acf0cb9b3e00--------------------------------)

·Writer for

[Level Up Coding](https://levelup.gitconnected.com/?source=post_page---post_author_info--acf0cb9b3e00--------------------------------)

Senior data scientist | about science, machine learning, and AI. Top writer in Artificial Intelligence

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--post_author_info--acf0cb9b3e00---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F596074279287&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&newsletterV3=f1a08d9452cd&newsletterV3Id=596074279287&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---post_author_info--acf0cb9b3e00---------------------subscribe_user-----------)

More from Salvatore Raieli and Level Up Coding
----------------------------------------------

![Image 7: Are LLMs able to reasoning?](https://miro.medium.com/v2/resize:fit:679/1*DEROz5k61T_8wf-I6515HA.png)

[![Image 8: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:20:20/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=author_recirc-----acf0cb9b3e00----0---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[Salvatore Raieli](https://salvatore-raieli.medium.com/?source=author_recirc-----acf0cb9b3e00----0---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

in

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----acf0cb9b3e00----0---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[The Savant Syndrome: Is Pattern Recognition Equivalent to Intelligence? ----------------------------------------------------------------------- ### Exploring the limits of artificial intelligence: why mastering patterns may not equal genuine reasoning](https://towardsdatascience.com/the-savant-syndrome-is-pattern-recognition-equivalent-to-intelligence-242aab928152?source=author_recirc-----acf0cb9b3e00----0---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

Oct 31

[1.98K 40](https://towardsdatascience.com/the-savant-syndrome-is-pattern-recognition-equivalent-to-intelligence-242aab928152?source=author_recirc-----acf0cb9b3e00----0---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F242aab928152&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-savant-syndrome-is-pattern-recognition-equivalent-to-intelligence-242aab928152&source=-----acf0cb9b3e00----0-----------------bookmark_preview----ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

![Image 9: LangGraph for Healthcare: A Comprehensive Technical Guide](https://miro.medium.com/v2/resize:fit:679/0*E3u4l_WYUlpUMIub)

[![Image 10: Senthil E](https://miro.medium.com/v2/resize:fill:20:20/1*7LSbLKp-_jaS5-_NzLBxuA.jpeg)](https://esenthil.medium.com/?source=author_recirc-----acf0cb9b3e00----1---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[Senthil E](https://esenthil.medium.com/?source=author_recirc-----acf0cb9b3e00----1---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

in

[Level Up Coding](https://levelup.gitconnected.com/?source=author_recirc-----acf0cb9b3e00----1---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[LangGraph for Healthcare: A Comprehensive Technical Guide --------------------------------------------------------- ### Building Production-Ready Medical Operations Agents](https://medium.com/langgraph-for-healthcare-a-comprehensive-technical-guide-e6038b06c108?source=author_recirc-----acf0cb9b3e00----1---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

1d ago

[37](https://medium.com/langgraph-for-healthcare-a-comprehensive-technical-guide-e6038b06c108?source=author_recirc-----acf0cb9b3e00----1---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe6038b06c108&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Flanggraph-for-healthcare-a-comprehensive-technical-guide-e6038b06c108&source=-----acf0cb9b3e00----1-----------------bookmark_preview----ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

![Image 11: What It Means to Be a 10x Engineer](https://miro.medium.com/v2/resize:fit:679/0*tpSSuwUncUr9K2eX.png)

[![Image 12: Jarek Orzel](https://miro.medium.com/v2/resize:fill:20:20/1*F3AJ1USJe5V8mhrj9Wze1g.png)](https://medium.com/@orzel.jarek?source=author_recirc-----acf0cb9b3e00----2---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[Jarek Orzel](https://medium.com/@orzel.jarek?source=author_recirc-----acf0cb9b3e00----2---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

in

[Level Up Coding](https://levelup.gitconnected.com/?source=author_recirc-----acf0cb9b3e00----2---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[What It Means to Be a 10x Engineer ---------------------------------- ### Not a Myth, But a Powerful Metaphor for Impactful Team Players](https://medium.com/what-it-means-to-be-a-10x-engineer-0f5c4db543a6?source=author_recirc-----acf0cb9b3e00----2---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

1d ago

[108 1](https://medium.com/what-it-means-to-be-a-10x-engineer-0f5c4db543a6?source=author_recirc-----acf0cb9b3e00----2---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F0f5c4db543a6&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-it-means-to-be-a-10x-engineer-0f5c4db543a6&source=-----acf0cb9b3e00----2-----------------bookmark_preview----ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

![Image 13: What if LLMs Are Better Than We Think? Or Is It Our Judgement That’s Flawed?](https://miro.medium.com/v2/resize:fit:679/1*4C1b2-U9wfYhhZQEw6SkLQ.jpeg)

[![Image 14: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:20:20/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=author_recirc-----acf0cb9b3e00----3---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[Salvatore Raieli](https://salvatore-raieli.medium.com/?source=author_recirc-----acf0cb9b3e00----3---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

in

[AI Advances](https://ai.gopubby.com/?source=author_recirc-----acf0cb9b3e00----3---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[What if LLMs Are Better Than We Think? Or Is It Our Judgement That’s Flawed? ---------------------------------------------------------------------------- ### A Study of Label Errors and Their Impact on LLM Performance Evaluations](https://ai.gopubby.com/what-if-llms-are-better-than-we-think-or-is-it-our-judgement-thats-flawed-5cbd9c758275?source=author_recirc-----acf0cb9b3e00----3---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

Oct 29

[541 12](https://ai.gopubby.com/what-if-llms-are-better-than-we-think-or-is-it-our-judgement-thats-flawed-5cbd9c758275?source=author_recirc-----acf0cb9b3e00----3---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cbd9c758275&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fwhat-if-llms-are-better-than-we-think-or-is-it-our-judgement-thats-flawed-5cbd9c758275&source=-----acf0cb9b3e00----3-----------------bookmark_preview----ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[See all from Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----acf0cb9b3e00--------------------------------)

[See all from Level Up Coding](https://levelup.gitconnected.com/?source=post_page-----acf0cb9b3e00--------------------------------)

Recommended from Medium
-----------------------

![Image 15: Has Anthropic Claude just wiped out an entire industry?](https://miro.medium.com/v2/resize:fit:679/0*vx14ZsK32TV7BWTG.png)

[![Image 16: AI Rabbit](https://miro.medium.com/v2/resize:fill:20:20/1*1cIrPiG5AyUHt-rt6gh_Vw.jpeg)](https://medium.com/@airabbitX?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[AI Rabbit](https://medium.com/@airabbitX?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

in

[CodeX](https://medium.com/codex?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Has Anthropic Claude just wiped out an entire industry? ------------------------------------------------------- ### If you have been following the news, you may have read about a new feature (or should I call it a product) in the Claude API — it is…](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

Oct 27

[1.4K 22](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc1ada7a8d91&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fhas-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91&source=-----acf0cb9b3e00----0-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

![Image 17: GPT-5 is finally here — What To Expect and What Not To Expect](https://miro.medium.com/v2/resize:fit:679/0*WS8GaZ6iL7VsWAgM)

[![Image 18: Don Lim](https://miro.medium.com/v2/resize:fill:20:20/1*SkAt7uMC11I7WgRXlBMiPA.jpeg)](https://medium.com/@don-lim?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Don Lim](https://medium.com/@don-lim?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[GPT-5 is finally here — What To Expect and What Not To Expect ------------------------------------------------------------- ### Microsoft engineers are preparing to host Orion (GPT-5) on Azure as early as November 2024.](https://medium.com/@don-lim/gpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

Oct 29

[705 13](https://medium.com/@don-lim/gpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f90e5362408&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40don-lim%2Fgpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408&source=-----acf0cb9b3e00----1-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

Lists
-----

[![Image 19](https://miro.medium.com/v2/resize:fill:48:48/0*r4yjMpEmqzHCUvWC.jpg) ![Image 20](https://miro.medium.com/v2/resize:fill:48:48/1*bv2KUVNLi2sFNjBTdoBmWw.png) ![Image 21](https://miro.medium.com/v2/resize:fill:48:48/0*zsngbTOmFCy6sUCx.jpeg) Predictive Modeling w/ Python ----------------------------- 20 stories·1652 saves](https://medium.com/@ben.putney/list/predictive-modeling-w-python-e3668ea008e1?source=read_next_recirc-----acf0cb9b3e00--------------------------------)

[![Image 22](https://miro.medium.com/v2/resize:fill:48:48/0*BMoBXwlLY_RNGQvi.jpeg) ![Image 23](https://miro.medium.com/v2/resize:fill:48:48/1*cL4lJbdwYn-0UH4SyOYqXw.jpeg) ![Image 24](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*UeZPcm_AcNpatRN4) Natural Language Processing --------------------------- 1803 stories·1418 saves](https://medium.com/@AMGAS14/list/natural-language-processing-0a856388a93a?source=read_next_recirc-----acf0cb9b3e00--------------------------------)

[![Image 25: Principal Component Analysis for ML](https://miro.medium.com/v2/resize:fill:48:48/1*swd_PY6vTCyPnsgBYoFZfA.png) ![Image 26: Time Series Analysis](https://miro.medium.com/v2/resize:fill:48:48/1*8sSAHftNwd_RNJ3k4VA0pA.png) ![Image 27: deep learning cheatsheet for beginner](https://miro.medium.com/v2/resize:fill:48:48/1*uNyD4yNMH-DnOel1wzxOOA.png) Practical Guides to Machine Learning ------------------------------------ 10 stories·2016 saves](https://destingong.medium.com/list/practical-guides-to-machine-learning-a877c2a39884?source=read_next_recirc-----acf0cb9b3e00--------------------------------)

[![Image 28](https://miro.medium.com/v2/resize:fill:48:48/1*I2o9__q4g1dzbcH9XRqcRg.png) ![Image 29](https://miro.medium.com/v2/resize:fill:48:48/0*F6q2BN7oddumBDGY.png) ![Image 30](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*dT68KKwa4mw4ShQJ) ChatGPT prompts --------------- 50 stories·2203 saves](https://medium.com/@nicholas.michael.janulewicz/list/chatgpt-prompts-b4c47b8e12ee?source=read_next_recirc-----acf0cb9b3e00--------------------------------)

![Image 31: 4 Mindblowing ChatGPT Features (Nov 2024)](https://miro.medium.com/v2/resize:fit:679/1*5wtVAZE3HbOFcklO3opyhQ.jpeg)

[![Image 32: Jordan Gibbs](https://miro.medium.com/v2/resize:fill:20:20/1*A1IH-oySSaC8eRBAxDhWxQ.jpeg)](https://medium.com/@jordan_gibbs?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Jordan Gibbs](https://medium.com/@jordan_gibbs?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[4 Mindblowing ChatGPT Features (Nov 2024) ----------------------------------------- ### Don’t miss these incredible new and overlooked features that will revolutionize your ChatGPT workflow.](https://medium.com/@jordan_gibbs/4-mindblowing-chatgpt-features-nov-2024-ed6af71b4f35?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

Nov 4

[756 6](https://medium.com/@jordan_gibbs/4-mindblowing-chatgpt-features-nov-2024-ed6af71b4f35?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed6af71b4f35&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40jordan_gibbs%2F4-mindblowing-chatgpt-features-nov-2024-ed6af71b4f35&source=-----acf0cb9b3e00----0-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

![Image 33: Donald Trump](https://miro.medium.com/v2/resize:fit:679/1*kMdzbel_AYpw_UDsylf6vg.jpeg)

[![Image 34: Isaac Saul](https://miro.medium.com/v2/resize:fill:20:20/1*5bMy4uvQlQxjhi_xhBlJJQ.jpeg)](https://medium.com/@isaac_1884?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Isaac Saul](https://medium.com/@isaac_1884?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

in

[The Political Prism](https://medium.com/the-political-prism?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[22 Thoughts about Trump’s Win ----------------------------- ### Reflecting on the election and looking forward to what may come](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

5d ago

[7.8K 263](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F610bbb304850&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fthe-political-prism%2F22-thoughts-about-trumps-win-610bbb304850&source=-----acf0cb9b3e00----1-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

![Image 35: Ready or Not, AI Gets Trumped: Navigating the Chaos Ahead](https://miro.medium.com/v2/resize:fit:679/1*hYg1MyzJQfaVh9cr6ThqHg.png)

[![Image 36: Cezary Gesikowski](https://miro.medium.com/v2/resize:fill:20:20/1*5_A7uzGUVqVtOpAyHdk0MQ.jpeg)](https://gesikowski.medium.com/?source=read_next_recirc-----acf0cb9b3e00----2---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Cezary Gesikowski](https://gesikowski.medium.com/?source=read_next_recirc-----acf0cb9b3e00----2---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

in

[Generative AI](https://generativeai.pub/?source=read_next_recirc-----acf0cb9b3e00----2---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Ready or Not, AI Gets Trumped: Navigating the Chaos Ahead --------------------------------------------------------- ### The High-Stakes Battle for AI Ethics, Innovation, and Global Influence](https://generativeai.pub/ready-or-not-ai-gets-trumped-navigating-the-chaos-ahead-cd2bc14b363b?source=read_next_recirc-----acf0cb9b3e00----2---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

4d ago

[446 11](https://generativeai.pub/ready-or-not-ai-gets-trumped-navigating-the-chaos-ahead-cd2bc14b363b?source=read_next_recirc-----acf0cb9b3e00----2---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcd2bc14b363b&operation=register&redirect=https%3A%2F%2Fgenerativeai.pub%2Fready-or-not-ai-gets-trumped-navigating-the-chaos-ahead-cd2bc14b363b&source=-----acf0cb9b3e00----2-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

![Image 37: The PDF Extraction Revolution: Why PymuPDF4llm is Your New Best Friend (and LlamaParse is Crying)](https://miro.medium.com/v2/resize:fit:679/0*1PQz2rhOIopPlzvo)

[![Image 38: Richardson Gunde](https://miro.medium.com/v2/resize:fill:20:20/1*tp2uj3tur89cbR2GW0SrDQ.png)](https://medium.com/@honeyricky1m3?source=read_next_recirc-----acf0cb9b3e00----3---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Richardson Gunde](https://medium.com/@honeyricky1m3?source=read_next_recirc-----acf0cb9b3e00----3---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

in

[AI Advances](https://ai.gopubby.com/?source=read_next_recirc-----acf0cb9b3e00----3---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[The PDF Extraction Revolution: Why PymuPDF4llm is Your New Best Friend (and LlamaParse is Crying) ------------------------------------------------------------------------------------------------- ### Hey there, data-loving friends! Ready for some serious AI magic? Picture this: you’re knee-deep in PDFs, trying to extract information for…](https://ai.gopubby.com/the-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8?source=read_next_recirc-----acf0cb9b3e00----3---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

Oct 31

[1K 13](https://ai.gopubby.com/the-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8?source=read_next_recirc-----acf0cb9b3e00----3---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe57882dee7f8&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fthe-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8&source=-----acf0cb9b3e00----3-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[See more recommendations](https://medium.com/?source=post_page-----acf0cb9b3e00--------------------------------)

[Help](https://help.medium.com/hc/en-us?source=post_page-----acf0cb9b3e00--------------------------------)

[Status](https://medium.statuspage.io/?source=post_page-----acf0cb9b3e00--------------------------------)

[About](https://medium.com/about?autoplay=1&source=post_page-----acf0cb9b3e00--------------------------------)

[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----acf0cb9b3e00--------------------------------)

[Press](https://medium.com/gitconnected/pressinquiries@medium.com?source=post_page-----acf0cb9b3e00--------------------------------)

[Blog](https://blog.medium.com/?source=post_page-----acf0cb9b3e00--------------------------------)

[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----acf0cb9b3e00--------------------------------)

[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----acf0cb9b3e00--------------------------------)

[Text to speech](https://speechify.com/medium?source=post_page-----acf0cb9b3e00--------------------------------)

[Teams](https://medium.com/business?source=post_page-----acf0cb9b3e00--------------------------------)


## Visual Content Analysis

### Image Analysis
Title: What Is The Best Therapy For a Hallucinating AI Patient?

URL Source: https://medium.com/gitconnected/what-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00

Published Time: 2024-11-11T02:50:06.029Z

Markdown Content:
What Is The Best Therapy For a Hallucinating AI Patient? | by Salvatore Raieli | Nov, 2024 | Level Up Coding
===============
 

[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Facf0cb9b3e00&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---top_nav_layout_nav----------------------------------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[](https://medium.com/?source=---top_nav_layout_nav----------------------------------)

[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav-----------)

[](https://medium.com/search?source=---top_nav_layout_nav----------------------------------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

![Image 1](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)

Top highlight

Member-only story

|LLM|AI|HALLUCINATION|PROMPT ENGINEERING|BENCHMARK|
---------------------------------------------------

What Is The Best Therapy For a Hallucinating AI Patient?
========================================================

Exploring the Art and Science of Prompt Engineering to Cure LLM Hallucinations
------------------------------------------------------------------------------

[![Image 2: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:88:88/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=post_page---byline--acf0cb9b3e00--------------------------------)

[![Image 3: Level Up Coding](https://miro.medium.com/v2/resize:fill:48:48/1*5D9oYBd58pyjMkV_5-zXXQ.jpeg)](https://levelup.gitconnected.com/?source=post_page---byline--acf0cb9b3e00--------------------------------)

[Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page---byline--acf0cb9b3e00--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--byline--acf0cb9b3e00---------------------post_header-----------)

Published in

[Level Up Coding](https://levelup.gitconnected.com/?source=post_page---byline--acf0cb9b3e00--------------------------------)

·

10 min read

·

1 day ago

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Facf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---header_actions--acf0cb9b3e00---------------------clap_footer-----------)

631

16

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=---header_actions--acf0cb9b3e00---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Dacf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=---header_actions--acf0cb9b3e00---------------------post_audio_button-----------)

Share

![Image 4: Discover how Large Language Models (LLMs) handle language tasks and the methods to reduce AI inaccuracies known as hallucinations. This study evaluates different prompt engineering strategies, revealing that simpler techniques often outperform complex ones. It also explores how tool-calling agents, which augment LLMs with external tools, can increase hallucination rates, emphasizing the importance of balanced prompt design for optimal performance in NLP tasks.](https://miro.medium.com/v2/resize:fit:700/1*iozTEShq70i8p46b-BvjzQ.jpeg)

image generated by the author using AI

> Without execution, ‘vision’ is just another word for hallucination. — Mark V. Hurd
> 
> A hallucination is a fact, not an error; what is erroneous is a judgment based upon it. — Bertrand Russell

[Large language models (LLMs)](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=Large%20Language%20Models,-What%20is%20a) are ubiquitous today, especially because of their [ability to generate text](https://www.ibm.com/topics/large-language-models) and adapt to different tasks without being trained. In addition, there has been debate about their reasoning capabilities and being able to apply them to solving complex problems or making decisions. Despite what seems like a success story, LLMs are not without flaws and can sometimes generate inaccurate or misleading information, often referred to as [hallucinations](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20does%20it%20mean%20LLM%27s%20hallucination%3F). Hallucinations are dangerous because they can produce factual errors, bias, and misinformation. [Hallucinations](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20does%20it%20mean%20LLM%27s%20hallucination%3F) and lack of understanding can be a serious risk for sensitive applications (medical, financial, and so on).

Create an account to read the full story.


---------------------------------------------

The author made this story available to Medium members only.  
If you’re new to Medium, create a new account to read this story on us.

[Continue in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Facf0cb9b3e00&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=regwall&source=-----acf0cb9b3e00---------------------post_regwall-----------)

Or, continue in mobile web

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00%3Fsource%3D-----acf0cb9b3e00---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----acf0cb9b3e00---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00%3Fsource%3D-----acf0cb9b3e00---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----acf0cb9b3e00---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00%3Fsource%3D-----acf0cb9b3e00---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----acf0cb9b3e00---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=-----acf0cb9b3e00---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Facf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---footer_actions--acf0cb9b3e00---------------------clap_footer-----------)

631

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Facf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---footer_actions--acf0cb9b3e00---------------------clap_footer-----------)

631

16

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facf0cb9b3e00&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&source=---footer_actions--acf0cb9b3e00---------------------bookmark_footer-----------)

[![Image 5: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:144:144/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=post_page---post_author_info--acf0cb9b3e00--------------------------------)

[![Image 6: Level Up Coding](https://miro.medium.com/v2/resize:fill:64:64/1*5D9oYBd58pyjMkV_5-zXXQ.jpeg)](https://levelup.gitconnected.com/?source=post_page---post_author_info--acf0cb9b3e00--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--post_author_info--acf0cb9b3e00---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F596074279287&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&newsletterV3=f1a08d9452cd&newsletterV3Id=596074279287&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---post_author_info--acf0cb9b3e00---------------------subscribe_user-----------)

[Written by Salvatore Raieli ---------------------------](https://salvatore-raieli.medium.com/?source=post_page---post_author_info--acf0cb9b3e00--------------------------------)

[12.4K Followers](https://salvatore-raieli.medium.com/followers?source=post_page---post_author_info--acf0cb9b3e00--------------------------------)

·Writer for

[Level Up Coding](https://levelup.gitconnected.com/?source=post_page---post_author_info--acf0cb9b3e00--------------------------------)

Senior data scientist | about science, machine learning, and AI. Top writer in Artificial Intelligence

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--post_author_info--acf0cb9b3e00---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F596074279287&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-is-the-best-therapy-for-a-hallucinating-ai-patient-acf0cb9b3e00&newsletterV3=f1a08d9452cd&newsletterV3Id=596074279287&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---post_author_info--acf0cb9b3e00---------------------subscribe_user-----------)

More from Salvatore Raieli and Level Up Coding
----------------------------------------------

![Image 7: Are LLMs able to reasoning?](https://miro.medium.com/v2/resize:fit:679/1*DEROz5k61T_8wf-I6515HA.png)

[![Image 8: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:20:20/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=author_recirc-----acf0cb9b3e00----0---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[Salvatore Raieli](https://salvatore-raieli.medium.com/?source=author_recirc-----acf0cb9b3e00----0---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

in

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----acf0cb9b3e00----0---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[The Savant Syndrome: Is Pattern Recognition Equivalent to Intelligence? ----------------------------------------------------------------------- ### Exploring the limits of artificial intelligence: why mastering patterns may not equal genuine reasoning](https://towardsdatascience.com/the-savant-syndrome-is-pattern-recognition-equivalent-to-intelligence-242aab928152?source=author_recirc-----acf0cb9b3e00----0---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

Oct 31

[1.98K 40](https://towardsdatascience.com/the-savant-syndrome-is-pattern-recognition-equivalent-to-intelligence-242aab928152?source=author_recirc-----acf0cb9b3e00----0---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F242aab928152&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-savant-syndrome-is-pattern-recognition-equivalent-to-intelligence-242aab928152&source=-----acf0cb9b3e00----0-----------------bookmark_preview----ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

![Image 9: LangGraph for Healthcare: A Comprehensive Technical Guide](https://miro.medium.com/v2/resize:fit:679/0*E3u4l_WYUlpUMIub)

[![Image 10: Senthil E](https://miro.medium.com/v2/resize:fill:20:20/1*7LSbLKp-_jaS5-_NzLBxuA.jpeg)](https://esenthil.medium.com/?source=author_recirc-----acf0cb9b3e00----1---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[Senthil E](https://esenthil.medium.com/?source=author_recirc-----acf0cb9b3e00----1---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

in

[Level Up Coding](https://levelup.gitconnected.com/?source=author_recirc-----acf0cb9b3e00----1---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[LangGraph for Healthcare: A Comprehensive Technical Guide --------------------------------------------------------- ### Building Production-Ready Medical Operations Agents](https://medium.com/langgraph-for-healthcare-a-comprehensive-technical-guide-e6038b06c108?source=author_recirc-----acf0cb9b3e00----1---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

1d ago

[37](https://medium.com/langgraph-for-healthcare-a-comprehensive-technical-guide-e6038b06c108?source=author_recirc-----acf0cb9b3e00----1---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe6038b06c108&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Flanggraph-for-healthcare-a-comprehensive-technical-guide-e6038b06c108&source=-----acf0cb9b3e00----1-----------------bookmark_preview----ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

![Image 11: What It Means to Be a 10x Engineer](https://miro.medium.com/v2/resize:fit:679/0*tpSSuwUncUr9K2eX.png)

[![Image 12: Jarek Orzel](https://miro.medium.com/v2/resize:fill:20:20/1*F3AJ1USJe5V8mhrj9Wze1g.png)](https://medium.com/@orzel.jarek?source=author_recirc-----acf0cb9b3e00----2---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[Jarek Orzel](https://medium.com/@orzel.jarek?source=author_recirc-----acf0cb9b3e00----2---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

in

[Level Up Coding](https://levelup.gitconnected.com/?source=author_recirc-----acf0cb9b3e00----2---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[What It Means to Be a 10x Engineer ---------------------------------- ### Not a Myth, But a Powerful Metaphor for Impactful Team Players](https://medium.com/what-it-means-to-be-a-10x-engineer-0f5c4db543a6?source=author_recirc-----acf0cb9b3e00----2---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

1d ago

[108 1](https://medium.com/what-it-means-to-be-a-10x-engineer-0f5c4db543a6?source=author_recirc-----acf0cb9b3e00----2---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F0f5c4db543a6&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-it-means-to-be-a-10x-engineer-0f5c4db543a6&source=-----acf0cb9b3e00----2-----------------bookmark_preview----ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

![Image 13: What if LLMs Are Better Than We Think? Or Is It Our Judgement That’s Flawed?](https://miro.medium.com/v2/resize:fit:679/1*4C1b2-U9wfYhhZQEw6SkLQ.jpeg)

[![Image 14: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:20:20/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=author_recirc-----acf0cb9b3e00----3---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[Salvatore Raieli](https://salvatore-raieli.medium.com/?source=author_recirc-----acf0cb9b3e00----3---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

in

[AI Advances](https://ai.gopubby.com/?source=author_recirc-----acf0cb9b3e00----3---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[What if LLMs Are Better Than We Think? Or Is It Our Judgement That’s Flawed? ---------------------------------------------------------------------------- ### A Study of Label Errors and Their Impact on LLM Performance Evaluations](https://ai.gopubby.com/what-if-llms-are-better-than-we-think-or-is-it-our-judgement-thats-flawed-5cbd9c758275?source=author_recirc-----acf0cb9b3e00----3---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

Oct 29

[541 12](https://ai.gopubby.com/what-if-llms-are-better-than-we-think-or-is-it-our-judgement-thats-flawed-5cbd9c758275?source=author_recirc-----acf0cb9b3e00----3---------------------ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cbd9c758275&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fwhat-if-llms-are-better-than-we-think-or-is-it-our-judgement-thats-flawed-5cbd9c758275&source=-----acf0cb9b3e00----3-----------------bookmark_preview----ea8d7551_3772_4ae4_9455_c7f88a00340c-------)

[See all from Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----acf0cb9b3e00--------------------------------)

[See all from Level Up Coding](https://levelup.gitconnected.com/?source=post_page-----acf0cb9b3e00--------------------------------)

Recommended from Medium
-----------------------

![Image 15: Has Anthropic Claude just wiped out an entire industry?](https://miro.medium.com/v2/resize:fit:679/0*vx14ZsK32TV7BWTG.png)

[![Image 16: AI Rabbit](https://miro.medium.com/v2/resize:fill:20:20/1*1cIrPiG5AyUHt-rt6gh_Vw.jpeg)](https://medium.com/@airabbitX?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[AI Rabbit](https://medium.com/@airabbitX?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

in

[CodeX](https://medium.com/codex?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Has Anthropic Claude just wiped out an entire industry? ------------------------------------------------------- ### If you have been following the news, you may have read about a new feature (or should I call it a product) in the Claude API — it is…](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

Oct 27

[1.4K 22](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc1ada7a8d91&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fhas-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91&source=-----acf0cb9b3e00----0-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

![Image 17: GPT-5 is finally here — What To Expect and What Not To Expect](https://miro.medium.com/v2/resize:fit:679/0*WS8GaZ6iL7VsWAgM)

[![Image 18: Don Lim](https://miro.medium.com/v2/resize:fill:20:20/1*SkAt7uMC11I7WgRXlBMiPA.jpeg)](https://medium.com/@don-lim?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Don Lim](https://medium.com/@don-lim?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[GPT-5 is finally here — What To Expect and What Not To Expect ------------------------------------------------------------- ### Microsoft engineers are preparing to host Orion (GPT-5) on Azure as early as November 2024.](https://medium.com/@don-lim/gpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

Oct 29

[705 13](https://medium.com/@don-lim/gpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f90e5362408&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40don-lim%2Fgpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408&source=-----acf0cb9b3e00----1-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

Lists
-----

[![Image 19](https://miro.medium.com/v2/resize:fill:48:48/0*r4yjMpEmqzHCUvWC.jpg) ![Image 20](https://miro.medium.com/v2/resize:fill:48:48/1*bv2KUVNLi2sFNjBTdoBmWw.png) ![Image 21](https://miro.medium.com/v2/resize:fill:48:48/0*zsngbTOmFCy6sUCx.jpeg) Predictive Modeling w/ Python ----------------------------- 20 stories·1652 saves](https://medium.com/@ben.putney/list/predictive-modeling-w-python-e3668ea008e1?source=read_next_recirc-----acf0cb9b3e00--------------------------------)

[![Image 22](https://miro.medium.com/v2/resize:fill:48:48/0*BMoBXwlLY_RNGQvi.jpeg) ![Image 23](https://miro.medium.com/v2/resize:fill:48:48/1*cL4lJbdwYn-0UH4SyOYqXw.jpeg) ![Image 24](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*UeZPcm_AcNpatRN4) Natural Language Processing --------------------------- 1803 stories·1418 saves](https://medium.com/@AMGAS14/list/natural-language-processing-0a856388a93a?source=read_next_recirc-----acf0cb9b3e00--------------------------------)

[![Image 25: Principal Component Analysis for ML](https://miro.medium.com/v2/resize:fill:48:48/1*swd_PY6vTCyPnsgBYoFZfA.png) ![Image 26: Time Series Analysis](https://miro.medium.com/v2/resize:fill:48:48/1*8sSAHftNwd_RNJ3k4VA0pA.png) ![Image 27: deep learning cheatsheet for beginner](https://miro.medium.com/v2/resize:fill:48:48/1*uNyD4yNMH-DnOel1wzxOOA.png) Practical Guides to Machine Learning ------------------------------------ 10 stories·2016 saves](https://destingong.medium.com/list/practical-guides-to-machine-learning-a877c2a39884?source=read_next_recirc-----acf0cb9b3e00--------------------------------)

[![Image 28](https://miro.medium.com/v2/resize:fill:48:48/1*I2o9__q4g1dzbcH9XRqcRg.png) ![Image 29](https://miro.medium.com/v2/resize:fill:48:48/0*F6q2BN7oddumBDGY.png) ![Image 30](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*dT68KKwa4mw4ShQJ) ChatGPT prompts --------------- 50 stories·2203 saves](https://medium.com/@nicholas.michael.janulewicz/list/chatgpt-prompts-b4c47b8e12ee?source=read_next_recirc-----acf0cb9b3e00--------------------------------)

![Image 31: 4 Mindblowing ChatGPT Features (Nov 2024)](https://miro.medium.com/v2/resize:fit:679/1*5wtVAZE3HbOFcklO3opyhQ.jpeg)

[![Image 32: Jordan Gibbs](https://miro.medium.com/v2/resize:fill:20:20/1*A1IH-oySSaC8eRBAxDhWxQ.jpeg)](https://medium.com/@jordan_gibbs?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Jordan Gibbs](https://medium.com/@jordan_gibbs?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[4 Mindblowing ChatGPT Features (Nov 2024) ----------------------------------------- ### Don’t miss these incredible new and overlooked features that will revolutionize your ChatGPT workflow.](https://medium.com/@jordan_gibbs/4-mindblowing-chatgpt-features-nov-2024-ed6af71b4f35?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

Nov 4

[756 6](https://medium.com/@jordan_gibbs/4-mindblowing-chatgpt-features-nov-2024-ed6af71b4f35?source=read_next_recirc-----acf0cb9b3e00----0---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed6af71b4f35&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40jordan_gibbs%2F4-mindblowing-chatgpt-features-nov-2024-ed6af71b4f35&source=-----acf0cb9b3e00----0-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

![Image 33: Donald Trump](https://miro.medium.com/v2/resize:fit:679/1*kMdzbel_AYpw_UDsylf6vg.jpeg)

[![Image 34: Isaac Saul](https://miro.medium.com/v2/resize:fill:20:20/1*5bMy4uvQlQxjhi_xhBlJJQ.jpeg)](https://medium.com/@isaac_1884?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Isaac Saul](https://medium.com/@isaac_1884?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

in

[The Political Prism](https://medium.com/the-political-prism?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[22 Thoughts about Trump’s Win ----------------------------- ### Reflecting on the election and looking forward to what may come](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

5d ago

[7.8K 263](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----acf0cb9b3e00----1---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F610bbb304850&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fthe-political-prism%2F22-thoughts-about-trumps-win-610bbb304850&source=-----acf0cb9b3e00----1-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

![Image 35: Ready or Not, AI Gets Trumped: Navigating the Chaos Ahead](https://miro.medium.com/v2/resize:fit:679/1*hYg1MyzJQfaVh9cr6ThqHg.png)

[![Image 36: Cezary Gesikowski](https://miro.medium.com/v2/resize:fill:20:20/1*5_A7uzGUVqVtOpAyHdk0MQ.jpeg)](https://gesikowski.medium.com/?source=read_next_recirc-----acf0cb9b3e00----2---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Cezary Gesikowski](https://gesikowski.medium.com/?source=read_next_recirc-----acf0cb9b3e00----2---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

in

[Generative AI](https://generativeai.pub/?source=read_next_recirc-----acf0cb9b3e00----2---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Ready or Not, AI Gets Trumped: Navigating the Chaos Ahead --------------------------------------------------------- ### The High-Stakes Battle for AI Ethics, Innovation, and Global Influence](https://generativeai.pub/ready-or-not-ai-gets-trumped-navigating-the-chaos-ahead-cd2bc14b363b?source=read_next_recirc-----acf0cb9b3e00----2---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

4d ago

[446 11](https://generativeai.pub/ready-or-not-ai-gets-trumped-navigating-the-chaos-ahead-cd2bc14b363b?source=read_next_recirc-----acf0cb9b3e00----2---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcd2bc14b363b&operation=register&redirect=https%3A%2F%2Fgenerativeai.pub%2Fready-or-not-ai-gets-trumped-navigating-the-chaos-ahead-cd2bc14b363b&source=-----acf0cb9b3e00----2-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

![Image 37: The PDF Extraction Revolution: Why PymuPDF4llm is Your New Best Friend (and LlamaParse is Crying)](https://miro.medium.com/v2/resize:fit:679/0*1PQz2rhOIopPlzvo)

[![Image 38: Richardson Gunde](https://miro.medium.com/v2/resize:fill:20:20/1*tp2uj3tur89cbR2GW0SrDQ.png)](https://medium.com/@honeyricky1m3?source=read_next_recirc-----acf0cb9b3e00----3---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[Richardson Gunde](https://medium.com/@honeyricky1m3?source=read_next_recirc-----acf0cb9b3e00----3---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

in

[AI Advances](https://ai.gopubby.com/?source=read_next_recirc-----acf0cb9b3e00----3---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[The PDF Extraction Revolution: Why PymuPDF4llm is Your New Best Friend (and LlamaParse is Crying) ------------------------------------------------------------------------------------------------- ### Hey there, data-loving friends! Ready for some serious AI magic? Picture this: you’re knee-deep in PDFs, trying to extract information for…](https://ai.gopubby.com/the-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8?source=read_next_recirc-----acf0cb9b3e00----3---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

Oct 31

[1K 13](https://ai.gopubby.com/the-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8?source=read_next_recirc-----acf0cb9b3e00----3---------------------c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe57882dee7f8&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fthe-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8&source=-----acf0cb9b3e00----3-----------------bookmark_preview----c6511380_63dd_4b9e_9fd2_aff05e48c6a3-------)

[See more recommendations](https://medium.com/?source=post_page-----acf0cb9b3e00--------------------------------)

[Help](https://help.medium.com/hc/en-us?source=post_page-----acf0cb9b3e00--------------------------------)

[Status](https://medium.statuspage.io/?source=post_page-----acf0cb9b3e00--------------------------------)

[About](https://medium.com/about?autoplay=1&source=post_page-----acf0cb9b3e00--------------------------------)

[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----acf0cb9b3e00--------------------------------)

[Press](https://medium.com/gitconnected/pressinquiries@medium.com?source=post_page-----acf0cb9b3e00--------------------------------)

[Blog](https://blog.medium.com/?source=post_page-----acf0cb9b3e00--------------------------------)

[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----acf0cb9b3e00--------------------------------)

[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----acf0cb9b3e00--------------------------------)

[Text to speech](https://speechify.com/medium?source=post_page-----acf0cb9b3e00--------------------------------)

[Teams](https://medium.com/business?source=post_page-----acf0cb9b3e00--------------------------------)


---

## https://medium.com/towards-data-science/understanding-llms-from-scratch-using-middle-school-math-e602d27ec876

Title: LLMs from Scratch Using Middle School Math | Towards Data Science

URL Source: https://medium.com/towards-data-science/understanding-llms-from-scratch-using-middle-school-math-e602d27ec876

Markdown Content:
A self-contained, full explanation to inner workings of an LLM
--------------------------------------------------------------

[![Image 1: Rohit Patel](https://miro.medium.com/v2/resize:fill:88:88/1*ECmWr6Z-ToM5JE-h8ywyLQ.jpeg)](https://rohit-patel.medium.com/?source=post_page---byline--e602d27ec876--------------------------------)

[![Image 2: Towards Data Science](https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg)](https://towardsdatascience.com/?source=post_page---byline--e602d27ec876--------------------------------)

In this article, we talk about how Large Language Models (LLMs) work, from scratch — assuming only that you know how to add and multiply two numbers. The article is meant to be fully self-contained. We start by building a simple Generative AI on pen and paper, and then walk through everything we need to have a firm understanding of modern LLMs and the Transformer architecture. The article will strip out all the fancy language and jargon in ML and represent everything simply as they are: numbers. We will still call out what things are called to tether your thoughts when you read jargon-y content.

Going from addition/multiplication to the most advanced AI models today without assuming other knowledge or referring to other sources means we cover a LOT of ground. This is NOT a toy LLM explanation — a determined person can theoretically recreate a modern LLM from all the information here. I have cut out every word/line that was unnecessary and as such this article isn’t really meant to be browsed.

What will we cover?
-------------------

1.  A simple neural network
2.  How are these models trained?
3.  How does all this generate language?
4.  What makes LLMs work so well?
5.  Embeddings
6.  Sub-word tokenizers
7.  Self-attention
8.  Softmax
9.  Residual connections
10.  Layer Normalization
11.  Dropout
12.  Multi-head attention
13.  Positional embeddings
14.  The GPT architecture
15.  The transformer architecture

Let’s dive in.

The first thing to note is that neural networks can only take numbers as inputs and can only output numbers. No exceptions. The art is in figuring out how to feed your inputs as numbers, interpreting the output numbers in a way that achieves your goals. And finally, building neural nets that will take the inputs you provide and give you the outputs you want (given the interpretation you chose for these outputs). Let’s walk through how we get from adding and multiplying numbers to things like [Llama 3.1](https://ai.meta.com/blog/meta-llama-3-1/).

A simple neural network:
------------------------

Let’s work through a simple neural network that can classify an object:

*   **Object data available:** Dominant color (RGB) & Volume (in milli-liters)
*   **Classify into**: Leaf OR Flower

Here’s what the data for a leaf and a sunflower can look like:

![Image 3: a table showing the number of leaves and flowers](https://miro.medium.com/v2/resize:fit:700/1*ymWXxVf7N4-Ps-62Cih2XQ.png)

Image by author

Let’s now build a neural net that does this classification. We need to decide on input/output interpretations. Our inputs are already numbers, so we can feed them directly into the network. Our outputs are two objects, leaf and flower which the neural network cannot output. Let’s look at a couple of schemes we can use here:

*   We can make the network output a single number. And if the number is positive we say it’s a leaf and if it is negative we say it’s a flower
*   OR, we can make the network output two numbers. We interpret the first one as a number for leaf and second one as the number for flower and we will say that the selection is whichever number is larger

Both schemes allow the network to output number(s) that we can interpret as leaf or flower. Let’s pick the second scheme here because it generalizes well to other things we will look at later. And here’s a neural network that does the classification using this scheme. Let’s work through it:

![Image 4: a sunflower with a number of sunflowers](https://miro.medium.com/v2/resize:fit:700/1*D-e4rt_QBPp1fMY5OseJiQ.png)

Image by author

Blue circle like so: (32 \* 0.10) **+** (107 \* -0.29) **+** (56 \* -0.07) **+** (11.2 \* 0.46) = **— 26.6**

Some jargon:

**_Neurons/nodes_**: The numbers in the circles

**_Weights_**: The colored numbers on the lines

**_Layers_**: A collection of neurons is called a layer. You could think of this network as having 3 layers: Input layer with 4 neurons, Middle layer with 3 neurons, and the Output layer with 2 neurons.

To calculate the prediction/output from this network (called a “**forward pass**”), you start from the left. We have the data available for the neurons in the Input layer. To move “forward” to the next layer, you multiply the number in the circle with the weight for the corresponding neuron pairing and you add them all up. We demonstrate blue and orange circle math above. Running the whole network we see that the first number in the output layer comes out higher so we interpret it as “network classified these (RGB,Vol) values as leaf”. A well trained network can take various inputs for (RGB,Vol) and correctly classify the object.

The model has no notion of what a leaf or a flower is, or what (RGB,Vol) are. It has a job of taking in exactly 4 numbers and giving out exactly 2 numbers. It is our interpretation that the 4 input numbers are (RGB,Vol) and it is also our decision to look at the output numbers and infer that if the first number is larger it’s a leaf and so on. And finally, it is also up to us to choose the right weights such that the model will take our input numbers and give us the right two numbers such that when we interpret them we get the interpretation we want.

An interesting side effect of this is that you can take the same network and instead of feeding RGB,Vol feed other 4 numbers like cloud cover, humidity etc.. and interpret the two numbers as “Sunny in an hour” or “Rainy in an hour” and then if you have the weights well calibrated you can get the exact same network to do two things at the same time — classify leaf/flower and predict rain in an hour! The network just gives you two numbers, whether you interpret it as classification or prediction or something else is entirely up to you.

Stuff left out for simplification (feel free to ignore without compromising comprehensibility):

*   **Activation layer**: A critical thing missing from this network is an “activation layer”. That’s a fancy word for saying that we take the number in each circle and apply a nonlinear function to it (**RELU** is a common function where you just take the number and set it to zero if it is negative, and leave it unchanged if it is positive). So basically in our case above, we would take the middle layer and replace the two numbers (-26.6 and -47.1) with zeros before we proceed further to the next layer. Of course, we would have to re-train the weights here to make the network useful again. Without the activation layer all the additions and multiplications in the network can be collapsed to a single layer. In our case, you could write the green circle as the sum of RGB directly with some weights and you would not need the middle layer. It would be something like (0.10 \* -0.17 + 0.12 \* 0.39–0.36 \* 0.1) \* R + (-0.29 \* -0.17–0.05 \* 0.39–0.21 \* 0.1) \* G …and so on. This is usually not possible if we have a nonlinearity there. This helps networks deal with more complex situations.
*   **Bias:** Networks will usually also contain another number associated with each node, this number is simply added to the product to calculate the value of the node and this number is called the “bias”. So if the bias for the top blue node was 0.25 then the value in the node would be: (32 \* 0.10) + (107 \* -0.29) + (56 \* -0.07) + (11.2 \* 0.46) **\+ 0.25** \= — 26.35. The word parameters is usually used to refer to all these numbers in the model that are not neurons/nodes.
*   **Softmax:** We don’t usually interpret the output layer directly as shown in our models. We convert the numbers into probabilities (i.e. make it so that all numbers are positive and add up to 1). If all the numbers in the output layer were already positive one way you could achieve this is by dividing each number by the sum of all numbers in the output layer. Though a “softmax” function is normally used which can handle both positive and negative numbers.

How are these models trained?
-----------------------------

In the example above, we magically had the weights that allowed us to put data into the model and get a good output. But how are these weights determined? The process of setting these weights (or “parameters”) is called “**training the model**”, and we need some training data to train the model.

Let’s say we have some data where we have the inputs and we already know if each input corresponds to leaf or flower, this is our “**training data**” and since we have the leaf/flower label for each set of (R,G,B,Vol) numbers, this is “**labeled data**”.

Here’s how it works:

*   Start with a random numbers, i.e. set each parameter/weight to a random number
*   Now, we know that when we input the data corresponding to the leaf (R=32, G=107, B=56, Vol=11.2). Suppose we want a larger number for leaf in the output layer. Let’s say we want the number corresponding to leaf as 0.8 and the one corresponding to flower as 0.2 (as shown in example above, but these are illustrative numbers to demonstrate training, in reality we would not want 0.8 and 0.2. In reality these would be probabilities, which they are not here, and we would them to be 1 and 0)
*   We know the numbers we want in the output layer, and the numbers we are getting from the randomly selected parameters (which are different from what we want). So for all the neurons in the output layer, let’s take the difference between the number we want and the number we have. Then add up the differences. E.g., if the output layer is 0.6 and 0.4 in the two neurons, then we get: (0.8–0.6)=0.2 and (0.2–0.4)= -0.2 so we get a total of 0.4 (ignoring minus signs before adding). We can call this our “**loss**”. Ideally we want the loss to be close to zero, i.e. we want to “**minimize the loss**”.
*   Once we have the loss, we can slightly change each parameter to see if increasing or decreasing it will increase the loss or decrease it. This is called the “**gradient**” of that parameter. Then we can move each of the parameters by a small amount in the direction where the loss goes down (the direction of the gradient). Once we have moved all the parameters slightly, the loss should be lower
*   Keep repeating the process and you will reduce the loss, and eventually have a set of weights/parameters that are “**trained**”. This whole process is called “**gradient descent**”.

Couple of notes:

*   You often have multiple training examples, so when you change the weights slightly to minimize the loss for one example it might make the loss worse for another example. The way to deal with this is to define loss as average loss over all the examples and then take gradient over that average loss. This reduces the average loss over the entire training data set. Each such cycle is called an “**epoch**”. Then you can keep repeating the epochs thus finding weights that reduce average loss.
*   We don’t actually need to “move weights around” to calculate the gradient for each weight — we can just infer it from the formula (e.g. if the weight is 0.17 in the last step, and the value of neuron is positive, and we want a larger number in output we can see that increasing this number to 0.18 will help).

In practice, training deep networks is a hard and complex process because gradients can easily spiral out of control, going to zero or infinity during training (called “vanishing gradient” and “exploding gradient” problems). The simple definition of loss that we talked about here is perfectly valid, but rarely used as there are better functional forms that work well for specific purposes. With modern models containing billions of parameters, training a model requires massive compute resources which has its own problems (memory limitations, parallelization etc.)

How does all this help generate language?
-----------------------------------------

Remember, neural nets take in some numbers, do some math based on the trained parameters, and give out some other numbers. Everything is about interpretation and training the parameters (i.e. setting them to some numbers). If we can interpret the two numbers as “leaf/flower” or “rain or sun in an hour”, we can also interpret them as “next character in a sentence”.

But there are more than 2 letters in English, and so we must expand the number of neurons in the output layer to, say, the 26 letters in the English language (let’s also throw in some symbols like space, period etc..). Each neuron can correspond to a character and we look at the (26 or so) neurons in the output layer and say that the character corresponding to the highest numbered neuron in the output layer is the output character. Now we have a network that can take some inputs and output a character.

What if we replace the input in our network with these characters: “Humpty Dumpt” and asked it to output a character and interpreted it as the “Network’s suggestion of the next character in the sequence that we just entered”. We can probably set the weights well enough for it to output “y” — thereby completing “Humpty Dumpty”. Except for one problem, how do we input these lists of characters in the network? Our network only accepts numbers!!

One simple solution is to assign a number to each character. Let’s say a=1, b=2 and so on. Now we can input “humpty dumpt” and train it to give us “y”. Our network looks something like this:

![Image 5: a diagram showing the different types of networks](https://miro.medium.com/v2/resize:fit:700/1*XPyJ-V0vbPv6EDwFpk7KYQ.png)

Image by author

Ok, so now we can predict one character ahead by providing the network a list of characters. We can use this fact to build a whole sentence. For example, once we have the “y” predicted, we can append that “y” to the list of characters we have and feed it to the network and ask it to predict the next character. And if well trained it should give us a space, and so on and so forth. By the end, we should be able to recursively generate “Humpty Dumpty sat on a wall”. We have Generative AI. Moreover, **_we now have a network capable of generating language!_** Now, nobody ever actually puts in randomly assigned numbers and we will see more sensible schemes down the line. If you cannot wait, feel free to check out the one-hot encoding section in the appendix.

Astute readers will note that we can’t actually input “Humpty Dumpty” into the network since the way the diagram is, it only has 12 neurons in the input layer one for each character in “humpty dumpt” (including the space). So how can we put in the “y” for the next pass. Putting a 13th neuron there would require us to modify the entire network, that’s not workable. The solution is simple, let’s kick the “h” out and send the 12 most recent characters. So we would be sending “umpty dumpty” and the network will predict a space. Then we would input “mpty dumpty “ and it will produce an s and so on. It looks something like this:

![Image 6: a diagram showing the different types of inputs](https://miro.medium.com/v2/resize:fit:700/1*0_tSCfEAL9NIK8U95Q-6Vg.png)

Image by author

We’re throwing away a lot of information in the last line by feeding the model only “ sat on the wal”. So what do the latest and greatest networks of today do? More or less exactly that. The length of inputs we can put into a network is fixed (determined by the size of the input layer). This is called “context length” — the context that is provided to the network to make future predictions. Modern networks can have very large context lengths (several thousand words) and that helps. There are some ways of inputting infinite length sequences but the performance of those methods, while impressive, has since been surpassed by other models with large (but fixed) context length.

One other thing careful readers will notice is that we have different interpretations for inputs and outputs for the same letters! For example, when inputting “h” we are simply denoting it with the number 8 but on the output layer we are not asking the model to output a single number (8 for “h”, 9 for “i” and so on..) instead we are are asking the model to output 26 numbers and then we see which one is the highest and then if the 8th number is highest we interpret the output as “h”. Why don’t we use the same, consistent, interpretation on both ends? We could, it’s just that in the case of language, freeing yourself to choose between different interpretations gives you a better chance of building better models. And it just so happens that the most effective currently known interpretations for the input and output are different. In-fact, the way we are inputting numbers in this model is not the best way to do it, we will look at better ways to do that shortly.

What makes large language models work so well?
----------------------------------------------

Generating “Humpty Dumpty sat on a wall” character-by-character is a far cry from what modern LLMs can do. There are a number of differences and innovations that get us from the simple generative AI that we discussed above to the human-like bot. Let’s go through them:

Embeddings
----------

Remember we said that the way that we are inputting characters into the model isn’t the best way to do it. We just arbitrarily selected a number for each character. What if there were better numbers we could assign that would make it possible for us to train better networks? How do we find these better numbers? Here’s a clever trick:

When we trained the models above, the way we did it was by moving around weights and seeing that gives us a smaller loss in the end. And then slowly and recursively changing the weights. At each turn we would:

*   Feed in the inputs
*   Calculate the output layer
*   Compare it to the output we ideally want and calculate the average loss
*   Adjust the weights and start again

In this process, the inputs are fixed. This made sense when inputs were (RGB, Vol). But the numbers we are putting in now for a,b,c etc.. are arbitrarily picked by us. What if at every iteration in addition to moving the weights around by a bit we also moved the input around and see if we can get a lower loss by using a different number to represent “a” and so on? We are definitely reducing the loss and making the model better (that’s the direction we moved a’s input in, by design). Basically, apply gradient descent not just to the weights but also the number representations for the inputs since they are arbitrarily picked numbers anyway. This is called an “**embedding**”. It is a mapping of inputs to numbers, and as you just saw, it needs to be trained. The process of training an embedding is much like that of training a parameter. One big advantage of this though is that once you train an embedding you can use it in another model if you wish. Keep in mind that you will consistently use the same embedding to represent a single token/character/word.

We talked about embeddings that are just one number per character. However, in reality embeddings have more than one number. That’s because it is hard to capture the richness of concept by a single number. If we look at our leaf and flower example, we have four numbers for each object (the size of the input layer). Each of these four numbers conveyed a property and the model was able to use all of them to effectively guess the object. If we had only one number, say the red channel of the color, it might have been a lot harder for the model. We’re trying to capture human language here — we’re going to need more than one number.

So instead of representing each character by a single number, maybe we can represent it by multiple numbers to capture the richness? Let’s assign a bunch of numbers to each character. Let’s call an ordered collection of numbers a “vector” (ordered as in each number has a position, and if we swap position of two numbers it gives us a different vector. This was the case with our leaf/flower data, if we swapped the R and G numbers for the leaf, we would get a different color, it would not be the same vector anymore). The length of a vector is simply how many numbers it contains. We’ll assign a vector to each character. Two questions arise:

*   If we have a vector assigned to each character instead of a number, how do we now feed “humpty dumpt” to the network? The answer is simple. Let’s say we assigned a vector of 10 numbers to each character. Then instead of the input layer having 12 neurons we would just put 120 neurons there since each of the 12 characters in “humpty dumpt” has 10 numbers to input. Now we just put the neurons next to each other and we are good to go
*   How do we find these vectors? Thankfully, we just learned how to train embedding numbers. Training an embedding vector is no different. You now have 120 inputs instead of 12 but all you are doing is moving them around to see how you can minimize loss. And then you take the first 10 of those and that’s the vector corresponding to “h” and so on.

All the embedding vectors must of course be the same length, otherwise we would not have a way of entering all the character combinations into the network. E.g. “humpty dumpt” and in the next iteration “umpty dumpty” — in both cases we are entering 12 characters in the network and if each of the 12 characters was not represented by vectors of length 10 we won’t be able to reliably feed them all into a 120-long input layer. Let’s visualize these embedding vectors:

![Image 7: a diagram showing the different numbers of the number of rows](https://miro.medium.com/v2/resize:fit:421/1*lZOR8fNDEWHxUhLCSB-67A.png)

Image by author

Let’s call an ordered collection of same-sized vectors a matrix. This matrix above is called an **embedding matrix**. You tell it a column number corresponding to your letter and looking at that column in the matrix will give you the vector that you are using to represent that letter. This can be applied more generally for embedding any arbitrary collection of things — you would just need to have as many columns in this matrix as the things you have.

Subword Tokenizers
------------------

So far, we have been working with characters as the basic building blocks of language. This has its limitations. The neural network weights have to do a lot of the heavy lifting where they must make sense of certain sequences of characters (i.e. words) appearing next to each other and then next to other words. What if we directly assigned embeddings to words and made the network predict the next word. The network doesn’t understand anything more than numbers anyway, so we can assign a 10-length vector to each of the words “humpty”, “dumpty”, “sat”, “on” etc.. and then we just feed it two words and it can give us the next word. “**Token**” is the term for a single unit that we embed and then feed to the model. Our models so far were using characters as tokens, now we are proposing to use entire words as a token (you can of course use entire sentences or phrases as tokens if you like).

Using word tokenization has one profound effect on our model. There are more than 180K words in the English language. Using our output interpretation scheme of having a neuron per possible output we need hundreds of thousands of neurons in the output layer insead of the 26 or so. With the size of the hidden layers needed to achieve meaningful results for modern networks, this issue becomes less pressing. What is however worth noting is that since we are treating each word separately, and we are starting with a random number embeddings for each — very similar words (e.g. “cat” and “cats”) will start with no relationship. You would expect that embeddings for the two words should be close to each other — which undoubtedly the model will learn. But, can we somehow use this obvious similarity to get a jumpstart and simplify matters?

Yes we can. The most common embedding scheme in language models today is something where you break words down into subwords and then embed them. In the cat example, we would break down cats into two tokens “cat” and ”s”. Now it is easier for the model to understand the concept of “s” followed by other familiar words and so on. This also reduces the number of tokens we need ([sentencpiece](https://github.com/google/sentencepiece) is a common tokenizer with vocab size options in tens of thousands vs hundreds of thousands of words in english). A tokenizer is something that takes you input text (e.g. “Humpty Dumpt”) and splits it into the tokens and gives you the corresponding numbers that you need to look up the embedding vector for that token in the embedding matrix. For example, in case of “humpty dumpty” if we’re using character level tokenizer and we arranged our embedding matrix as in the picture above, then the tokenizer will first split humpty dumpt into characters \[‘h’,’u’,…’t’\] and then give you back the numbers \[8,21,…20\] because you need to look up the 8th column of the embedding matrix to get the embedding vector for ‘h’ (embedding vector is what you will feed into the model, not the number 8, unlike before). The arrangement of the columns in the matrix is completely irrelevant, we could assign any column to ‘h’ and as long as we look up the same vector every time we input ‘h’ we should be good. Tokenizers just give us an arbitrary (but fixed) number to make lookup easy. The main task we need them for really is splitting the sentence in tokens.

With embeddings and subword tokenization, a model could look something like this:

![Image 8: a diagram showing the different types of networks](https://miro.medium.com/v2/resize:fit:700/1*VGNZ1Zighiek1sAMdiZCaw.png)

Image by author

The next few sections deal with more recent advances in language modeling, and the ones that made LLMs as powerful as they are today. However, to understand these there are a few basic math concepts you need to know. Here are the concepts:

*   Matrices and matrix multiplication
*   General concept of functions in mathematics
*   Raising numbers to powers (e.g. a3 = a\*a\*a)
*   Sample mean, variance, and standard deviation

I have added summaries of these concepts in the appendix.

Self Attention
--------------

So far we have seen only one simple neural network structure (called feedforward network), one which contains a number of layers and each layer is fully connected to the next (i.e., there is a line connecting any two neurons in consecutive layers), and it is only connected to the next layer (e.g. no lines between layer 1 and layer 3 etc..). However, as you can imagine there is nothing stopping us from removing or making other connections. Or even making more complex structures. Let’s explore a particularly important structure: self-attention.

If you look at the structure of human language, the next word that we want to predict will depend on all the words before. However, they may depend on some words before them to a greater degree than others. For example, if we are trying to predict the next word in “Damian had a secret child, a girl, and he had written in his will that all his belongings, along with the magical orb, will belong to \_\_\_\_”. This word here could be “her” or “him” and it depends specifically on a much earlier word in the sentence: _girl/boy_.

The good news is, our simple feedforward model connects to all the words in the context, and so it can learn the appropriate weights for important words, But here’s the problem, the weights connecting specific positions in our model through feed forward layers are fixed (for every position). If the important word was always in the same position, it would learn the weights appropriately and we would be fine. However, the relevant word to the next prediction could be anywhere in the system. We could paraphrase that sentence above and when guessing “her vs his”, one very important word for this prediction would be boy/girl no matter where it appeared in that sentence. So, we need weights that depend not only on the position but also on the content in that position. How do we achieve this?

Self attention does something like adding up the embedding vectors for each of the words, but instead of directly adding them up it applies some weights to each. So if the embedding vectors for humpty,dumpty, sat are x1, x2, x3 respectively, then it will multiply each one with a weight (a number) before adding them up. Something like output = 0.5 x1 + 0.25 x2 + 0.25 x3 where output is the self-attention output. If we write the weights as u1, u2, u3 such that output = u1x1+u2x2+u3x3 then how do we find these weights u1, u2, u3?

Ideally, we want these weights to be dependent on the vector we are adding — as we saw some may be more important than others. But important to whom? To the word we are about to predict. So we also want the weights to depend on the word we are about to predict. Now that’s an issue, we of course don’t know the word we are about to predict before we predict it. So, self attention uses the word immediately preceding the word we are about to predict, i.e., the last word in the sentence available (I don’t really know why this and why not something else, but a lot of things in deep learning are trial and error and I suspect this works well).

Great, so we want weights for these vectors, and we want each weight to depend on the word that we are aggregating and word immediately preceding the one we are going to predict. Basically, we want a function u1 = F(x1, x3) where x1 is the word we will weight and x3 is the last word in the sequence we have (assuming we have only 3 words). Now, a straightforward way of achieving this is to have a vector for x1 (let’s call it k1) and a separate vector for x3 (let’s call it q3) and then simply take their dot product. This will give us a number and it will depend on both x1 and x3. How do we get these vectors k1 and q3? We build a tiny single layer neural network to go from x1 to k1 (or x2 to k2, x3 to k3 and so on). And we build another network going from x3 to q3 etc… Using our matrix notation, we basically come up with weight matrices Wk and Wq such that k1 = Wkx1 and q1 =Wqx1 and so on. Now we can take a dot product of k1 and q3 to get a scalar, so u1 = F(x1,x3) = Wkx1 **·** Wqx3.

One additional thing that happens in self-attention is that we don’t directly take the weighted sum of the embedding vectors themselves. Instead, we take the weighted sum of some “value” of that embedding vector, which is obtained by another small single layer network. What this means is similar to k1 and q1, we also now have a v1 for the word x1 and we obtain it through a matrix Wv such that v1=Wvx1. This v1 is then aggregated. So it all looks something like this if we only have 3 words and we are trying to predict the fourth:

![Image 9: self-adjusted outputs with a humpy](https://miro.medium.com/v2/resize:fit:700/1*oETLwMpxy3oH_B9pN-xLcg.png)

Self attention. Image by author

The plus sign represents a simple addition of the vectors, implying they have to have the same length. One last modification not shown here is that the scalars u1, u2, u3 etc.. won’t necessarily add up to 1. If we need them to be weights, we should make them add up. So we will apply a familiar trick here and use the softmax function.

This is self-attention. There is also cross-attention where you can have the q3 come from the last word, but the k’s and the v’s can come from another sentence altogether. This is for example valuable in translation tasks. Now we know what attention is.

This whole thing can now be put in a box and be called a “self attention block”. Basically, this self attention block takes in the embedding vectors and spits out a single output vector of any user-chosen length. This block has three parameters, Wk,Wq,Wv — it doesn’t need to be more complicated than that. There are many such blocks in the machine learning literature, and they are usually represented by boxes in diagrams with their name on it. Something like this:

![Image 10: a diagram showing the different types of blocks](https://miro.medium.com/v2/resize:fit:700/1*OgcRxWyftIXN8WbQw_-QKg.png)

Image by author

One of the things that you will notice with self-attention is that the position of things so far does not seem relevant. We are using the same W’s across the board and so switching Humpty and Dumpty won’t really make a difference here — all numbers will end up being the same. This means that while attention can figure out what to pay attention to, this won’t depend on word position. However, we do know that word positions are important in english and we can probably improve performance by giving the model some sense of a word’s position.

And so, when attention is used, we don’t often feed the embedding vectors directly to the self attention block. We will later see how “positional encoding” is added to embedding vectors before feeding to attention blocks.

_Note for the pre-initiated_: Those for whom this isn’t the first time reading about self-attention will note that we are not referencing any K and Q matrices, or applying masks etc.. That is because those things are implementation details arising out of how these models are commonly trained. A batch of data is fed and the model is simultaneously trained to predict dumpty from humpty, sat from humpty dumpty and so on. This is a matter of gaining efficiency and does not affect interpretation or even model outputs, and we have chosen to omit training efficiency hacks here.

Softmax
-------

We talked briefly about softmax in the very first note. Here’s the problem softmax is trying to solve: In our output interpretation we have as many neurons as the options from which we want the network to select one. And we said that we are going to interpret the network’s choice as the highest value neuron. Then we said we are going to calculate loss as the difference between the value that network provides, and an ideal value we want. But what’s that ideal value we want? We set it to 0.8 in the leaf/flower example. But why 0.8? Why no 5, or 10, or 10 million? The higher the better for that training example. Ideally we want infinity there! Now that would make the problem intractable — all loss would be infinite and our plan of minimizing loss by moving around parameters (remember “gradient descent”) fails. How do we deal with this?

One simple thing we can do is cap the values we want. Let’s say between 0 and 1? This would make all loss finite, but now we have the issue of what happens when the network overshoots. Let’s say it outputs (5,1) for (leaf,flower) in one case, and (0,1) in another. The first case made the right choice but the loss is worse! Ok, so now we need a way to also convert the outputs of the last layer in (0,1) range so that it preserves the order. We could use any function (a “**function**” in mathematics is simply a mapping of one number to another — in goes one number, out comes another — it’s rule based in terms of what will be output for a given input) here to get the job done. One possible option is the logistic function (see graph below) which maps all numbers to numbers between (0,1) and preserves the order:

![Image 11: linear function for h - i](https://miro.medium.com/v2/resize:fit:700/1*jSyo_owKB-tfTrPXV2giKg.png)

Image by author

Now, we have a number between 0 and 1 for each of the neurons in the last layer and we can calculate loss by setting the correct neuron to 1, others to 0 and taking the difference of that from what the network provides us. This will work, but can we do better?

Going back to our “Humpty dumpty” example, let’s say we are trying to generate dumpty character-by-character and our model makes a mistake when predicting “m” in dumpty. Instead of giving us the last layer with “m” as the highest value, it gives us “u” as the highest value but “m” is a close second.

Now we can continue with “duu” and try to predict next character and so on, but the model confidence will be low because there are not that many good continuations from “humpty duu..”. On the other hand, “m” was a close second, so we can also give “m” a shot, predict the next few characters, and see what happens? Maybe it gives us a better overall word?

So what we are talking about here is not just blindly selecting the max value, but trying a few. What’s a good way to do it? Well we have to assign a chance to each one — say we will pick the top one with 50%, second one with 25% and so on. That’s a good way to do it. But maybe we would want the chance to be dependent on the underlying model predictions. If the model predicts values for m and u to be really close to each other here (compared to other values) — then maybe a close 50–50 chance of exploring the two is a good idea?

So we need a nice rule that takes all these numbers and converts them into chances. That’s what softmax does. It is a generalization of the logistic function above but with additional features. If you give it 10 arbitrary numbers — it will give you 10 outputs, each between 0 and 1 and importantly, all 10 adding up to 1 so that we can interpret them as chance. You will find softmax as the last layer in nearly every language model.

Residual connections
--------------------

We have slowly changed our visualization of networks as the sections progress. We are now using boxes/blocks to denote certain concepts. This notation is useful in denoting a particularly useful concept of residual connections. Let’s look at residual connection combined with a self-attention block:

![Image 12: a diagram of a self-blocking system](https://miro.medium.com/v2/resize:fit:700/1*270MXDfslVtvmBjShHL2hQ.png)

A residual connection. Image by author

Note that we put “Input” and “Output” as boxes to make things simpler, but these are still basically just a collection of neurons/numbers same as shown above.

So what’s going on here? We are basically taking the output of self-attention block and before passing it to the next block, we are adding to it the original Input. First thing to note is that this would require that the dimensions of the self-attention block output must now be the same as that of the input. This is not a problem since as we noted the self-attention output is determined by the user. But why do this? We won’t get into all the details here but the key thing is that as networks get deeper (more layers between input and output) it gets increasingly harder to train them. Residual connections have been shown to help with these training challenges.

Layer Normalization
-------------------

Layer normalization is a fairly simple layer that takes the data coming into the layer and normalizes it by subtracting the mean and dividing it by standard deviation (maybe a bit more, as we see below). For example, if we were to apply layer normalization immediately after the input, it would take all the neurons in the input layer and then it would calculate two statistics: their mean and their standard deviation. Let’s say the mean is M and the standard deviation is S then what layer norm is doing is taking each of these neurons and replacing it with (x-M)/S where x denotes any given neuron’s original value.

Now how does this help? It basically stabilizes the input vector and helps with training deep networks. One concern is that by normalizing inputs, are we removing some useful information from them that may be helpful in learning something valuable about our goal? To address this, the layer norm layer has a scale and a bias parameter. Basically, for each neuron you just multiply it with a scalar and then add a bias to it. These scalar and bias values are parameters that can be trained. This allows the network to learn some of the variation that may be valuable to the predictions. And since these are the only parameters, the LayerNorm block doesn’t have a lot of parameters to train. The whole thing looks something like this:

![Image 13: a diagram of a layer nomination block](https://miro.medium.com/v2/resize:fit:700/1*Zd-PvX2cYslEyrjL6MVnzA.png)

Layer Normalization. Image by author

The Scale and Bias are trainable parameters. You can see that layer norm is a relatively simple block where each number is only operated on pointwise (after the initial mean and std calculation). Reminds us of the activation layer (e.g. RELU) with the key difference being that here we have some trainable parameters (albeit lot fewer than other layers because of the simple pointwise operation).

Standard deviation is a statistical measure of how spread out the values are, e.g., if the values are all the same you would say the standard deviation is zero. If, in general, each value is really far from the mean of these very same values, then you will have a high standard deviation. The formula to calculate standard deviation for a set of numbers, a1, a2, a3…. (say N numbers) goes something like this: subtract the mean (of these numbers) from each of the numbers, then square the answer for each of N numbers. Add up all these numbers and then divide by N. Now take a square root of the answer.

Note for the pre-initiated: Experienced ML professionals will note that there is no discussion of batch norm here. In-fact, we haven’t even introduced the concept of batches in this article at all. For the most part, I believe batches are another training accelerant not related to the understanding of core concepts (except perhaps batch norm which we do not need here).

Dropout
-------

Dropout is a simple but effective method to avoid model overfitting. Overfitting is a term for when you train the model on your training data, and it works well on that dataset but does not generalize well to the examples the model has not seen. Techniques that help us avoid overfitting are called “**regularization techniques**”, and dropout is one of them.

If you train a model, it might make errors on the data and/or overfit it in a particular way. If you train another model, it might do the same, but in a different way. What if you trained a number of these models and averaged the outputs? These are typically called “**ensemble** **models**” because they predict the outputs by combining outputs from an ensemble of models, and ensemble models generally perform better than any of the individual models.

In neural networks, you could do the same. You could build multiple (slightly different) models and then combine their outputs to get a better model. However, this can be computationally expensive. Dropout is a technique that doesn’t quite build ensemble models but does capture some of the essence of the concept.

The concept is simple, by inserting a dropout layer during training what you are doing is randomly deleting a certain percentage of the direct neuron connections between the layers that dropout is inserted. Considering our initial network and inserting a Dropout layer between the input and the middle layer with 50% dropout rate can look something like this:

![Image 14: a diagram of a sunflower and a sunflower](https://miro.medium.com/v2/resize:fit:700/1*j0oKuXvH7kfrIpIfXE03VA.png)

![Image 15: a diagram showing the arrow pointing to the right](https://miro.medium.com/v2/resize:fit:700/1*UodvtsDn5z73Cp578XOoVw.png)

![Image 16: a diagram of a sunflower and its leaves](https://miro.medium.com/v2/resize:fit:700/1*qHPSwQmV3sfvKT5pG4TEJw.png)

Image by author

Now, this forces the network to train with a lot of redundancy. Essentially, you are training a number of different models at the same time — but they share weights.

Now for making inferences, we could follow the same approach as an ensemble model. We could make multiple predictions using dropouts and then combine them. However, since that is computationally intensive — and since our models share common weights — why don’t we just do a prediction using all the weights (so instead of using 50% of the weights at a time we use all at the same time). This should give us some approximation of what an ensemble will provide.

One issue though: the model trained with 50% of the weights will have very different numbers in the middle neurons than one using all the weights. What we want is more ensemble style averaging here. How do we do this? Well, a simple way is to simply take all the weights and multiply them by 0.5 since we are now using twice as many weights. This is what Droput does during inference. It will use the full network with all the weights and simply multiply the weights with (1- p) where p is the deletion probability. And this has been shown to work rather well as a regularization technique.

Multi-head Attention
--------------------

This is the key block in the transformer architecture. We’ve already seen what an attention block is. Remember that the output of an attention block was determined by the user and it was the length of v’s. What a multi-attention head is basically you run several attention heads in parallel (they all take the same inputs). Then we take all their outputs and simply concatenate them. It looks something like this:

![Image 17: a diagram showing the different types of data](https://miro.medium.com/v2/resize:fit:700/1*BmZd8SIDEQu7r5_R7y54kQ.png)

Multi-head attention. Image by author

Keep in mind the arrows going from v1 -\> v1h1 are linear layers — there’s a matrix on each arrow that transforms. I just did not show them to avoid clutter.

What is going on here is that we are generating the same key, query and values for each of the heads. But then we are basically applying a linear transformation on top of that (separately to each k,q,v and separately for each head) before we use those k,q,v values. This extra layer did not exist in self attention.

A side note is that to me, this is a slightly surprising way of creating a multi-headed attention. For example, why not create separate Wk,Wq,Wv matrices for each of the heads rather than adding a new layer and sharing these weights. Let me know if you know — I really have no idea.

Positional encoding and embedding
---------------------------------

We briefly talked about the motivation for using positional encoding in the self-attention section. What are these? While the picture shows positional encoding, using a positional embedding is more common than using an encoding. As such we talk about a common positional embedding here but the appendix also covers positional encoding used in the original paper. A positional embedding is no different than any other embedding except that instead of embedding the word vocabulary we will embed numbers 1, 2, 3 etc. So this embedding is a matrix of the same length as word embedding, and each column corresponds to a number. That’s really all there is to it.

The GPT architecture
--------------------

Let’s talk about the GPT architecture. This is what is used in most GPT models (with variation across). If you have been following the article thus far, this should be fairly trivial to understand. Using the box notation, this is what the architecture looks like at high level:

![Image 18: a diagram of a process for a transducer](https://miro.medium.com/v2/resize:fit:700/0*U9mQKCWiyakNVwxU)

The GPT Architecture. Image by author

At this point, other than the “GPT Transformer Block” all the other blocks have been discussed in great detail. The + sign here simply means that the two vectors are added together (which means the two embeddings must be the same size). Let’s look at this GPT Transformer Block:

![Image 19: the transformation book for gtf](https://miro.medium.com/v2/resize:fit:700/1*Mq4hBZcKPL9GALPSSQG9Xg.png)

And that’s pretty much it. It is called “transformer” here because it is derived from and is a type of transformer — which is an architecture we will look at in the next section. This doesn’t affect understanding as we’ve already covered all the building blocks shown here before. Let’s recap everything we’ve covered so far building up to this GPT architecture:

*   We saw how neural nets take numbers and output other numbers and have weights as parameters which can be trained
*   We can attach interpretations to these input/output numbers and give real world meaning to a neural network
*   We can chain neural networks to create bigger ones, and we can call each one a “block” and denote it with a box to make diagrams easier. Each block still does the same thing, take in a bunch of numbers and output other bunch of numbers
*   We learned a lot of different types of blocks that serve different purposes
*   GPT is just a special arrangement of these blocks that is shown above with an interpretation that we discussed in Part 1

Modifications have been made over time to this as companies have built up to powerful modern LLMs, but the basic remains the same.

Now, this GPT transformer is actually what is called a “decoder” in the original transformer paper that introduced the transformer architecture. Let’s take a look at that.

The transformer architecture
----------------------------

This is one of the key innovations driving rapid acceleration in the capabilities of language models recently. Transformers not only improved the prediction accuracy, they are also easier/more efficient than previous models (to train), allowing for larger model sizes. This is what the GPT architecture above is based on.

If you look at GPT architecture, you can see that it is great for generating the next word in the sequence. It fundamentally follows the same logic we discussed in Part 1. Start with a few words and then continue generating one at a time. But, what if you wanted to do translation. What if you had a sentence in german (e.g. “Wo wohnst du?” = “Where do you live?”) and you wanted to translate it to english. How would we train the model to do this?

Well, first thing we would need to do is figure out a way to input german words. Which means we have to expand our embedding to include both german and english. Now, I guess here is a simply way of inputting the information. Why don’t we just concatenate the german sentence at the beginning of whatever so far generated english is and feed it to the context. To make it easier for the model, we can add a separator. This would look something like this at each step:

![Image 20: a diagram showing the different ways to say the word](https://miro.medium.com/v2/resize:fit:700/1*psIz3-v2dMfI3SMsFQjRPQ.png)

Image by author

This will work, but it has room for improvement:

*   If the context length is fixed, sometimes the original sentence is lost
*   The model has a lot to learn here. Two languages simultaneously, but also to know that <SEP\> is the separator token where it needs to start translating
*   You are processing the entire german sentence, with different offsets, for each word generation. This means there will be different internal representations of the same thing and the model should be able to work through it all for translation

Transformer was originally created for this task and consists of an “encoder” and a “decoder” — which are basically two separate blocks. One block simply takes the german sentence and gives out an intermediate representation (again, bunch of numbers, basically) — this is called the encoder.

The second block generates words (we’ve seen a lot of this so far). The only difference is that in addition to feeding it the words generated so far we also feed it the encoded german (from the encoder block) sentence. So as it is generating language, it’s context is basically all the words generated so far, plus the german. This block is called the decoder.

Each of these encoders and decoders consist of a few blocks, notably the attention block sandwiched between other layers. Let’s look at the illustration of a transformer from the paper “Attention is all you need” and try to understand it:

![Image 21: a diagram showing the process of a video processing system](https://miro.medium.com/v2/resize:fit:683/1*uPwJ24na4D_ECHBv1Lg5Fg.png)

Image from Vaswani et al. (2017)

The vertical set of blocks on the left is called the “encoder” and the ones to the right is called the “decoder”. Let’s go over and understand anything that we have not already covered before:

_Recap on how to read the diagram:_ Each of the boxes here is a block that takes in some inputs in the form of neurons, and spits out a set of neurons as output that can then either be processed by the next block or interpreted by us. The arrows show where the output of a block is going. As you can see, we will often take the output of one block and feed it in as input into multiple blocks. Let’s go through each thing here:

Feed forward: A feedforward network is one that does not contain cycles. Our original network in section 1 is a feed forward. In-fact, this block uses very much the same structure. It contains two linear layers, each followed by a RELU (see note on RELU in first section) and a dropout layer. Keep in mind that this feedforward neetwork applies to each position independently. What this means is that the information on position 0 has a feedforward network, and on position 1 has one and so on.. But the neurons from position x do not have a linkage to the feedforward network of position y. This is important because if we did not do this, it would allow the network to cheat during training time by looking forward.

_Cross-attention:_ You will notice that the decoder has a multi-head attention with arrows coming from the encoder. What is going on here? Remember the value, key, query in self-attention and multi-head attention? They all came from the same sequence. The query was just from the last word of the sequence in-fact. So what if we kept the query but fetched the value and key from a completely different sequence altogether? That is what is happening here. The value and key come from the output of the encoder. Nothing has changed mathematically except where the inputs for key and value are coming from now.

_Nx_: The Nx here simply represents that this block is chain-repeated N times. So basically you are stacking the block back-to-back and passing the input from the previous block to the next one. This is a way to make the neural network deeper. Now, looking at the diagram there is room for confusion about how the encoder output is fed to the decoder. Let’s say N=5. Do we feed the output of each encoder layer to the corresponding decoder layer? No. Basically you run the encoder all the way through once and only once. Then you just take that representation and feed the same thing to every one of the 5 decoder layers.

_Add & Norm block_: This is basically the same as below (guess the authors were just trying to save space)

![Image 22: layer norm diagram](https://miro.medium.com/v2/resize:fit:681/0*sXvYIassJutgqw5W)

Image by author

Everything else has already been discussed. Now you have a complete explanation of the transformer architecture building up from simple sum and product operations and fully self contained! You know what every line, every sum, every box and word means in terms of how to build them from scratch. Theoretically, these notes contain what you need to code up the transformer from scratch. In-fact, if you are interested [this repo](https://github.com/karpathy/nanoGPT) does that for the GPT architecture above.

Appendix
--------

Matrix Multiplication
---------------------

We introduced vectors and matrices above in the context of embeddings. A matrix has two dimensions (number or rows and columns). A vector can also be thought of as a matrix where one of the dimensions equals one. Product of two matrices is defined as:

![Image 23: a diagram showing the structure of a dna](https://miro.medium.com/v2/resize:fit:700/0*woel5Da5Z22EmiGx)

Image by author

Dots represent multiplication. Now let’s take a second look at the calculation of blue and organic neurons in the very first picture. If we write the weights as a matrix and the inputs as vectors, we can write the whole operation in the following way:

![Image 24: a diagram showing the number of numbers in a matrix](https://miro.medium.com/v2/resize:fit:466/0*yn1TPuxw_QqnD93k)

Image by author

If the weight matrix is called “W” and the inputs are called “x” then Wx is the result (the middle layer in this case). We can also transpose the two and write it as xW — this is a matter of preference.

Standard deviation
------------------

We use the concept of standard deviation in the Layer Normalization section. Standard deviation is a statistical measure of how spread out the values are (in a set of numbers), e.g., if the values are all the same you would say the standard deviation is zero. If, in general, each value is really far from the mean of these very same values, then you will have a high standard deviation. The formula to calculate standard deviation for a set of numbers, a1, a2, a3…. (say N numbers) goes something like this: subtract the mean (of these numbers) from each of the numbers, then square the answer for each of N numbers. Add up all these numbers and then divide by N. Now take a square root of the answer.

Positional Encoding
-------------------

We talked about positional embedding above. A positional encoding is simply a vector of the same length as the word embedding vector, except it is not an embedding in the sense that it is not trained. We simply assign a unique vector to every position e.g. a different vector for position 1 and different one for position 2 and so on. A simple way of doing this is to make the vector for that position simply full of the position number. So the vector for position 1 would be \[1,1,1…1\] for 2 would be \[2,2,2…2\] and so on (remember length of each vector must match embedding length for addition to work). This is problematic because we can end up with large numbers in vectors which creates challenges during training. We can, of course, normalize these vectors by dividing every number by the max of position, so if there are 3 words total then position 1 is \[.33,.33,..,.33\] and 2 is \[.67, .67, ..,.67\] and so on. This has the problem now that we are constantly changing the encoding for position 1 (those numbers will be different when we feed 4 word sentence as input) and it creates challenges for the network to learn. So here, we want a scheme that allocates a unique vector to each position, and the numbers don’t explode. Basically if the context length is d (i.e., maximum number of tokens/words that we can feed into the network for predicting next token/word, see discussion in “how does it all generate language?” section) and if the length of the embedding vector is 10 (say), then we need a matrix with 10 rows and d columns where all the columns are unique and all the numbers lie between 0 and 1. Given that there are infinitely many numbers between zero and 1, and the matrix is finitely sized, this can be done in many ways.

The approach used in the “Attention is all you need” paper goes something like this:

*   Draw 10 sin curves each being si(p) = sin (p/10000(i/d)) (that’s 10k to power i/d)
*   Fill the encoding matrix with numbers such that (i,p)th number is si(p), e.g., for position 1 the 5th element of the encoding vector is s5(1)=sin (1/10000(5/d))

Why choose this method? By changing the power on 10k you are changing the amplitude of the sine function when viewed on the p-axis. And if you have 10 different sine functions with 10 different amplitudes, then it will be a long time before you get a repetition (i.e. all 10 values are the same) for changing values of p. And this helps give us unique values. Now, the actual paper uses both sine and cosine functions and the form of encoding is: si(p) = sin (p/10000(i/d)) if i is even and si(p) = cos(p/10000(i/d)) if i is odd.


## Visual Content Analysis

### Image Analysis
Title: LLMs from Scratch Using Middle School Math | Towards Data Science

URL Source: https://medium.com/towards-data-science/understanding-llms-from-scratch-using-middle-school-math-e602d27ec876

Markdown Content:
A self-contained, full explanation to inner workings of an LLM
--------------------------------------------------------------

[![Image 1: Rohit Patel](https://miro.medium.com/v2/resize:fill:88:88/1*ECmWr6Z-ToM5JE-h8ywyLQ.jpeg)](https://rohit-patel.medium.com/?source=post_page---byline--e602d27ec876--------------------------------)

[![Image 2: Towards Data Science](https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg)](https://towardsdatascience.com/?source=post_page---byline--e602d27ec876--------------------------------)

In this article, we talk about how Large Language Models (LLMs) work, from scratch — assuming only that you know how to add and multiply two numbers. The article is meant to be fully self-contained. We start by building a simple Generative AI on pen and paper, and then walk through everything we need to have a firm understanding of modern LLMs and the Transformer architecture. The article will strip out all the fancy language and jargon in ML and represent everything simply as they are: numbers. We will still call out what things are called to tether your thoughts when you read jargon-y content.

Going from addition/multiplication to the most advanced AI models today without assuming other knowledge or referring to other sources means we cover a LOT of ground. This is NOT a toy LLM explanation — a determined person can theoretically recreate a modern LLM from all the information here. I have cut out every word/line that was unnecessary and as such this article isn’t really meant to be browsed.

What will we cover?
-------------------

1.  A simple neural network
2.  How are these models trained?
3.  How does all this generate language?
4.  What makes LLMs work so well?
5.  Embeddings
6.  Sub-word tokenizers
7.  Self-attention
8.  Softmax
9.  Residual connections
10.  Layer Normalization
11.  Dropout
12.  Multi-head attention
13.  Positional embeddings
14.  The GPT architecture
15.  The transformer architecture

Let’s dive in.

The first thing to note is that neural networks can only take numbers as inputs and can only output numbers. No exceptions. The art is in figuring out how to feed your inputs as numbers, interpreting the output numbers in a way that achieves your goals. And finally, building neural nets that will take the inputs you provide and give you the outputs you want (given the interpretation you chose for these outputs). Let’s walk through how we get from adding and multiplying numbers to things like [Llama 3.1](https://ai.meta.com/blog/meta-llama-3-1/).

A simple neural network:
------------------------

Let’s work through a simple neural network that can classify an object:

*   **Object data available:** Dominant color (RGB) & Volume (in milli-liters)
*   **Classify into**: Leaf OR Flower

Here’s what the data for a leaf and a sunflower can look like:

![Image 3: a table showing the number of leaves and flowers](https://miro.medium.com/v2/resize:fit:700/1*ymWXxVf7N4-Ps-62Cih2XQ.png)

Image by author

Let’s now build a neural net that does this classification. We need to decide on input/output interpretations. Our inputs are already numbers, so we can feed them directly into the network. Our outputs are two objects, leaf and flower which the neural network cannot output. Let’s look at a couple of schemes we can use here:

*   We can make the network output a single number. And if the number is positive we say it’s a leaf and if it is negative we say it’s a flower
*   OR, we can make the network output two numbers. We interpret the first one as a number for leaf and second one as the number for flower and we will say that the selection is whichever number is larger

Both schemes allow the network to output number(s) that we can interpret as leaf or flower. Let’s pick the second scheme here because it generalizes well to other things we will look at later. And here’s a neural network that does the classification using this scheme. Let’s work through it:

![Image 4: a sunflower with a number of sunflowers](https://miro.medium.com/v2/resize:fit:700/1*D-e4rt_QBPp1fMY5OseJiQ.png)

Image by author

Blue circle like so: (32 \* 0.10) **+** (107 \* -0.29) **+** (56 \* -0.07) **+** (11.2 \* 0.46) = **— 26.6**

Some jargon:

**_Neurons/nodes_**: The numbers in the circles

**_Weights_**: The colored numbers on the lines

**_Layers_**: A collection of neurons is called a layer. You could think of this network as having 3 layers: Input layer with 4 neurons, Middle layer with 3 neurons, and the Output layer with 2 neurons.

To calculate the prediction/output from this network (called a “**forward pass**”), you start from the left. We have the data available for the neurons in the Input layer. To move “forward” to the next layer, you multiply the number in the circle with the weight for the corresponding neuron pairing and you add them all up. We demonstrate blue and orange circle math above. Running the whole network we see that the first number in the output layer comes out higher so we interpret it as “network classified these (RGB,Vol) values as leaf”. A well trained network can take various inputs for (RGB,Vol) and correctly classify the object.

The model has no notion of what a leaf or a flower is, or what (RGB,Vol) are. It has a job of taking in exactly 4 numbers and giving out exactly 2 numbers. It is our interpretation that the 4 input numbers are (RGB,Vol) and it is also our decision to look at the output numbers and infer that if the first number is larger it’s a leaf and so on. And finally, it is also up to us to choose the right weights such that the model will take our input numbers and give us the right two numbers such that when we interpret them we get the interpretation we want.

An interesting side effect of this is that you can take the same network and instead of feeding RGB,Vol feed other 4 numbers like cloud cover, humidity etc.. and interpret the two numbers as “Sunny in an hour” or “Rainy in an hour” and then if you have the weights well calibrated you can get the exact same network to do two things at the same time — classify leaf/flower and predict rain in an hour! The network just gives you two numbers, whether you interpret it as classification or prediction or something else is entirely up to you.

Stuff left out for simplification (feel free to ignore without compromising comprehensibility):

*   **Activation layer**: A critical thing missing from this network is an “activation layer”. That’s a fancy word for saying that we take the number in each circle and apply a nonlinear function to it (**RELU** is a common function where you just take the number and set it to zero if it is negative, and leave it unchanged if it is positive). So basically in our case above, we would take the middle layer and replace the two numbers (-26.6 and -47.1) with zeros before we proceed further to the next layer. Of course, we would have to re-train the weights here to make the network useful again. Without the activation layer all the additions and multiplications in the network can be collapsed to a single layer. In our case, you could write the green circle as the sum of RGB directly with some weights and you would not need the middle layer. It would be something like (0.10 \* -0.17 + 0.12 \* 0.39–0.36 \* 0.1) \* R + (-0.29 \* -0.17–0.05 \* 0.39–0.21 \* 0.1) \* G …and so on. This is usually not possible if we have a nonlinearity there. This helps networks deal with more complex situations.
*   **Bias:** Networks will usually also contain another number associated with each node, this number is simply added to the product to calculate the value of the node and this number is called the “bias”. So if the bias for the top blue node was 0.25 then the value in the node would be: (32 \* 0.10) + (107 \* -0.29) + (56 \* -0.07) + (11.2 \* 0.46) **\+ 0.25** \= — 26.35. The word parameters is usually used to refer to all these numbers in the model that are not neurons/nodes.
*   **Softmax:** We don’t usually interpret the output layer directly as shown in our models. We convert the numbers into probabilities (i.e. make it so that all numbers are positive and add up to 1). If all the numbers in the output layer were already positive one way you could achieve this is by dividing each number by the sum of all numbers in the output layer. Though a “softmax” function is normally used which can handle both positive and negative numbers.

How are these models trained?
-----------------------------

In the example above, we magically had the weights that allowed us to put data into the model and get a good output. But how are these weights determined? The process of setting these weights (or “parameters”) is called “**training the model**”, and we need some training data to train the model.

Let’s say we have some data where we have the inputs and we already know if each input corresponds to leaf or flower, this is our “**training data**” and since we have the leaf/flower label for each set of (R,G,B,Vol) numbers, this is “**labeled data**”.

Here’s how it works:

*   Start with a random numbers, i.e. set each parameter/weight to a random number
*   Now, we know that when we input the data corresponding to the leaf (R=32, G=107, B=56, Vol=11.2). Suppose we want a larger number for leaf in the output layer. Let’s say we want the number corresponding to leaf as 0.8 and the one corresponding to flower as 0.2 (as shown in example above, but these are illustrative numbers to demonstrate training, in reality we would not want 0.8 and 0.2. In reality these would be probabilities, which they are not here, and we would them to be 1 and 0)
*   We know the numbers we want in the output layer, and the numbers we are getting from the randomly selected parameters (which are different from what we want). So for all the neurons in the output layer, let’s take the difference between the number we want and the number we have. Then add up the differences. E.g., if the output layer is 0.6 and 0.4 in the two neurons, then we get: (0.8–0.6)=0.2 and (0.2–0.4)= -0.2 so we get a total of 0.4 (ignoring minus signs before adding). We can call this our “**loss**”. Ideally we want the loss to be close to zero, i.e. we want to “**minimize the loss**”.
*   Once we have the loss, we can slightly change each parameter to see if increasing or decreasing it will increase the loss or decrease it. This is called the “**gradient**” of that parameter. Then we can move each of the parameters by a small amount in the direction where the loss goes down (the direction of the gradient). Once we have moved all the parameters slightly, the loss should be lower
*   Keep repeating the process and you will reduce the loss, and eventually have a set of weights/parameters that are “**trained**”. This whole process is called “**gradient descent**”.

Couple of notes:

*   You often have multiple training examples, so when you change the weights slightly to minimize the loss for one example it might make the loss worse for another example. The way to deal with this is to define loss as average loss over all the examples and then take gradient over that average loss. This reduces the average loss over the entire training data set. Each such cycle is called an “**epoch**”. Then you can keep repeating the epochs thus finding weights that reduce average loss.
*   We don’t actually need to “move weights around” to calculate the gradient for each weight — we can just infer it from the formula (e.g. if the weight is 0.17 in the last step, and the value of neuron is positive, and we want a larger number in output we can see that increasing this number to 0.18 will help).

In practice, training deep networks is a hard and complex process because gradients can easily spiral out of control, going to zero or infinity during training (called “vanishing gradient” and “exploding gradient” problems). The simple definition of loss that we talked about here is perfectly valid, but rarely used as there are better functional forms that work well for specific purposes. With modern models containing billions of parameters, training a model requires massive compute resources which has its own problems (memory limitations, parallelization etc.)

How does all this help generate language?
-----------------------------------------

Remember, neural nets take in some numbers, do some math based on the trained parameters, and give out some other numbers. Everything is about interpretation and training the parameters (i.e. setting them to some numbers). If we can interpret the two numbers as “leaf/flower” or “rain or sun in an hour”, we can also interpret them as “next character in a sentence”.

But there are more than 2 letters in English, and so we must expand the number of neurons in the output layer to, say, the 26 letters in the English language (let’s also throw in some symbols like space, period etc..). Each neuron can correspond to a character and we look at the (26 or so) neurons in the output layer and say that the character corresponding to the highest numbered neuron in the output layer is the output character. Now we have a network that can take some inputs and output a character.

What if we replace the input in our network with these characters: “Humpty Dumpt” and asked it to output a character and interpreted it as the “Network’s suggestion of the next character in the sequence that we just entered”. We can probably set the weights well enough for it to output “y” — thereby completing “Humpty Dumpty”. Except for one problem, how do we input these lists of characters in the network? Our network only accepts numbers!!

One simple solution is to assign a number to each character. Let’s say a=1, b=2 and so on. Now we can input “humpty dumpt” and train it to give us “y”. Our network looks something like this:

![Image 5: a diagram showing the different types of networks](https://miro.medium.com/v2/resize:fit:700/1*XPyJ-V0vbPv6EDwFpk7KYQ.png)

Image by author

Ok, so now we can predict one character ahead by providing the network a list of characters. We can use this fact to build a whole sentence. For example, once we have the “y” predicted, we can append that “y” to the list of characters we have and feed it to the network and ask it to predict the next character. And if well trained it should give us a space, and so on and so forth. By the end, we should be able to recursively generate “Humpty Dumpty sat on a wall”. We have Generative AI. Moreover, **_we now have a network capable of generating language!_** Now, nobody ever actually puts in randomly assigned numbers and we will see more sensible schemes down the line. If you cannot wait, feel free to check out the one-hot encoding section in the appendix.

Astute readers will note that we can’t actually input “Humpty Dumpty” into the network since the way the diagram is, it only has 12 neurons in the input layer one for each character in “humpty dumpt” (including the space). So how can we put in the “y” for the next pass. Putting a 13th neuron there would require us to modify the entire network, that’s not workable. The solution is simple, let’s kick the “h” out and send the 12 most recent characters. So we would be sending “umpty dumpty” and the network will predict a space. Then we would input “mpty dumpty “ and it will produce an s and so on. It looks something like this:

![Image 6: a diagram showing the different types of inputs](https://miro.medium.com/v2/resize:fit:700/1*0_tSCfEAL9NIK8U95Q-6Vg.png)

Image by author

We’re throwing away a lot of information in the last line by feeding the model only “ sat on the wal”. So what do the latest and greatest networks of today do? More or less exactly that. The length of inputs we can put into a network is fixed (determined by the size of the input layer). This is called “context length” — the context that is provided to the network to make future predictions. Modern networks can have very large context lengths (several thousand words) and that helps. There are some ways of inputting infinite length sequences but the performance of those methods, while impressive, has since been surpassed by other models with large (but fixed) context length.

One other thing careful readers will notice is that we have different interpretations for inputs and outputs for the same letters! For example, when inputting “h” we are simply denoting it with the number 8 but on the output layer we are not asking the model to output a single number (8 for “h”, 9 for “i” and so on..) instead we are are asking the model to output 26 numbers and then we see which one is the highest and then if the 8th number is highest we interpret the output as “h”. Why don’t we use the same, consistent, interpretation on both ends? We could, it’s just that in the case of language, freeing yourself to choose between different interpretations gives you a better chance of building better models. And it just so happens that the most effective currently known interpretations for the input and output are different. In-fact, the way we are inputting numbers in this model is not the best way to do it, we will look at better ways to do that shortly.

What makes large language models work so well?
----------------------------------------------

Generating “Humpty Dumpty sat on a wall” character-by-character is a far cry from what modern LLMs can do. There are a number of differences and innovations that get us from the simple generative AI that we discussed above to the human-like bot. Let’s go through them:

Embeddings
----------

Remember we said that the way that we are inputting characters into the model isn’t the best way to do it. We just arbitrarily selected a number for each character. What if there were better numbers we could assign that would make it possible for us to train better networks? How do we find these better numbers? Here’s a clever trick:

When we trained the models above, the way we did it was by moving around weights and seeing that gives us a smaller loss in the end. And then slowly and recursively changing the weights. At each turn we would:

*   Feed in the inputs
*   Calculate the output layer
*   Compare it to the output we ideally want and calculate the average loss
*   Adjust the weights and start again

In this process, the inputs are fixed. This made sense when inputs were (RGB, Vol). But the numbers we are putting in now for a,b,c etc.. are arbitrarily picked by us. What if at every iteration in addition to moving the weights around by a bit we also moved the input around and see if we can get a lower loss by using a different number to represent “a” and so on? We are definitely reducing the loss and making the model better (that’s the direction we moved a’s input in, by design). Basically, apply gradient descent not just to the weights but also the number representations for the inputs since they are arbitrarily picked numbers anyway. This is called an “**embedding**”. It is a mapping of inputs to numbers, and as you just saw, it needs to be trained. The process of training an embedding is much like that of training a parameter. One big advantage of this though is that once you train an embedding you can use it in another model if you wish. Keep in mind that you will consistently use the same embedding to represent a single token/character/word.

We talked about embeddings that are just one number per character. However, in reality embeddings have more than one number. That’s because it is hard to capture the richness of concept by a single number. If we look at our leaf and flower example, we have four numbers for each object (the size of the input layer). Each of these four numbers conveyed a property and the model was able to use all of them to effectively guess the object. If we had only one number, say the red channel of the color, it might have been a lot harder for the model. We’re trying to capture human language here — we’re going to need more than one number.

So instead of representing each character by a single number, maybe we can represent it by multiple numbers to capture the richness? Let’s assign a bunch of numbers to each character. Let’s call an ordered collection of numbers a “vector” (ordered as in each number has a position, and if we swap position of two numbers it gives us a different vector. This was the case with our leaf/flower data, if we swapped the R and G numbers for the leaf, we would get a different color, it would not be the same vector anymore). The length of a vector is simply how many numbers it contains. We’ll assign a vector to each character. Two questions arise:

*   If we have a vector assigned to each character instead of a number, how do we now feed “humpty dumpt” to the network? The answer is simple. Let’s say we assigned a vector of 10 numbers to each character. Then instead of the input layer having 12 neurons we would just put 120 neurons there since each of the 12 characters in “humpty dumpt” has 10 numbers to input. Now we just put the neurons next to each other and we are good to go
*   How do we find these vectors? Thankfully, we just learned how to train embedding numbers. Training an embedding vector is no different. You now have 120 inputs instead of 12 but all you are doing is moving them around to see how you can minimize loss. And then you take the first 10 of those and that’s the vector corresponding to “h” and so on.

All the embedding vectors must of course be the same length, otherwise we would not have a way of entering all the character combinations into the network. E.g. “humpty dumpt” and in the next iteration “umpty dumpty” — in both cases we are entering 12 characters in the network and if each of the 12 characters was not represented by vectors of length 10 we won’t be able to reliably feed them all into a 120-long input layer. Let’s visualize these embedding vectors:

![Image 7: a diagram showing the different numbers of the number of rows](https://miro.medium.com/v2/resize:fit:421/1*lZOR8fNDEWHxUhLCSB-67A.png)

Image by author

Let’s call an ordered collection of same-sized vectors a matrix. This matrix above is called an **embedding matrix**. You tell it a column number corresponding to your letter and looking at that column in the matrix will give you the vector that you are using to represent that letter. This can be applied more generally for embedding any arbitrary collection of things — you would just need to have as many columns in this matrix as the things you have.

Subword Tokenizers
------------------

So far, we have been working with characters as the basic building blocks of language. This has its limitations. The neural network weights have to do a lot of the heavy lifting where they must make sense of certain sequences of characters (i.e. words) appearing next to each other and then next to other words. What if we directly assigned embeddings to words and made the network predict the next word. The network doesn’t understand anything more than numbers anyway, so we can assign a 10-length vector to each of the words “humpty”, “dumpty”, “sat”, “on” etc.. and then we just feed it two words and it can give us the next word. “**Token**” is the term for a single unit that we embed and then feed to the model. Our models so far were using characters as tokens, now we are proposing to use entire words as a token (you can of course use entire sentences or phrases as tokens if you like).

Using word tokenization has one profound effect on our model. There are more than 180K words in the English language. Using our output interpretation scheme of having a neuron per possible output we need hundreds of thousands of neurons in the output layer insead of the 26 or so. With the size of the hidden layers needed to achieve meaningful results for modern networks, this issue becomes less pressing. What is however worth noting is that since we are treating each word separately, and we are starting with a random number embeddings for each — very similar words (e.g. “cat” and “cats”) will start with no relationship. You would expect that embeddings for the two words should be close to each other — which undoubtedly the model will learn. But, can we somehow use this obvious similarity to get a jumpstart and simplify matters?

Yes we can. The most common embedding scheme in language models today is something where you break words down into subwords and then embed them. In the cat example, we would break down cats into two tokens “cat” and ”s”. Now it is easier for the model to understand the concept of “s” followed by other familiar words and so on. This also reduces the number of tokens we need ([sentencpiece](https://github.com/google/sentencepiece) is a common tokenizer with vocab size options in tens of thousands vs hundreds of thousands of words in english). A tokenizer is something that takes you input text (e.g. “Humpty Dumpt”) and splits it into the tokens and gives you the corresponding numbers that you need to look up the embedding vector for that token in the embedding matrix. For example, in case of “humpty dumpty” if we’re using character level tokenizer and we arranged our embedding matrix as in the picture above, then the tokenizer will first split humpty dumpt into characters \[‘h’,’u’,…’t’\] and then give you back the numbers \[8,21,…20\] because you need to look up the 8th column of the embedding matrix to get the embedding vector for ‘h’ (embedding vector is what you will feed into the model, not the number 8, unlike before). The arrangement of the columns in the matrix is completely irrelevant, we could assign any column to ‘h’ and as long as we look up the same vector every time we input ‘h’ we should be good. Tokenizers just give us an arbitrary (but fixed) number to make lookup easy. The main task we need them for really is splitting the sentence in tokens.

With embeddings and subword tokenization, a model could look something like this:

![Image 8: a diagram showing the different types of networks](https://miro.medium.com/v2/resize:fit:700/1*VGNZ1Zighiek1sAMdiZCaw.png)

Image by author

The next few sections deal with more recent advances in language modeling, and the ones that made LLMs as powerful as they are today. However, to understand these there are a few basic math concepts you need to know. Here are the concepts:

*   Matrices and matrix multiplication
*   General concept of functions in mathematics
*   Raising numbers to powers (e.g. a3 = a\*a\*a)
*   Sample mean, variance, and standard deviation

I have added summaries of these concepts in the appendix.

Self Attention
--------------

So far we have seen only one simple neural network structure (called feedforward network), one which contains a number of layers and each layer is fully connected to the next (i.e., there is a line connecting any two neurons in consecutive layers), and it is only connected to the next layer (e.g. no lines between layer 1 and layer 3 etc..). However, as you can imagine there is nothing stopping us from removing or making other connections. Or even making more complex structures. Let’s explore a particularly important structure: self-attention.

If you look at the structure of human language, the next word that we want to predict will depend on all the words before. However, they may depend on some words before them to a greater degree than others. For example, if we are trying to predict the next word in “Damian had a secret child, a girl, and he had written in his will that all his belongings, along with the magical orb, will belong to \_\_\_\_”. This word here could be “her” or “him” and it depends specifically on a much earlier word in the sentence: _girl/boy_.

The good news is, our simple feedforward model connects to all the words in the context, and so it can learn the appropriate weights for important words, But here’s the problem, the weights connecting specific positions in our model through feed forward layers are fixed (for every position). If the important word was always in the same position, it would learn the weights appropriately and we would be fine. However, the relevant word to the next prediction could be anywhere in the system. We could paraphrase that sentence above and when guessing “her vs his”, one very important word for this prediction would be boy/girl no matter where it appeared in that sentence. So, we need weights that depend not only on the position but also on the content in that position. How do we achieve this?

Self attention does something like adding up the embedding vectors for each of the words, but instead of directly adding them up it applies some weights to each. So if the embedding vectors for humpty,dumpty, sat are x1, x2, x3 respectively, then it will multiply each one with a weight (a number) before adding them up. Something like output = 0.5 x1 + 0.25 x2 + 0.25 x3 where output is the self-attention output. If we write the weights as u1, u2, u3 such that output = u1x1+u2x2+u3x3 then how do we find these weights u1, u2, u3?

Ideally, we want these weights to be dependent on the vector we are adding — as we saw some may be more important than others. But important to whom? To the word we are about to predict. So we also want the weights to depend on the word we are about to predict. Now that’s an issue, we of course don’t know the word we are about to predict before we predict it. So, self attention uses the word immediately preceding the word we are about to predict, i.e., the last word in the sentence available (I don’t really know why this and why not something else, but a lot of things in deep learning are trial and error and I suspect this works well).

Great, so we want weights for these vectors, and we want each weight to depend on the word that we are aggregating and word immediately preceding the one we are going to predict. Basically, we want a function u1 = F(x1, x3) where x1 is the word we will weight and x3 is the last word in the sequence we have (assuming we have only 3 words). Now, a straightforward way of achieving this is to have a vector for x1 (let’s call it k1) and a separate vector for x3 (let’s call it q3) and then simply take their dot product. This will give us a number and it will depend on both x1 and x3. How do we get these vectors k1 and q3? We build a tiny single layer neural network to go from x1 to k1 (or x2 to k2, x3 to k3 and so on). And we build another network going from x3 to q3 etc… Using our matrix notation, we basically come up with weight matrices Wk and Wq such that k1 = Wkx1 and q1 =Wqx1 and so on. Now we can take a dot product of k1 and q3 to get a scalar, so u1 = F(x1,x3) = Wkx1 **·** Wqx3.

One additional thing that happens in self-attention is that we don’t directly take the weighted sum of the embedding vectors themselves. Instead, we take the weighted sum of some “value” of that embedding vector, which is obtained by another small single layer network. What this means is similar to k1 and q1, we also now have a v1 for the word x1 and we obtain it through a matrix Wv such that v1=Wvx1. This v1 is then aggregated. So it all looks something like this if we only have 3 words and we are trying to predict the fourth:

![Image 9: self-adjusted outputs with a humpy](https://miro.medium.com/v2/resize:fit:700/1*oETLwMpxy3oH_B9pN-xLcg.png)

Self attention. Image by author

The plus sign represents a simple addition of the vectors, implying they have to have the same length. One last modification not shown here is that the scalars u1, u2, u3 etc.. won’t necessarily add up to 1. If we need them to be weights, we should make them add up. So we will apply a familiar trick here and use the softmax function.

This is self-attention. There is also cross-attention where you can have the q3 come from the last word, but the k’s and the v’s can come from another sentence altogether. This is for example valuable in translation tasks. Now we know what attention is.

This whole thing can now be put in a box and be called a “self attention block”. Basically, this self attention block takes in the embedding vectors and spits out a single output vector of any user-chosen length. This block has three parameters, Wk,Wq,Wv — it doesn’t need to be more complicated than that. There are many such blocks in the machine learning literature, and they are usually represented by boxes in diagrams with their name on it. Something like this:

![Image 10: a diagram showing the different types of blocks](https://miro.medium.com/v2/resize:fit:700/1*OgcRxWyftIXN8WbQw_-QKg.png)

Image by author

One of the things that you will notice with self-attention is that the position of things so far does not seem relevant. We are using the same W’s across the board and so switching Humpty and Dumpty won’t really make a difference here — all numbers will end up being the same. This means that while attention can figure out what to pay attention to, this won’t depend on word position. However, we do know that word positions are important in english and we can probably improve performance by giving the model some sense of a word’s position.

And so, when attention is used, we don’t often feed the embedding vectors directly to the self attention block. We will later see how “positional encoding” is added to embedding vectors before feeding to attention blocks.

_Note for the pre-initiated_: Those for whom this isn’t the first time reading about self-attention will note that we are not referencing any K and Q matrices, or applying masks etc.. That is because those things are implementation details arising out of how these models are commonly trained. A batch of data is fed and the model is simultaneously trained to predict dumpty from humpty, sat from humpty dumpty and so on. This is a matter of gaining efficiency and does not affect interpretation or even model outputs, and we have chosen to omit training efficiency hacks here.

Softmax
-------

We talked briefly about softmax in the very first note. Here’s the problem softmax is trying to solve: In our output interpretation we have as many neurons as the options from which we want the network to select one. And we said that we are going to interpret the network’s choice as the highest value neuron. Then we said we are going to calculate loss as the difference between the value that network provides, and an ideal value we want. But what’s that ideal value we want? We set it to 0.8 in the leaf/flower example. But why 0.8? Why no 5, or 10, or 10 million? The higher the better for that training example. Ideally we want infinity there! Now that would make the problem intractable — all loss would be infinite and our plan of minimizing loss by moving around parameters (remember “gradient descent”) fails. How do we deal with this?

One simple thing we can do is cap the values we want. Let’s say between 0 and 1? This would make all loss finite, but now we have the issue of what happens when the network overshoots. Let’s say it outputs (5,1) for (leaf,flower) in one case, and (0,1) in another. The first case made the right choice but the loss is worse! Ok, so now we need a way to also convert the outputs of the last layer in (0,1) range so that it preserves the order. We could use any function (a “**function**” in mathematics is simply a mapping of one number to another — in goes one number, out comes another — it’s rule based in terms of what will be output for a given input) here to get the job done. One possible option is the logistic function (see graph below) which maps all numbers to numbers between (0,1) and preserves the order:

![Image 11: linear function for h - i](https://miro.medium.com/v2/resize:fit:700/1*jSyo_owKB-tfTrPXV2giKg.png)

Image by author

Now, we have a number between 0 and 1 for each of the neurons in the last layer and we can calculate loss by setting the correct neuron to 1, others to 0 and taking the difference of that from what the network provides us. This will work, but can we do better?

Going back to our “Humpty dumpty” example, let’s say we are trying to generate dumpty character-by-character and our model makes a mistake when predicting “m” in dumpty. Instead of giving us the last layer with “m” as the highest value, it gives us “u” as the highest value but “m” is a close second.

Now we can continue with “duu” and try to predict next character and so on, but the model confidence will be low because there are not that many good continuations from “humpty duu..”. On the other hand, “m” was a close second, so we can also give “m” a shot, predict the next few characters, and see what happens? Maybe it gives us a better overall word?

So what we are talking about here is not just blindly selecting the max value, but trying a few. What’s a good way to do it? Well we have to assign a chance to each one — say we will pick the top one with 50%, second one with 25% and so on. That’s a good way to do it. But maybe we would want the chance to be dependent on the underlying model predictions. If the model predicts values for m and u to be really close to each other here (compared to other values) — then maybe a close 50–50 chance of exploring the two is a good idea?

So we need a nice rule that takes all these numbers and converts them into chances. That’s what softmax does. It is a generalization of the logistic function above but with additional features. If you give it 10 arbitrary numbers — it will give you 10 outputs, each between 0 and 1 and importantly, all 10 adding up to 1 so that we can interpret them as chance. You will find softmax as the last layer in nearly every language model.

Residual connections
--------------------

We have slowly changed our visualization of networks as the sections progress. We are now using boxes/blocks to denote certain concepts. This notation is useful in denoting a particularly useful concept of residual connections. Let’s look at residual connection combined with a self-attention block:

![Image 12: a diagram of a self-blocking system](https://miro.medium.com/v2/resize:fit:700/1*270MXDfslVtvmBjShHL2hQ.png)

A residual connection. Image by author

Note that we put “Input” and “Output” as boxes to make things simpler, but these are still basically just a collection of neurons/numbers same as shown above.

So what’s going on here? We are basically taking the output of self-attention block and before passing it to the next block, we are adding to it the original Input. First thing to note is that this would require that the dimensions of the self-attention block output must now be the same as that of the input. This is not a problem since as we noted the self-attention output is determined by the user. But why do this? We won’t get into all the details here but the key thing is that as networks get deeper (more layers between input and output) it gets increasingly harder to train them. Residual connections have been shown to help with these training challenges.

Layer Normalization
-------------------

Layer normalization is a fairly simple layer that takes the data coming into the layer and normalizes it by subtracting the mean and dividing it by standard deviation (maybe a bit more, as we see below). For example, if we were to apply layer normalization immediately after the input, it would take all the neurons in the input layer and then it would calculate two statistics: their mean and their standard deviation. Let’s say the mean is M and the standard deviation is S then what layer norm is doing is taking each of these neurons and replacing it with (x-M)/S where x denotes any given neuron’s original value.

Now how does this help? It basically stabilizes the input vector and helps with training deep networks. One concern is that by normalizing inputs, are we removing some useful information from them that may be helpful in learning something valuable about our goal? To address this, the layer norm layer has a scale and a bias parameter. Basically, for each neuron you just multiply it with a scalar and then add a bias to it. These scalar and bias values are parameters that can be trained. This allows the network to learn some of the variation that may be valuable to the predictions. And since these are the only parameters, the LayerNorm block doesn’t have a lot of parameters to train. The whole thing looks something like this:

![Image 13: a diagram of a layer nomination block](https://miro.medium.com/v2/resize:fit:700/1*Zd-PvX2cYslEyrjL6MVnzA.png)

Layer Normalization. Image by author

The Scale and Bias are trainable parameters. You can see that layer norm is a relatively simple block where each number is only operated on pointwise (after the initial mean and std calculation). Reminds us of the activation layer (e.g. RELU) with the key difference being that here we have some trainable parameters (albeit lot fewer than other layers because of the simple pointwise operation).

Standard deviation is a statistical measure of how spread out the values are, e.g., if the values are all the same you would say the standard deviation is zero. If, in general, each value is really far from the mean of these very same values, then you will have a high standard deviation. The formula to calculate standard deviation for a set of numbers, a1, a2, a3…. (say N numbers) goes something like this: subtract the mean (of these numbers) from each of the numbers, then square the answer for each of N numbers. Add up all these numbers and then divide by N. Now take a square root of the answer.

Note for the pre-initiated: Experienced ML professionals will note that there is no discussion of batch norm here. In-fact, we haven’t even introduced the concept of batches in this article at all. For the most part, I believe batches are another training accelerant not related to the understanding of core concepts (except perhaps batch norm which we do not need here).

Dropout
-------

Dropout is a simple but effective method to avoid model overfitting. Overfitting is a term for when you train the model on your training data, and it works well on that dataset but does not generalize well to the examples the model has not seen. Techniques that help us avoid overfitting are called “**regularization techniques**”, and dropout is one of them.

If you train a model, it might make errors on the data and/or overfit it in a particular way. If you train another model, it might do the same, but in a different way. What if you trained a number of these models and averaged the outputs? These are typically called “**ensemble** **models**” because they predict the outputs by combining outputs from an ensemble of models, and ensemble models generally perform better than any of the individual models.

In neural networks, you could do the same. You could build multiple (slightly different) models and then combine their outputs to get a better model. However, this can be computationally expensive. Dropout is a technique that doesn’t quite build ensemble models but does capture some of the essence of the concept.

The concept is simple, by inserting a dropout layer during training what you are doing is randomly deleting a certain percentage of the direct neuron connections between the layers that dropout is inserted. Considering our initial network and inserting a Dropout layer between the input and the middle layer with 50% dropout rate can look something like this:

![Image 14: a diagram of a sunflower and a sunflower](https://miro.medium.com/v2/resize:fit:700/1*j0oKuXvH7kfrIpIfXE03VA.png)

![Image 15: a diagram showing the arrow pointing to the right](https://miro.medium.com/v2/resize:fit:700/1*UodvtsDn5z73Cp578XOoVw.png)

![Image 16: a diagram of a sunflower and its leaves](https://miro.medium.com/v2/resize:fit:700/1*qHPSwQmV3sfvKT5pG4TEJw.png)

Image by author

Now, this forces the network to train with a lot of redundancy. Essentially, you are training a number of different models at the same time — but they share weights.

Now for making inferences, we could follow the same approach as an ensemble model. We could make multiple predictions using dropouts and then combine them. However, since that is computationally intensive — and since our models share common weights — why don’t we just do a prediction using all the weights (so instead of using 50% of the weights at a time we use all at the same time). This should give us some approximation of what an ensemble will provide.

One issue though: the model trained with 50% of the weights will have very different numbers in the middle neurons than one using all the weights. What we want is more ensemble style averaging here. How do we do this? Well, a simple way is to simply take all the weights and multiply them by 0.5 since we are now using twice as many weights. This is what Droput does during inference. It will use the full network with all the weights and simply multiply the weights with (1- p) where p is the deletion probability. And this has been shown to work rather well as a regularization technique.

Multi-head Attention
--------------------

This is the key block in the transformer architecture. We’ve already seen what an attention block is. Remember that the output of an attention block was determined by the user and it was the length of v’s. What a multi-attention head is basically you run several attention heads in parallel (they all take the same inputs). Then we take all their outputs and simply concatenate them. It looks something like this:

![Image 17: a diagram showing the different types of data](https://miro.medium.com/v2/resize:fit:700/1*BmZd8SIDEQu7r5_R7y54kQ.png)

Multi-head attention. Image by author

Keep in mind the arrows going from v1 -\> v1h1 are linear layers — there’s a matrix on each arrow that transforms. I just did not show them to avoid clutter.

What is going on here is that we are generating the same key, query and values for each of the heads. But then we are basically applying a linear transformation on top of that (separately to each k,q,v and separately for each head) before we use those k,q,v values. This extra layer did not exist in self attention.

A side note is that to me, this is a slightly surprising way of creating a multi-headed attention. For example, why not create separate Wk,Wq,Wv matrices for each of the heads rather than adding a new layer and sharing these weights. Let me know if you know — I really have no idea.

Positional encoding and embedding
---------------------------------

We briefly talked about the motivation for using positional encoding in the self-attention section. What are these? While the picture shows positional encoding, using a positional embedding is more common than using an encoding. As such we talk about a common positional embedding here but the appendix also covers positional encoding used in the original paper. A positional embedding is no different than any other embedding except that instead of embedding the word vocabulary we will embed numbers 1, 2, 3 etc. So this embedding is a matrix of the same length as word embedding, and each column corresponds to a number. That’s really all there is to it.

The GPT architecture
--------------------

Let’s talk about the GPT architecture. This is what is used in most GPT models (with variation across). If you have been following the article thus far, this should be fairly trivial to understand. Using the box notation, this is what the architecture looks like at high level:

![Image 18: a diagram of a process for a transducer](https://miro.medium.com/v2/resize:fit:700/0*U9mQKCWiyakNVwxU)

The GPT Architecture. Image by author

At this point, other than the “GPT Transformer Block” all the other blocks have been discussed in great detail. The + sign here simply means that the two vectors are added together (which means the two embeddings must be the same size). Let’s look at this GPT Transformer Block:

![Image 19: the transformation book for gtf](https://miro.medium.com/v2/resize:fit:700/1*Mq4hBZcKPL9GALPSSQG9Xg.png)

And that’s pretty much it. It is called “transformer” here because it is derived from and is a type of transformer — which is an architecture we will look at in the next section. This doesn’t affect understanding as we’ve already covered all the building blocks shown here before. Let’s recap everything we’ve covered so far building up to this GPT architecture:

*   We saw how neural nets take numbers and output other numbers and have weights as parameters which can be trained
*   We can attach interpretations to these input/output numbers and give real world meaning to a neural network
*   We can chain neural networks to create bigger ones, and we can call each one a “block” and denote it with a box to make diagrams easier. Each block still does the same thing, take in a bunch of numbers and output other bunch of numbers
*   We learned a lot of different types of blocks that serve different purposes
*   GPT is just a special arrangement of these blocks that is shown above with an interpretation that we discussed in Part 1

Modifications have been made over time to this as companies have built up to powerful modern LLMs, but the basic remains the same.

Now, this GPT transformer is actually what is called a “decoder” in the original transformer paper that introduced the transformer architecture. Let’s take a look at that.

The transformer architecture
----------------------------

This is one of the key innovations driving rapid acceleration in the capabilities of language models recently. Transformers not only improved the prediction accuracy, they are also easier/more efficient than previous models (to train), allowing for larger model sizes. This is what the GPT architecture above is based on.

If you look at GPT architecture, you can see that it is great for generating the next word in the sequence. It fundamentally follows the same logic we discussed in Part 1. Start with a few words and then continue generating one at a time. But, what if you wanted to do translation. What if you had a sentence in german (e.g. “Wo wohnst du?” = “Where do you live?”) and you wanted to translate it to english. How would we train the model to do this?

Well, first thing we would need to do is figure out a way to input german words. Which means we have to expand our embedding to include both german and english. Now, I guess here is a simply way of inputting the information. Why don’t we just concatenate the german sentence at the beginning of whatever so far generated english is and feed it to the context. To make it easier for the model, we can add a separator. This would look something like this at each step:

![Image 20: a diagram showing the different ways to say the word](https://miro.medium.com/v2/resize:fit:700/1*psIz3-v2dMfI3SMsFQjRPQ.png)

Image by author

This will work, but it has room for improvement:

*   If the context length is fixed, sometimes the original sentence is lost
*   The model has a lot to learn here. Two languages simultaneously, but also to know that


### Image Analysis
is the separator token where it needs to start translating
*   You are processing the entire german sentence, with different offsets, for each word generation. This means there will be different internal representations of the same thing and the model should be able to work through it all for translation

Transformer was originally created for this task and consists of an “encoder” and a “decoder” — which are basically two separate blocks. One block simply takes the german sentence and gives out an intermediate representation (again, bunch of numbers, basically) — this is called the encoder.

The second block generates words (we’ve seen a lot of this so far). The only difference is that in addition to feeding it the words generated so far we also feed it the encoded german (from the encoder block) sentence. So as it is generating language, it’s context is basically all the words generated so far, plus the german. This block is called the decoder.

Each of these encoders and decoders consist of a few blocks, notably the attention block sandwiched between other layers. Let’s look at the illustration of a transformer from the paper “Attention is all you need” and try to understand it:

![Image 21: a diagram showing the process of a video processing system](https://miro.medium.com/v2/resize:fit:683/1*uPwJ24na4D_ECHBv1Lg5Fg.png)

Image from Vaswani et al. (2017)

The vertical set of blocks on the left is called the “encoder” and the ones to the right is called the “decoder”. Let’s go over and understand anything that we have not already covered before:

_Recap on how to read the diagram:_ Each of the boxes here is a block that takes in some inputs in the form of neurons, and spits out a set of neurons as output that can then either be processed by the next block or interpreted by us. The arrows show where the output of a block is going. As you can see, we will often take the output of one block and feed it in as input into multiple blocks. Let’s go through each thing here:

Feed forward: A feedforward network is one that does not contain cycles. Our original network in section 1 is a feed forward. In-fact, this block uses very much the same structure. It contains two linear layers, each followed by a RELU (see note on RELU in first section) and a dropout layer. Keep in mind that this feedforward neetwork applies to each position independently. What this means is that the information on position 0 has a feedforward network, and on position 1 has one and so on.. But the neurons from position x do not have a linkage to the feedforward network of position y. This is important because if we did not do this, it would allow the network to cheat during training time by looking forward.

_Cross-attention:_ You will notice that the decoder has a multi-head attention with arrows coming from the encoder. What is going on here? Remember the value, key, query in self-attention and multi-head attention? They all came from the same sequence. The query was just from the last word of the sequence in-fact. So what if we kept the query but fetched the value and key from a completely different sequence altogether? That is what is happening here. The value and key come from the output of the encoder. Nothing has changed mathematically except where the inputs for key and value are coming from now.

_Nx_: The Nx here simply represents that this block is chain-repeated N times. So basically you are stacking the block back-to-back and passing the input from the previous block to the next one. This is a way to make the neural network deeper. Now, looking at the diagram there is room for confusion about how the encoder output is fed to the decoder. Let’s say N=5. Do we feed the output of each encoder layer to the corresponding decoder layer? No. Basically you run the encoder all the way through once and only once. Then you just take that representation and feed the same thing to every one of the 5 decoder layers.

_Add & Norm block_: This is basically the same as below (guess the authors were just trying to save space)

![Image 22: layer norm diagram](https://miro.medium.com/v2/resize:fit:681/0*sXvYIassJutgqw5W)

Image by author

Everything else has already been discussed. Now you have a complete explanation of the transformer architecture building up from simple sum and product operations and fully self contained! You know what every line, every sum, every box and word means in terms of how to build them from scratch. Theoretically, these notes contain what you need to code up the transformer from scratch. In-fact, if you are interested [this repo](https://github.com/karpathy/nanoGPT) does that for the GPT architecture above.

Appendix
--------

Matrix Multiplication
---------------------

We introduced vectors and matrices above in the context of embeddings. A matrix has two dimensions (number or rows and columns). A vector can also be thought of as a matrix where one of the dimensions equals one. Product of two matrices is defined as:

![Image 23: a diagram showing the structure of a dna](https://miro.medium.com/v2/resize:fit:700/0*woel5Da5Z22EmiGx)

Image by author

Dots represent multiplication. Now let’s take a second look at the calculation of blue and organic neurons in the very first picture. If we write the weights as a matrix and the inputs as vectors, we can write the whole operation in the following way:

![Image 24: a diagram showing the number of numbers in a matrix](https://miro.medium.com/v2/resize:fit:466/0*yn1TPuxw_QqnD93k)

Image by author

If the weight matrix is called “W” and the inputs are called “x” then Wx is the result (the middle layer in this case). We can also transpose the two and write it as xW — this is a matter of preference.

Standard deviation
------------------

We use the concept of standard deviation in the Layer Normalization section. Standard deviation is a statistical measure of how spread out the values are (in a set of numbers), e.g., if the values are all the same you would say the standard deviation is zero. If, in general, each value is really far from the mean of these very same values, then you will have a high standard deviation. The formula to calculate standard deviation for a set of numbers, a1, a2, a3…. (say N numbers) goes something like this: subtract the mean (of these numbers) from each of the numbers, then square the answer for each of N numbers. Add up all these numbers and then divide by N. Now take a square root of the answer.

Positional Encoding
-------------------

We talked about positional embedding above. A positional encoding is simply a vector of the same length as the word embedding vector, except it is not an embedding in the sense that it is not trained. We simply assign a unique vector to every position e.g. a different vector for position 1 and different one for position 2 and so on. A simple way of doing this is to make the vector for that position simply full of the position number. So the vector for position 1 would be \[1,1,1…1\] for 2 would be \[2,2,2…2\] and so on (remember length of each vector must match embedding length for addition to work). This is problematic because we can end up with large numbers in vectors which creates challenges during training. We can, of course, normalize these vectors by dividing every number by the max of position, so if there are 3 words total then position 1 is \[.33,.33,..,.33\] and 2 is \[.67, .67, ..,.67\] and so on. This has the problem now that we are constantly changing the encoding for position 1 (those numbers will be different when we feed 4 word sentence as input) and it creates challenges for the network to learn. So here, we want a scheme that allocates a unique vector to each position, and the numbers don’t explode. Basically if the context length is d (i.e., maximum number of tokens/words that we can feed into the network for predicting next token/word, see discussion in “how does it all generate language?” section) and if the length of the embedding vector is 10 (say), then we need a matrix with 10 rows and d columns where all the columns are unique and all the numbers lie between 0 and 1. Given that there are infinitely many numbers between zero and 1, and the matrix is finitely sized, this can be done in many ways.

The approach used in the “Attention is all you need” paper goes something like this:

*   Draw 10 sin curves each being si(p) = sin (p/10000(i/d)) (that’s 10k to power i/d)
*   Fill the encoding matrix with numbers such that (i,p)th number is si(p), e.g., for position 1 the 5th element of the encoding vector is s5(1)=sin (1/10000(5/d))

Why choose this method? By changing the power on 10k you are changing the amplitude of the sine function when viewed on the p-axis. And if you have 10 different sine functions with 10 different amplitudes, then it will be a long time before you get a repetition (i.e. all 10 values are the same) for changing values of p. And this helps give us unique values. Now, the actual paper uses both sine and cosine functions and the form of encoding is: si(p) = sin (p/10000(i/d)) if i is even and si(p) = cos(p/10000(i/d)) if i is odd.


---

## https://medium.com/gitconnected/llms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82

Title: LLMs and the Student Dilemma: Learning to Solve or Learning to Remember?

URL Source: https://medium.com/gitconnected/llms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82

Published Time: 2024-11-07T01:20:36.867Z

Markdown Content:
LLMs and the Student Dilemma: Learning to Solve or Learning to Remember? | by Salvatore Raieli | Nov, 2024 | Level Up Coding
===============
 

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

|LLM|MATH|ARITHMETIC|MEMORIZATION|AI|
-------------------------------------

LLMs and the Student Dilemma: Learning to Solve or Learning to Remember?
========================================================================

Investigating Whether Large Language Models Rely on Genuine Understanding or Clever Heuristics in Arithmetic Reasoning
----------------------------------------------------------------------------------------------------------------------

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--byline--249152b72d82---------------------post_header-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---header_actions--249152b72d82---------------------clap_footer-----------)

582

19

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=---header_actions--249152b72d82---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=---header_actions--249152b72d82---------------------post_audio_button-----------)

![Image 4: Do large language models (LLMs) truly understand arithmetic, or are they simply mimicking solutions? This study uncovers a network of heuristic-based neurons that recognize input patterns, revealing that LLMs rely on a ‘bag of tricks’ rather than algorithms or memorization. Learn how this approach, emerging early in training, shapes LLMs’ problem-solving abilities](https://miro.medium.com/v2/resize:fit:700/1*wOF7yk30r9pCZk5AfGUm7g.png)

> God does arithmetic. — Carl Friedrich Gauss
> 
> Maybe fate’s arithmetic is so diffuse that it’s not arithmetic at all. — David Levithan

[Large language models (LLMs)](https://en.wikipedia.org/wiki/Large_language_model) have shown incredible ability and flexibility to be able to solve tasks for which they do not appear to have been trained. Math [problem-solving](https://en.wikipedia.org/wiki/Problem_solving) has led researchers to discuss whether LLMs possess [reasoning skills](https://www.twinkl.it/teaching-wiki/reasoning-skills). This is a hotly debated topic, and the implications of answering this question are very important.

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82%3Fsource%3D-----249152b72d82---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----249152b72d82---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82%3Fsource%3D-----249152b72d82---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----249152b72d82---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82%3Fsource%3D-----249152b72d82---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----249152b72d82---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=-----249152b72d82---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---footer_actions--249152b72d82---------------------clap_footer-----------)

582

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---footer_actions--249152b72d82---------------------clap_footer-----------)

582

19

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=---footer_actions--249152b72d82---------------------bookmark_footer-----------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--post_author_info--249152b72d82---------------------follow_profile-----------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--post_author_info--249152b72d82---------------------follow_profile-----------)

[![Image 8: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:20:20/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=author_recirc-----249152b72d82----0---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Salvatore Raieli](https://salvatore-raieli.medium.com/?source=author_recirc-----249152b72d82----0---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----249152b72d82----0---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[1.98K 40](https://towardsdatascience.com/the-savant-syndrome-is-pattern-recognition-equivalent-to-intelligence-242aab928152?source=author_recirc-----249152b72d82----0---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F242aab928152&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-savant-syndrome-is-pattern-recognition-equivalent-to-intelligence-242aab928152&source=-----249152b72d82----0-----------------bookmark_preview----6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[![Image 10: Senthil E](https://miro.medium.com/v2/resize:fill:20:20/1*7LSbLKp-_jaS5-_NzLBxuA.jpeg)](https://esenthil.medium.com/?source=author_recirc-----249152b72d82----1---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Senthil E](https://esenthil.medium.com/?source=author_recirc-----249152b72d82----1---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Level Up Coding](https://levelup.gitconnected.com/?source=author_recirc-----249152b72d82----1---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[37](https://medium.com/langgraph-for-healthcare-a-comprehensive-technical-guide-e6038b06c108?source=author_recirc-----249152b72d82----1---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe6038b06c108&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Flanggraph-for-healthcare-a-comprehensive-technical-guide-e6038b06c108&source=-----249152b72d82----1-----------------bookmark_preview----6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[![Image 12: Jarek Orzel](https://miro.medium.com/v2/resize:fill:20:20/1*F3AJ1USJe5V8mhrj9Wze1g.png)](https://medium.com/@orzel.jarek?source=author_recirc-----249152b72d82----2---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Jarek Orzel](https://medium.com/@orzel.jarek?source=author_recirc-----249152b72d82----2---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Level Up Coding](https://levelup.gitconnected.com/?source=author_recirc-----249152b72d82----2---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[What It Means to Be a 10x Engineer ---------------------------------- ### Not a Myth, But a Powerful Metaphor for Impactful Team Players](https://medium.com/what-it-means-to-be-a-10x-engineer-0f5c4db543a6?source=author_recirc-----249152b72d82----2---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[108 1](https://medium.com/what-it-means-to-be-a-10x-engineer-0f5c4db543a6?source=author_recirc-----249152b72d82----2---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F0f5c4db543a6&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-it-means-to-be-a-10x-engineer-0f5c4db543a6&source=-----249152b72d82----2-----------------bookmark_preview----6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[![Image 14: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:20:20/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=author_recirc-----249152b72d82----3---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Salvatore Raieli](https://salvatore-raieli.medium.com/?source=author_recirc-----249152b72d82----3---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[AI Advances](https://ai.gopubby.com/?source=author_recirc-----249152b72d82----3---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[541 12](https://ai.gopubby.com/what-if-llms-are-better-than-we-think-or-is-it-our-judgement-thats-flawed-5cbd9c758275?source=author_recirc-----249152b72d82----3---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cbd9c758275&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fwhat-if-llms-are-better-than-we-think-or-is-it-our-judgement-thats-flawed-5cbd9c758275&source=-----249152b72d82----3-----------------bookmark_preview----6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[![Image 16: AI Rabbit](https://miro.medium.com/v2/resize:fill:20:20/1*1cIrPiG5AyUHt-rt6gh_Vw.jpeg)](https://medium.com/@airabbitX?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[AI Rabbit](https://medium.com/@airabbitX?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[CodeX](https://medium.com/codex?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[1.4K 22](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc1ada7a8d91&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fhas-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91&source=-----249152b72d82----0-----------------bookmark_preview----0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[![Image 18: Don Lim](https://miro.medium.com/v2/resize:fill:20:20/1*SkAt7uMC11I7WgRXlBMiPA.jpeg)](https://medium.com/@don-lim?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Don Lim](https://medium.com/@don-lim?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[705 13](https://medium.com/@don-lim/gpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f90e5362408&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40don-lim%2Fgpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408&source=-----249152b72d82----1-----------------bookmark_preview----0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[![Image 28](https://miro.medium.com/v2/resize:fill:48:48/1*vzu3JPzaq2EZKTZNY9BhLA.png) ![Image 29: AI-generated image of a cute tiny robot in the backdrop of ChatGPT’s logo](https://miro.medium.com/v2/resize:fill:48:48/1*lEmL62oZdrOOWIzAAFKiFg.jpeg) ![Image 30](https://miro.medium.com/v2/resize:fill:48:48/1*i2zLIwC9mftamP1dbciCeQ.jpeg) ChatGPT ------- 21 stories·864 saves](https://medium.com/@m.wasalski/list/chatgpt-3742c7a4727d?source=read_next_recirc-----249152b72d82--------------------------------)

![Image 31: Python is No More The King of Data Science](https://miro.medium.com/v2/resize:fit:679/1*uiA0nCufUQs-K64ebSUhew.jpeg)

[![Image 32: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Stackademic](https://blog.stackademic.com/?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[5.1K 23](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----249152b72d82----0-----------------bookmark_preview----0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[![Image 34: Isaac Saul](https://miro.medium.com/v2/resize:fill:20:20/1*5bMy4uvQlQxjhi_xhBlJJQ.jpeg)](https://medium.com/@isaac_1884?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Isaac Saul](https://medium.com/@isaac_1884?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[22 Thoughts about Trump’s Win ----------------------------- ### Reflecting on the election and looking forward to what may come](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[7.8K 263](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

![Image 35: How I Am Using a Lifetime 100% Free Server](https://miro.medium.com/v2/resize:fit:679/1*BqVsCBa2mLv1UWQrdhjX5w.png)

[![Image 36: Harendra](https://miro.medium.com/v2/resize:fill:20:20/1*uTEzlRvlNBr3ralJoTQkmg.jpeg)](https://medium.com/@harendra21?source=read_next_recirc-----249152b72d82----2---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Harendra](https://medium.com/@harendra21?source=read_next_recirc-----249152b72d82----2---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[How I Am Using a Lifetime 100% Free Server ------------------------------------------ ### Get a server with 24 GB RAM + 4 CPU + 200 GB Storage + Always Free](https://medium.com/@harendra21/how-i-am-using-a-lifetime-100-free-server-bd241e3a347a?source=read_next_recirc-----249152b72d82----2---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[4.1K 50](https://medium.com/@harendra21/how-i-am-using-a-lifetime-100-free-server-bd241e3a347a?source=read_next_recirc-----249152b72d82----2---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd241e3a347a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40harendra21%2Fhow-i-am-using-a-lifetime-100-free-server-bd241e3a347a&source=-----249152b72d82----2-----------------bookmark_preview----0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[![Image 38: Richardson Gunde](https://miro.medium.com/v2/resize:fill:20:20/1*tp2uj3tur89cbR2GW0SrDQ.png)](https://medium.com/@honeyricky1m3?source=read_next_recirc-----249152b72d82----3---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Richardson Gunde](https://medium.com/@honeyricky1m3?source=read_next_recirc-----249152b72d82----3---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[AI Advances](https://ai.gopubby.com/?source=read_next_recirc-----249152b72d82----3---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[1K 13](https://ai.gopubby.com/the-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8?source=read_next_recirc-----249152b72d82----3---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe57882dee7f8&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fthe-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8&source=-----249152b72d82----3-----------------bookmark_preview----0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

## Visual Content Analysis

### Image Analysis
Title: LLMs and the Student Dilemma: Learning to Solve or Learning to Remember?

URL Source: https://medium.com/gitconnected/llms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82

Published Time: 2024-11-07T01:20:36.867Z

Markdown Content:
LLMs and the Student Dilemma: Learning to Solve or Learning to Remember? | by Salvatore Raieli | Nov, 2024 | Level Up Coding
===============
 

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

|LLM|MATH|ARITHMETIC|MEMORIZATION|AI|
-------------------------------------

LLMs and the Student Dilemma: Learning to Solve or Learning to Remember?
========================================================================

Investigating Whether Large Language Models Rely on Genuine Understanding or Clever Heuristics in Arithmetic Reasoning
----------------------------------------------------------------------------------------------------------------------

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--byline--249152b72d82---------------------post_header-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---header_actions--249152b72d82---------------------clap_footer-----------)

582

19

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=---header_actions--249152b72d82---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=---header_actions--249152b72d82---------------------post_audio_button-----------)

![Image 4: Do large language models (LLMs) truly understand arithmetic, or are they simply mimicking solutions? This study uncovers a network of heuristic-based neurons that recognize input patterns, revealing that LLMs rely on a ‘bag of tricks’ rather than algorithms or memorization. Learn how this approach, emerging early in training, shapes LLMs’ problem-solving abilities](https://miro.medium.com/v2/resize:fit:700/1*wOF7yk30r9pCZk5AfGUm7g.png)

> God does arithmetic. — Carl Friedrich Gauss
> 
> Maybe fate’s arithmetic is so diffuse that it’s not arithmetic at all. — David Levithan

[Large language models (LLMs)](https://en.wikipedia.org/wiki/Large_language_model) have shown incredible ability and flexibility to be able to solve tasks for which they do not appear to have been trained. Math [problem-solving](https://en.wikipedia.org/wiki/Problem_solving) has led researchers to discuss whether LLMs possess [reasoning skills](https://www.twinkl.it/teaching-wiki/reasoning-skills). This is a hotly debated topic, and the implications of answering this question are very important.

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82%3Fsource%3D-----249152b72d82---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----249152b72d82---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82%3Fsource%3D-----249152b72d82---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----249152b72d82---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82%3Fsource%3D-----249152b72d82---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----249152b72d82---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=-----249152b72d82---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---footer_actions--249152b72d82---------------------clap_footer-----------)

582

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=---footer_actions--249152b72d82---------------------clap_footer-----------)

582

19

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F249152b72d82&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&source=---footer_actions--249152b72d82---------------------bookmark_footer-----------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--post_author_info--249152b72d82---------------------follow_profile-----------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fllms-and-the-student-dilemma-learning-to-solve-or-learning-to-remember-249152b72d82&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd--post_author_info--249152b72d82---------------------follow_profile-----------)

[![Image 8: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:20:20/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=author_recirc-----249152b72d82----0---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Salvatore Raieli](https://salvatore-raieli.medium.com/?source=author_recirc-----249152b72d82----0---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----249152b72d82----0---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[1.98K 40](https://towardsdatascience.com/the-savant-syndrome-is-pattern-recognition-equivalent-to-intelligence-242aab928152?source=author_recirc-----249152b72d82----0---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F242aab928152&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-savant-syndrome-is-pattern-recognition-equivalent-to-intelligence-242aab928152&source=-----249152b72d82----0-----------------bookmark_preview----6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[![Image 10: Senthil E](https://miro.medium.com/v2/resize:fill:20:20/1*7LSbLKp-_jaS5-_NzLBxuA.jpeg)](https://esenthil.medium.com/?source=author_recirc-----249152b72d82----1---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Senthil E](https://esenthil.medium.com/?source=author_recirc-----249152b72d82----1---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Level Up Coding](https://levelup.gitconnected.com/?source=author_recirc-----249152b72d82----1---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[37](https://medium.com/langgraph-for-healthcare-a-comprehensive-technical-guide-e6038b06c108?source=author_recirc-----249152b72d82----1---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe6038b06c108&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Flanggraph-for-healthcare-a-comprehensive-technical-guide-e6038b06c108&source=-----249152b72d82----1-----------------bookmark_preview----6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[![Image 12: Jarek Orzel](https://miro.medium.com/v2/resize:fill:20:20/1*F3AJ1USJe5V8mhrj9Wze1g.png)](https://medium.com/@orzel.jarek?source=author_recirc-----249152b72d82----2---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Jarek Orzel](https://medium.com/@orzel.jarek?source=author_recirc-----249152b72d82----2---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Level Up Coding](https://levelup.gitconnected.com/?source=author_recirc-----249152b72d82----2---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[What It Means to Be a 10x Engineer ---------------------------------- ### Not a Myth, But a Powerful Metaphor for Impactful Team Players](https://medium.com/what-it-means-to-be-a-10x-engineer-0f5c4db543a6?source=author_recirc-----249152b72d82----2---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[108 1](https://medium.com/what-it-means-to-be-a-10x-engineer-0f5c4db543a6?source=author_recirc-----249152b72d82----2---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F0f5c4db543a6&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhat-it-means-to-be-a-10x-engineer-0f5c4db543a6&source=-----249152b72d82----2-----------------bookmark_preview----6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[![Image 14: Salvatore Raieli](https://miro.medium.com/v2/resize:fill:20:20/1*cs7O1sBNbybTazY4AtBwig.jpeg)](https://salvatore-raieli.medium.com/?source=author_recirc-----249152b72d82----3---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[Salvatore Raieli](https://salvatore-raieli.medium.com/?source=author_recirc-----249152b72d82----3---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[AI Advances](https://ai.gopubby.com/?source=author_recirc-----249152b72d82----3---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[541 12](https://ai.gopubby.com/what-if-llms-are-better-than-we-think-or-is-it-our-judgement-thats-flawed-5cbd9c758275?source=author_recirc-----249152b72d82----3---------------------6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cbd9c758275&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fwhat-if-llms-are-better-than-we-think-or-is-it-our-judgement-thats-flawed-5cbd9c758275&source=-----249152b72d82----3-----------------bookmark_preview----6a865207_b2ee_4df1_909b_e86c6db16cf3-------)

[![Image 16: AI Rabbit](https://miro.medium.com/v2/resize:fill:20:20/1*1cIrPiG5AyUHt-rt6gh_Vw.jpeg)](https://medium.com/@airabbitX?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[AI Rabbit](https://medium.com/@airabbitX?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[CodeX](https://medium.com/codex?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[1.4K 22](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc1ada7a8d91&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fhas-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91&source=-----249152b72d82----0-----------------bookmark_preview----0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[![Image 18: Don Lim](https://miro.medium.com/v2/resize:fill:20:20/1*SkAt7uMC11I7WgRXlBMiPA.jpeg)](https://medium.com/@don-lim?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Don Lim](https://medium.com/@don-lim?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[705 13](https://medium.com/@don-lim/gpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f90e5362408&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40don-lim%2Fgpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408&source=-----249152b72d82----1-----------------bookmark_preview----0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[![Image 28](https://miro.medium.com/v2/resize:fill:48:48/1*vzu3JPzaq2EZKTZNY9BhLA.png) ![Image 29: AI-generated image of a cute tiny robot in the backdrop of ChatGPT’s logo](https://miro.medium.com/v2/resize:fill:48:48/1*lEmL62oZdrOOWIzAAFKiFg.jpeg) ![Image 30](https://miro.medium.com/v2/resize:fill:48:48/1*i2zLIwC9mftamP1dbciCeQ.jpeg) ChatGPT ------- 21 stories·864 saves](https://medium.com/@m.wasalski/list/chatgpt-3742c7a4727d?source=read_next_recirc-----249152b72d82--------------------------------)

![Image 31: Python is No More The King of Data Science](https://miro.medium.com/v2/resize:fit:679/1*uiA0nCufUQs-K64ebSUhew.jpeg)

[![Image 32: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Stackademic](https://blog.stackademic.com/?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[5.1K 23](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----249152b72d82----0---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----249152b72d82----0-----------------bookmark_preview----0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[![Image 34: Isaac Saul](https://miro.medium.com/v2/resize:fill:20:20/1*5bMy4uvQlQxjhi_xhBlJJQ.jpeg)](https://medium.com/@isaac_1884?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Isaac Saul](https://medium.com/@isaac_1884?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[22 Thoughts about Trump’s Win ----------------------------- ### Reflecting on the election and looking forward to what may come](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[7.8K 263](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----249152b72d82----1---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

![Image 35: How I Am Using a Lifetime 100% Free Server](https://miro.medium.com/v2/resize:fit:679/1*BqVsCBa2mLv1UWQrdhjX5w.png)

[![Image 36: Harendra](https://miro.medium.com/v2/resize:fill:20:20/1*uTEzlRvlNBr3ralJoTQkmg.jpeg)](https://medium.com/@harendra21?source=read_next_recirc-----249152b72d82----2---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Harendra](https://medium.com/@harendra21?source=read_next_recirc-----249152b72d82----2---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[How I Am Using a Lifetime 100% Free Server ------------------------------------------ ### Get a server with 24 GB RAM + 4 CPU + 200 GB Storage + Always Free](https://medium.com/@harendra21/how-i-am-using-a-lifetime-100-free-server-bd241e3a347a?source=read_next_recirc-----249152b72d82----2---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[4.1K 50](https://medium.com/@harendra21/how-i-am-using-a-lifetime-100-free-server-bd241e3a347a?source=read_next_recirc-----249152b72d82----2---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd241e3a347a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40harendra21%2Fhow-i-am-using-a-lifetime-100-free-server-bd241e3a347a&source=-----249152b72d82----2-----------------bookmark_preview----0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[![Image 38: Richardson Gunde](https://miro.medium.com/v2/resize:fill:20:20/1*tp2uj3tur89cbR2GW0SrDQ.png)](https://medium.com/@honeyricky1m3?source=read_next_recirc-----249152b72d82----3---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[Richardson Gunde](https://medium.com/@honeyricky1m3?source=read_next_recirc-----249152b72d82----3---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[AI Advances](https://ai.gopubby.com/?source=read_next_recirc-----249152b72d82----3---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[1K 13](https://ai.gopubby.com/the-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8?source=read_next_recirc-----249152b72d82----3---------------------0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe57882dee7f8&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fthe-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8&source=-----249152b72d82----3-----------------bookmark_preview----0dbc250e_3b91_4d8c_92e4_ab870e9f775e-------)


---

## https://medium.com/towards-data-science/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c

Title: Random Forest | Towards Data Science

URL Source: https://medium.com/towards-data-science/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c

Published Time: 2024-11-07T13:02:11.895Z

Markdown Content:
ENSEMBLE LEARNING
-----------------

Random Forest, Explained: A Visual Guide with Code Examples
-----------------------------------------------------------

Making tree-mendous predictions with random trees
-------------------------------------------------

[![Image 1: Samy Baladram](https://miro.medium.com/v2/resize:fill:88:88/1*M5J7CK552m9f4z-m1F7vYg.png)](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)

[Decision trees](https://towardsdatascience.com/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e) are a great starting point in machine learning — they’re clear and make sense. But there’s a catch: they often don’t work well when dealing with new data. The predictions can be inconsistent and unreliable, which is a real problem when you’re trying to build something useful.

This is where Random Forest comes in. It takes what’s good about decision trees and makes them work better by combining multiple trees together. It’s become a favorite tool for many data scientists because it’s both effective and practical.

Let’s see how Random Forest works and why it might be exactly what you need for your next project. It’s time to stop getting lost in the trees and see the forest for what it really is — your next reliable tool in machine learning.

![Image 3: a cartoon character is standing in front of a bunch of trees](https://miro.medium.com/v2/resize:fit:700/1*FBhxEgEzbfYWiSK0LYOv6g.gif)

All visuals: Author-created using Canva Pro. Optimized for mobile; may appear oversized on desktop.

Definition
----------

A Random Forest is an ensemble machine learning model that combines multiple decision trees. Each tree in the forest is trained on a random sample of the data (bootstrap sampling) and considers only a random subset of features when making splits (feature randomization).

For classification tasks, the forest predicts by majority voting among trees, while for regression tasks, it averages the predictions. The model’s strength comes from its “wisdom of crowds” approach — while individual trees might make errors, the collective decision-making process **tends to average out these mistakes** and arrive at more reliable predictions.

Random Forest is a part of bagging (bootstrap aggregating) algorithm because it builds each tree using different random part of data and combines their answers together.

Dataset Used
------------

Throughout this article, we’ll focus on the classic golf dataset as an example for classification. While Random Forests can handle both classification and regression tasks equally well, we’ll concentrate on the classification part — predicting whether someone will play golf based on weather conditions. The concepts we’ll explore can be easily adapted to regression problems (like predicting number of player) using the same principles.

![Image 5: a table with different numbers and numbers](https://miro.medium.com/v2/resize:fit:700/1*O0_DqZWXc5OM--Zxp3_uuw.png)

Columns: ‘Overcast (one-hot-encoded into 3 columns)’, ’Temperature’ (in Fahrenheit), ‘Humidity’ (in %), ‘Windy’ (Yes/No) and ‘Play’ (Yes/No, target feature)

import pandas as pd  
import numpy as np  
from sklearn.model\_selection import train\_test\_splitdataset\_dict = {  
    'Outlook': \['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast',   
                'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy',  
                'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast',  
                'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'\],  
    'Temperature': \[85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0,  
                   72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0,  
                   88.0, 77.0, 79.0, 80.0, 66.0, 84.0\],  
    'Humidity': \[85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0,  
                 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0,  
                 65.0, 70.0, 60.0, 95.0, 70.0, 78.0\],  
    'Wind': \[False, True, False, False, False, True, True, False, False, False, True,  
             True, False, True, True, False, False, True, False, True, True, False,  
             True, False, False, True, False, False\],  
    'Play': \['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',  
             'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',  
             'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes'\]  
}

df = pd.DataFrame(dataset\_dict)  
df = pd.get\_dummies(df, columns=\['Outlook'\], prefix='', prefix\_sep='', dtype=int)  
df\['Wind'\] = df\['Wind'\].astype(int)  
df\['Play'\] = (df\['Play'\] == 'Yes').astype(int)

column\_order = \['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind', 'Play'\]  
df = df\[column\_order\]

X,y = df.drop('Play', axis=1), df\['Play'\]  
X\_train, X\_test, y\_train, y\_test = train\_test\_split(X, y, train\_size=0.5, shuffle=False)

Main Mechanism
--------------

Here’s how Random Forest works:

1.  **Bootstrap Sampling:** Each tree gets its own unique training set, created by randomly sampling from the original data with replacement. This means some data points may appear multiple times while others aren’t used.
2.  **Random Feature Selection:** When making a split, each tree only considers a random subset of features (typically square root of total features).
3.  **Growing Trees:** Each tree grows using only its bootstrap sample and selected features, making splits until it reaches a stopping point (like pure groups or minimum sample size).
4.  **Final Prediction:** All trees vote together for the final prediction. For classification, take the majority vote of class predictions; for regression, average the predicted values from all trees.

![Image 6: a diagram showing the process of a data model](https://miro.medium.com/v2/resize:fit:700/1*FisK9hkTkWP2D92ANxAp9w.png)

A Random Forest Classifier makes predictions by combining results from 100 different decision trees, each analyzing features like temperature and outlook conditions. The final prediction comes from the most common answer among all trees.

Training Steps
--------------

The Random Forest algorithm constructs multiple decision trees and combines them. Here’s how it works:

**Step 1: Bootstrap Sample Creation**  
1.0. Set the number of trees (default = 100)  
1.1. For each tree in the forest:  
a. Create new training set by random sampling original data with replacement until reaching original dataset size. This is called **bootstrap sampling**.  
b. Mark and set aside non-selected samples as out-of-bag (OOB) samples for later error estimation

Random Forest creates different training sets for each tree by randomly picking data points from the original training set, with some numbers appearing multiple times. The unused data points become test sets for checking each tree’s performance.

  
n\_samples = len(X\_train)  
n\_bootstraps = 100  
all\_bootstrap\_indices = \[\]  
all\_oob\_indices = \[\]np.random.seed(42)    
for i in range(n\_bootstraps):  
      
    bootstrap\_indices = np.random.choice(n\_samples, size=n\_samples, replace=True)

oob\_indices = list(set(range(n\_samples)) - set(bootstrap\_indices))

all\_bootstrap\_indices.append(bootstrap\_indices)  
    all\_oob\_indices.append(oob\_indices)

samples\_to\_show = \[0, 1, 99\]

for i in samples\_to\_show:  
    print(f"\\nBootstrap Sample {i+1}:")  
    print(f"Chosen indices: {sorted(all\_bootstrap\_indices\[i\])}")  
    print(f"Number of unique chosen indices: {len(set(all\_bootstrap\_indices\[i\]))}")  
    print(f"OOB indices: {sorted(all\_oob\_indices\[i\])}")  
    print(f"Number of OOB samples: {len(all\_oob\_indices\[i\])}")  
    print(f"Percentage of OOB: {len(all\_oob\_indices\[i\])/n\_samples\*100:.1f}%")

![Image 8: a table with different numbers and numbers](https://miro.medium.com/v2/resize:fit:700/1*_smMUwVcgHdpla5vGIDVrw.png)

Notice how similar the percentages of OOB above? When doing bootstrap sampling of _n_ samples, each individual sample has about a 37% chance of never being picked. This comes from the probability calculation (1–1/_n_)_ⁿ_, which approaches 1/e ≈ 0.368 as _n_ gets larger. That’s why each tree ends up using roughly 63% of the data for training, with the remaining 37% becoming OOB samples.

**Step 2: Tree Construction**  
2.1. Start at root node with complete bootstrap sample

![Image 9: a table with a number of numbers and a number of numbers](https://miro.medium.com/v2/resize:fit:700/1*v4X7vEWV5j1oOfEX4R5lRw.png)

When building each decision tree, Random Forest considers a subset of data points and creates splits based on questions about their values — sending smaller values to the left and larger values to the right to make predictions.

a. Calculate initial node impurity using all samples in node  
· Classification: Gini or entropy  
· Regression: MSE

![Image 10: a screen showing the number of a number and the number of a number](https://miro.medium.com/v2/resize:fit:700/1*zNarI6dKgX4FiJjFyD3n2Q.png)

Random Forest starts by calculating the Gini Impurity of the entire dataset (before any splits) using the ratio of YES and NO labels — a measure of how mixed the labels are in the current data.

b. Select random subset of features from total available features:  
· Classification: √n\_features  
· Regression: n\_features/3

For each split in a tree, Random Forest randomly picks a subset of weather features (here 2 out of 6) to consider, making each tree focus on different aspects of the data.

c. For each selected feature:  
· Sort data points by feature values  
· Identify potential split points (midpoints between consecutive unique feature values)

![Image 12: a table with different numbers and numbers](https://miro.medium.com/v2/resize:fit:700/1*2e-uAc0hSvvdidQkFAZFmQ.png)

For each chosen feature, Random Forest looks at all possible split points in the sorted data (like temperature values 66.0, 69.0, 71.0, etc.) to find the best way to separate the data into two groups.

d. For each potential split point:  
· Divide samples into left and right groups  
· Calculate left child impurity using its samples  
· Calculate right child impurity using its samples  
· Calculate impurity reduction:  
parent\_impurity — (left\_weight × left\_impurity + right\_weight × right\_impurity)

![Image 13: a diagram showing the process of a number of numbers](https://miro.medium.com/v2/resize:fit:700/1*mhNv0BglEfXOxkyBJ6c2bg.png)

To find the best split point, Random Forest calculates Gini Impurity for each possible split, takes a weighted average based on group sizes, and picks the split that gives the biggest reduction in impurity from the parent node.

e. Split the current node data using the feature and split point that gives the highest impurity reduction. Then pass data points to the respective child nodes.

After comparing all possible splits, Random Forest picks the temperature threshold of 73.5°F as it gives the largest impurity reduction (0.041), creating two groups: one mixed group with temperatures below 73.5°F and one pure group.

f. For each child node, repeat the process (step b-e) until:  
\- Pure node or minimum impurity decrease  
\- Minimum samples threshold  
\- Maximum depth  
\- Maximum leaf nodes

![Image 15: a diagram showing the process of a cloud service](https://miro.medium.com/v2/resize:fit:700/1*QPkjzqkKWFGdwFI3VVZzGw.png)

This process continues for each new group (node): randomly select features, find the best split point, and divide the data further until each group is pure (all YES or all NO) or can’t be split anymore.

**Step 3: Tree Construction  
**Repeat the whole Step 2 for other bootstrap samples.

![Image 16: a tree diagram showing different types of water](https://miro.medium.com/v2/resize:fit:700/1*u9omyxuFVrVnM8HbmTCt3A.png)

Each decision tree in the Random Forest splits data in different ways using different features and thresholds. This variety helps the forest make better predictions than any single tree.

from sklearn.tree import plot\_tree  
from sklearn.ensemble import RandomForestClassifiernp.random.seed(42)    
rf = RandomForestClassifier(n\_estimators=100, random\_state=42)  
rf.fit(X\_train, y\_train)

trees\_to\_show = \[0, 1, 99\]    
feature\_names = X\_train.columns.tolist()  
class\_names = \['No', 'Yes'\]

fig, axes = plt.subplots(1, 3, figsize=(20, 6), dpi=300)    
fig.suptitle('Decision Trees from Random Forest', fontsize=16)

for idx, tree\_idx in enumerate(trees\_to\_show):  
    plot\_tree(rf.estimators\_\[tree\_idx\],   
              feature\_names=feature\_names,  
              class\_names=class\_names,  
              filled=True,  
              rounded=True,  
              ax=axes\[idx\],  
              fontsize=10)    
    axes\[idx\].set\_title(f'Tree {tree\_idx + 1}', fontsize=12)

plt.tight\_layout(rect=\[0, 0.03, 1, 0.95\])

![Image 17: a tree diagram showing different types of trees](https://miro.medium.com/v2/resize:fit:700/1*boY9Qp94g4ISXJig9TjWEQ.png)

Accessing the internal bootstrap indices directly isn’t possible in the current scikit-learn implementation so this gives different trees than the one calculated in our previous example.

Testing Step
------------

For prediction, route new samples through all trees and aggregate:  
\- Classification: majority vote  
\- Regression: mean prediction

When new data comes in, each tree in the Random Forest uses its own decision path to make a prediction. The forest combines all these predictions (74 YES vs 26 NO) and the majority vote becomes the final answer (YES in this case).

Out-of-Bag (OOB) Evaluation
---------------------------

Remember those samples that didn’t get used for training each tree — that leftover 1/3? Those are your OOB samples. Instead of just ignoring them, Random Forest uses them as a convenient validation set for each tree.

![Image 19: a diagram showing the process of a business](https://miro.medium.com/v2/resize:fit:700/1*iX_BcJIgo4xt7_pwhOp2uA.png)

Each tree gets tested on its own out-of-bag samples (data not used in its training). By averaging these individual OOB accuracy scores (50%, 66.6%, 60%), Random Forest provides a built-in way to measure performance without needing a separate test set.

Evaluation Step
---------------

After building all the trees, we can evaluate the test set.

![Image 20: a bar chart showing the percentage of the number of people who are using the app](https://miro.medium.com/v2/resize:fit:700/1*i9HhZ7Qb-PNAj8Dz1BS__g.png)

By combining multiple diverse decision trees and using majority voting, Random Forest achieves a high accuracy of 85.7% — typically better than single decision trees or simpler models!

Key Parameters
--------------

The key Random Forest parameters (especially in `scikit-learn`) include all Decision Tree parameters, plus some unique ones.

Random Forest-specific parameters
---------------------------------

*   ```
    oob_score  
    ```This uses leftover data (out-of-bag samples) to check how well the model works. This gives you a way to test your model without setting aside separate test data. It’s especially helpful with small datasets.
*   ```
    n_estimators  
    ```This parameter controls how many trees to build (default is 100).To find the optimal number of trees, **track the OOB error rate** as you add more trees to the forest. The error typically drops quickly at first, then levels off. **The point where it stabilizes suggests the optimal number** — adding more trees after this gives minimal improvement while increasing computation time.

  
n\_trees\_range = range(10, 201)  
oob\_errors = \[  
    1 - RandomForestClassifier(n\_estimators=n, oob\_score=True, random\_state=42).fit(X\_train, y\_train).oob\_score\_  
    for n in n\_trees\_range  
\]plt.figure(figsize=(7, 5), dpi=300)  
plt.plot(n\_trees\_range, oob\_errors, 'b-', linewidth=2)  
plt.xlabel('Number of Trees')  
plt.ylabel('Out-of-Bag Error Rate')  
plt.title('Random Forest OOB Error vs Number of Trees')  
plt.grid(True, alpha=0.2)  
plt.tight\_layout()

print("OOB Error by Number of Trees:")  
for i, error in enumerate(oob\_errors, 1):  
    if i % 10 == 0:  
        print(f"Trees: {i:3d}, OOB Error: {error:.4f}")

![Image 21: a table showing the number of trees in a tree](https://miro.medium.com/v2/resize:fit:700/1*QZGLjKBkq2Sv4GcJKALRgA.png)

![Image 22: random forest cdo error number of trees](https://miro.medium.com/v2/resize:fit:700/1*L2s739Wdeb89lNjtMLKznQ.png)

In our results, while around 27 trees showed the best score (0.2857), this early performance can be unreliable. Between 40–100 trees, the error rates settle around 0.5000, showing more consistent results. Using more than 100 trees doesn’t help and sometimes makes things worse. This suggests that using about 50–60 trees is a good choice — it’s stable, efficient, and reliable.

*   ```
    bootstrap  
    ```This decides whether each tree learns from a random sample of data (`True`) or uses all data ( `False`). The default (`True`) helps create different kinds of trees, which is key to how Random Forests work. Only consider **setting it to** `**False**` **when you have very little data** and can’t afford to skip any samples.
*   ```
    n_jobs  
    ```This controls how many processor cores to use during training. Setting it to `-1` uses all available cores, making training faster but using more memory. With big datasets, you might need to use fewer cores to avoid running out of memory.

Shared parameters with Decision Trees
-------------------------------------

The following parameters works the [same way as in Decision Tree](https://towardsdatascience.com/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e).

*   `max_depth`: Maximum tree depth
*   `min_samples_split`: Minimum samples needed to split a node
*   `min_samples_leaf`: Minimum samples required at leaf node

Compared to Decision Tree, here are key differences in parameter importance:

1.  ```
    max_depth  
    ```This matters less in Random Forests because combining many trees helps prevent overfitting, even with deeper trees. You can usually let trees grow deeper to catch complex patterns in your data.
2.  `min_samples_split` and ```
    min_samples_leaf  
    ```These are less important in Random Forests because using many trees naturally helps avoid overfitting. You can usually set these to smaller numbers than you would with a single decision tree.

Pros & Cons
-----------

Pros:
-----

1.  **Strong and Reliable:** Random Forests give accurate results and are less likely to overfit than single decision trees. By using random sampling and mixing up which features each tree considers at each node, they work well across many problems without needing much adjustment.
2.  **Feature Importance:** The model can tell you which features matter most in making predictions by measuring how much each feature helps across all trees. This helps you understand what drives your predictions.
3.  **Minimal Preprocessing:** Random Forests handle both numerical and categorical variables well without much preparation. They work well with missing values and outliers, and can find complex relationships in your data automatically.

Cons:
-----

1.  **Computational Cost:** Training and using the model takes more time as you add more trees or make them deeper. While you can speed up training by using multiple processors, it still needs substantial computing power for big datasets.
2.  **Limited Interpretability:** While you can see which features are important overall, it’s harder to understand exactly why the model made a specific prediction, unlike with single decision trees. This can be a problem when you need to explain each decision.
3.  **Prediction Speed:** To make a prediction, data must go through all trees and then combine their answers. This makes Random Forests slower than simpler models, which might be an issue for real-time applications.

Final Remarks
-------------

I’ve grown to really like Random Forests after seeing how well they work in practice. By combining multiple trees and letting each one learn from different parts of the data, they consistently make better predictions — of course, more than using just one tree alone.

While you do need to adjust some settings like the number of trees, they usually perform well even without much fine-tuning. They do need more computing power (and sometimes struggle with rare cases in the data) but their reliable performance and ease of use make them my go-to choice for many projects. It’s clear why so many data scientists feel the same way!

🌟 Random Forest Classifier Code Summarized
-------------------------------------------

import pandas as pd  
import numpy as np  
from sklearn.model\_selection import train\_test\_split  
from sklearn.metrics import accuracy\_score  
from sklearn.ensemble import RandomForestClassifierdataset\_dict = {  
    'Outlook': \['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast',   
                'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy',  
                'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast',  
                'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'\],  
    'Temperature': \[85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0,  
                   72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0,  
                   88.0, 77.0, 79.0, 80.0, 66.0, 84.0\],  
    'Humidity': \[85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0,  
                 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0,  
                 65.0, 70.0, 60.0, 95.0, 70.0, 78.0\],  
    'Wind': \[False, True, False, False, False, True, True, False, False, False, True,  
             True, False, True, True, False, False, True, False, True, True, False,  
             True, False, False, True, False, False\],  
    'Play': \['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',  
             'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',  
             'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes'\]  
}

df = pd.DataFrame(dataset\_dict)  
df = pd.get\_dummies(df, columns=\['Outlook'\], prefix='', prefix\_sep='', dtype=int)  
df\['Wind'\] = df\['Wind'\].astype(int)  
df\['Play'\] = (df\['Play'\] == 'Yes').astype(int)

column\_order = \['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind', 'Play'\]  
df = df\[column\_order\]

X, y = df.drop('Play', axis=1), df\['Play'\]  
X\_train, X\_test, y\_train, y\_test = train\_test\_split(X, y, train\_size=0.5, shuffle=False)

rf = RandomForestClassifier(n\_estimators=100, max\_features='sqrt', random\_state=42)  
rf.fit(X\_train, y\_train)

y\_pred = rf.predict(X\_test)  
print(f"Accuracy: {accuracy\_score(y\_test, y\_pred)}")

🌟 Random Forest Regressor Code Summarized
------------------------------------------

import pandas as pd  
import numpy as np  
from sklearn.model\_selection import train\_test\_split  
from sklearn.metrics import root\_mean\_squared\_error  
from sklearn.ensemble import RandomForestRegressordataset\_dict = {  
    'Outlook': \['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast',   
                'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain',  
                'sunny', 'overcast', 'rain', 'sunny', 'sunny', 'rain', 'overcast',  
                'rain', 'sunny', 'overcast', 'sunny', 'overcast', 'rain', 'overcast'\],  
    'Temp.': \[85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0,  
              72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0,  
              88.0, 77.0, 79.0, 80.0, 66.0, 84.0\],  
    'Humid.': \[85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0,  
               90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0,  
               65.0, 70.0, 60.0, 95.0, 70.0, 78.0\],  
    'Wind': \[False, True, False, False, False, True, True, False, False, False, True,  
             True, False, True, True, False, False, True, False, True, True, False,  
             True, False, False, True, False, False\],  
    'Num\_Players': \[52, 39, 43, 37, 28, 19, 43, 47, 56, 33, 49, 23, 42, 13, 33, 29,  
                    25, 51, 41, 14, 34, 29, 49, 36, 57, 21, 23, 41\]  
}

df = pd.DataFrame(dataset\_dict)  
df = pd.get\_dummies(df, columns=\['Outlook'\], prefix='', prefix\_sep='')  
df\['Wind'\] = df\['Wind'\].astype(int)

X, y = df.drop('Num\_Players', axis=1), df\['Num\_Players'\]  
X\_train, X\_test, y\_train, y\_test = train\_test\_split(X, y, train\_size=0.5, shuffle=False)

rf = RandomForestRegressor(n\_estimators=100, max\_features='sqrt', random\_state=42)  
rf.fit(X\_train, y\_train)

y\_pred = rf.predict(X\_test)  
rmse = root\_mean\_squared\_error(y\_test, y\_pred)

print(f"Root Mean Squared Error: {rmse:.2f}")

Further Reading
---------------

For a detailed explanation of the [RandomForestClassifier](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) and its implementation in scikit-learn, readers can refer to the official documentation, which provides comprehensive information on its usage and parameters.

Technical Environment
---------------------

This article uses Python 3.7 and scikit-learn 1.5. While the concepts discussed are generally applicable, specific code implementations may vary slightly with different versions.

About the Illustrations
-----------------------

Unless otherwise noted, all images are created by the author, incorporating licensed design elements from Canva Pro.


## Visual Content Analysis

### Image Analysis
Title: Random Forest | Towards Data Science

URL Source: https://medium.com/towards-data-science/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c

Published Time: 2024-11-07T13:02:11.895Z

Markdown Content:
ENSEMBLE LEARNING
-----------------

Random Forest, Explained: A Visual Guide with Code Examples
-----------------------------------------------------------

Making tree-mendous predictions with random trees
-------------------------------------------------

[![Image 1: Samy Baladram](https://miro.medium.com/v2/resize:fill:88:88/1*M5J7CK552m9f4z-m1F7vYg.png)](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)

[Decision trees](https://towardsdatascience.com/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e) are a great starting point in machine learning — they’re clear and make sense. But there’s a catch: they often don’t work well when dealing with new data. The predictions can be inconsistent and unreliable, which is a real problem when you’re trying to build something useful.

This is where Random Forest comes in. It takes what’s good about decision trees and makes them work better by combining multiple trees together. It’s become a favorite tool for many data scientists because it’s both effective and practical.

Let’s see how Random Forest works and why it might be exactly what you need for your next project. It’s time to stop getting lost in the trees and see the forest for what it really is — your next reliable tool in machine learning.

![Image 3: a cartoon character is standing in front of a bunch of trees](https://miro.medium.com/v2/resize:fit:700/1*FBhxEgEzbfYWiSK0LYOv6g.gif)

All visuals: Author-created using Canva Pro. Optimized for mobile; may appear oversized on desktop.

Definition
----------

A Random Forest is an ensemble machine learning model that combines multiple decision trees. Each tree in the forest is trained on a random sample of the data (bootstrap sampling) and considers only a random subset of features when making splits (feature randomization).

For classification tasks, the forest predicts by majority voting among trees, while for regression tasks, it averages the predictions. The model’s strength comes from its “wisdom of crowds” approach — while individual trees might make errors, the collective decision-making process **tends to average out these mistakes** and arrive at more reliable predictions.

Random Forest is a part of bagging (bootstrap aggregating) algorithm because it builds each tree using different random part of data and combines their answers together.

Dataset Used
------------

Throughout this article, we’ll focus on the classic golf dataset as an example for classification. While Random Forests can handle both classification and regression tasks equally well, we’ll concentrate on the classification part — predicting whether someone will play golf based on weather conditions. The concepts we’ll explore can be easily adapted to regression problems (like predicting number of player) using the same principles.

![Image 5: a table with different numbers and numbers](https://miro.medium.com/v2/resize:fit:700/1*O0_DqZWXc5OM--Zxp3_uuw.png)

Columns: ‘Overcast (one-hot-encoded into 3 columns)’, ’Temperature’ (in Fahrenheit), ‘Humidity’ (in %), ‘Windy’ (Yes/No) and ‘Play’ (Yes/No, target feature)

import pandas as pd  
import numpy as np  
from sklearn.model\_selection import train\_test\_splitdataset\_dict = {  
    'Outlook': \['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast',   
                'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy',  
                'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast',  
                'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'\],  
    'Temperature': \[85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0,  
                   72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0,  
                   88.0, 77.0, 79.0, 80.0, 66.0, 84.0\],  
    'Humidity': \[85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0,  
                 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0,  
                 65.0, 70.0, 60.0, 95.0, 70.0, 78.0\],  
    'Wind': \[False, True, False, False, False, True, True, False, False, False, True,  
             True, False, True, True, False, False, True, False, True, True, False,  
             True, False, False, True, False, False\],  
    'Play': \['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',  
             'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',  
             'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes'\]  
}

df = pd.DataFrame(dataset\_dict)  
df = pd.get\_dummies(df, columns=\['Outlook'\], prefix='', prefix\_sep='', dtype=int)  
df\['Wind'\] = df\['Wind'\].astype(int)  
df\['Play'\] = (df\['Play'\] == 'Yes').astype(int)

column\_order = \['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind', 'Play'\]  
df = df\[column\_order\]

X,y = df.drop('Play', axis=1), df\['Play'\]  
X\_train, X\_test, y\_train, y\_test = train\_test\_split(X, y, train\_size=0.5, shuffle=False)

Main Mechanism
--------------

Here’s how Random Forest works:

1.  **Bootstrap Sampling:** Each tree gets its own unique training set, created by randomly sampling from the original data with replacement. This means some data points may appear multiple times while others aren’t used.
2.  **Random Feature Selection:** When making a split, each tree only considers a random subset of features (typically square root of total features).
3.  **Growing Trees:** Each tree grows using only its bootstrap sample and selected features, making splits until it reaches a stopping point (like pure groups or minimum sample size).
4.  **Final Prediction:** All trees vote together for the final prediction. For classification, take the majority vote of class predictions; for regression, average the predicted values from all trees.

![Image 6: a diagram showing the process of a data model](https://miro.medium.com/v2/resize:fit:700/1*FisK9hkTkWP2D92ANxAp9w.png)

A Random Forest Classifier makes predictions by combining results from 100 different decision trees, each analyzing features like temperature and outlook conditions. The final prediction comes from the most common answer among all trees.

Training Steps
--------------

The Random Forest algorithm constructs multiple decision trees and combines them. Here’s how it works:

**Step 1: Bootstrap Sample Creation**  
1.0. Set the number of trees (default = 100)  
1.1. For each tree in the forest:  
a. Create new training set by random sampling original data with replacement until reaching original dataset size. This is called **bootstrap sampling**.  
b. Mark and set aside non-selected samples as out-of-bag (OOB) samples for later error estimation

Random Forest creates different training sets for each tree by randomly picking data points from the original training set, with some numbers appearing multiple times. The unused data points become test sets for checking each tree’s performance.

  
n\_samples = len(X\_train)  
n\_bootstraps = 100  
all\_bootstrap\_indices = \[\]  
all\_oob\_indices = \[\]np.random.seed(42)    
for i in range(n\_bootstraps):  
      
    bootstrap\_indices = np.random.choice(n\_samples, size=n\_samples, replace=True)

oob\_indices = list(set(range(n\_samples)) - set(bootstrap\_indices))

all\_bootstrap\_indices.append(bootstrap\_indices)  
    all\_oob\_indices.append(oob\_indices)

samples\_to\_show = \[0, 1, 99\]

for i in samples\_to\_show:  
    print(f"\\nBootstrap Sample {i+1}:")  
    print(f"Chosen indices: {sorted(all\_bootstrap\_indices\[i\])}")  
    print(f"Number of unique chosen indices: {len(set(all\_bootstrap\_indices\[i\]))}")  
    print(f"OOB indices: {sorted(all\_oob\_indices\[i\])}")  
    print(f"Number of OOB samples: {len(all\_oob\_indices\[i\])}")  
    print(f"Percentage of OOB: {len(all\_oob\_indices\[i\])/n\_samples\*100:.1f}%")

![Image 8: a table with different numbers and numbers](https://miro.medium.com/v2/resize:fit:700/1*_smMUwVcgHdpla5vGIDVrw.png)

Notice how similar the percentages of OOB above? When doing bootstrap sampling of _n_ samples, each individual sample has about a 37% chance of never being picked. This comes from the probability calculation (1–1/_n_)_ⁿ_, which approaches 1/e ≈ 0.368 as _n_ gets larger. That’s why each tree ends up using roughly 63% of the data for training, with the remaining 37% becoming OOB samples.

**Step 2: Tree Construction**  
2.1. Start at root node with complete bootstrap sample

![Image 9: a table with a number of numbers and a number of numbers](https://miro.medium.com/v2/resize:fit:700/1*v4X7vEWV5j1oOfEX4R5lRw.png)

When building each decision tree, Random Forest considers a subset of data points and creates splits based on questions about their values — sending smaller values to the left and larger values to the right to make predictions.

a. Calculate initial node impurity using all samples in node  
· Classification: Gini or entropy  
· Regression: MSE

![Image 10: a screen showing the number of a number and the number of a number](https://miro.medium.com/v2/resize:fit:700/1*zNarI6dKgX4FiJjFyD3n2Q.png)

Random Forest starts by calculating the Gini Impurity of the entire dataset (before any splits) using the ratio of YES and NO labels — a measure of how mixed the labels are in the current data.

b. Select random subset of features from total available features:  
· Classification: √n\_features  
· Regression: n\_features/3

For each split in a tree, Random Forest randomly picks a subset of weather features (here 2 out of 6) to consider, making each tree focus on different aspects of the data.

c. For each selected feature:  
· Sort data points by feature values  
· Identify potential split points (midpoints between consecutive unique feature values)

![Image 12: a table with different numbers and numbers](https://miro.medium.com/v2/resize:fit:700/1*2e-uAc0hSvvdidQkFAZFmQ.png)

For each chosen feature, Random Forest looks at all possible split points in the sorted data (like temperature values 66.0, 69.0, 71.0, etc.) to find the best way to separate the data into two groups.

d. For each potential split point:  
· Divide samples into left and right groups  
· Calculate left child impurity using its samples  
· Calculate right child impurity using its samples  
· Calculate impurity reduction:  
parent\_impurity — (left\_weight × left\_impurity + right\_weight × right\_impurity)

![Image 13: a diagram showing the process of a number of numbers](https://miro.medium.com/v2/resize:fit:700/1*mhNv0BglEfXOxkyBJ6c2bg.png)

To find the best split point, Random Forest calculates Gini Impurity for each possible split, takes a weighted average based on group sizes, and picks the split that gives the biggest reduction in impurity from the parent node.

e. Split the current node data using the feature and split point that gives the highest impurity reduction. Then pass data points to the respective child nodes.

After comparing all possible splits, Random Forest picks the temperature threshold of 73.5°F as it gives the largest impurity reduction (0.041), creating two groups: one mixed group with temperatures below 73.5°F and one pure group.

f. For each child node, repeat the process (step b-e) until:  
\- Pure node or minimum impurity decrease  
\- Minimum samples threshold  
\- Maximum depth  
\- Maximum leaf nodes

![Image 15: a diagram showing the process of a cloud service](https://miro.medium.com/v2/resize:fit:700/1*QPkjzqkKWFGdwFI3VVZzGw.png)

This process continues for each new group (node): randomly select features, find the best split point, and divide the data further until each group is pure (all YES or all NO) or can’t be split anymore.

**Step 3: Tree Construction  
**Repeat the whole Step 2 for other bootstrap samples.

![Image 16: a tree diagram showing different types of water](https://miro.medium.com/v2/resize:fit:700/1*u9omyxuFVrVnM8HbmTCt3A.png)

Each decision tree in the Random Forest splits data in different ways using different features and thresholds. This variety helps the forest make better predictions than any single tree.

from sklearn.tree import plot\_tree  
from sklearn.ensemble import RandomForestClassifiernp.random.seed(42)    
rf = RandomForestClassifier(n\_estimators=100, random\_state=42)  
rf.fit(X\_train, y\_train)

trees\_to\_show = \[0, 1, 99\]    
feature\_names = X\_train.columns.tolist()  
class\_names = \['No', 'Yes'\]

fig, axes = plt.subplots(1, 3, figsize=(20, 6), dpi=300)    
fig.suptitle('Decision Trees from Random Forest', fontsize=16)

for idx, tree\_idx in enumerate(trees\_to\_show):  
    plot\_tree(rf.estimators\_\[tree\_idx\],   
              feature\_names=feature\_names,  
              class\_names=class\_names,  
              filled=True,  
              rounded=True,  
              ax=axes\[idx\],  
              fontsize=10)    
    axes\[idx\].set\_title(f'Tree {tree\_idx + 1}', fontsize=12)

plt.tight\_layout(rect=\[0, 0.03, 1, 0.95\])

![Image 17: a tree diagram showing different types of trees](https://miro.medium.com/v2/resize:fit:700/1*boY9Qp94g4ISXJig9TjWEQ.png)

Accessing the internal bootstrap indices directly isn’t possible in the current scikit-learn implementation so this gives different trees than the one calculated in our previous example.

Testing Step
------------

For prediction, route new samples through all trees and aggregate:  
\- Classification: majority vote  
\- Regression: mean prediction

When new data comes in, each tree in the Random Forest uses its own decision path to make a prediction. The forest combines all these predictions (74 YES vs 26 NO) and the majority vote becomes the final answer (YES in this case).

Out-of-Bag (OOB) Evaluation
---------------------------

Remember those samples that didn’t get used for training each tree — that leftover 1/3? Those are your OOB samples. Instead of just ignoring them, Random Forest uses them as a convenient validation set for each tree.

![Image 19: a diagram showing the process of a business](https://miro.medium.com/v2/resize:fit:700/1*iX_BcJIgo4xt7_pwhOp2uA.png)

Each tree gets tested on its own out-of-bag samples (data not used in its training). By averaging these individual OOB accuracy scores (50%, 66.6%, 60%), Random Forest provides a built-in way to measure performance without needing a separate test set.

Evaluation Step
---------------

After building all the trees, we can evaluate the test set.

![Image 20: a bar chart showing the percentage of the number of people who are using the app](https://miro.medium.com/v2/resize:fit:700/1*i9HhZ7Qb-PNAj8Dz1BS__g.png)

By combining multiple diverse decision trees and using majority voting, Random Forest achieves a high accuracy of 85.7% — typically better than single decision trees or simpler models!

Key Parameters
--------------

The key Random Forest parameters (especially in `scikit-learn`) include all Decision Tree parameters, plus some unique ones.

Random Forest-specific parameters
---------------------------------

*   ```
    oob_score  
    ```This uses leftover data (out-of-bag samples) to check how well the model works. This gives you a way to test your model without setting aside separate test data. It’s especially helpful with small datasets.
*   ```
    n_estimators  
    ```This parameter controls how many trees to build (default is 100).To find the optimal number of trees, **track the OOB error rate** as you add more trees to the forest. The error typically drops quickly at first, then levels off. **The point where it stabilizes suggests the optimal number** — adding more trees after this gives minimal improvement while increasing computation time.

  
n\_trees\_range = range(10, 201)  
oob\_errors = \[  
    1 - RandomForestClassifier(n\_estimators=n, oob\_score=True, random\_state=42).fit(X\_train, y\_train).oob\_score\_  
    for n in n\_trees\_range  
\]plt.figure(figsize=(7, 5), dpi=300)  
plt.plot(n\_trees\_range, oob\_errors, 'b-', linewidth=2)  
plt.xlabel('Number of Trees')  
plt.ylabel('Out-of-Bag Error Rate')  
plt.title('Random Forest OOB Error vs Number of Trees')  
plt.grid(True, alpha=0.2)  
plt.tight\_layout()

print("OOB Error by Number of Trees:")  
for i, error in enumerate(oob\_errors, 1):  
    if i % 10 == 0:  
        print(f"Trees: {i:3d}, OOB Error: {error:.4f}")

![Image 21: a table showing the number of trees in a tree](https://miro.medium.com/v2/resize:fit:700/1*QZGLjKBkq2Sv4GcJKALRgA.png)

![Image 22: random forest cdo error number of trees](https://miro.medium.com/v2/resize:fit:700/1*L2s739Wdeb89lNjtMLKznQ.png)

In our results, while around 27 trees showed the best score (0.2857), this early performance can be unreliable. Between 40–100 trees, the error rates settle around 0.5000, showing more consistent results. Using more than 100 trees doesn’t help and sometimes makes things worse. This suggests that using about 50–60 trees is a good choice — it’s stable, efficient, and reliable.

*   ```
    bootstrap  
    ```This decides whether each tree learns from a random sample of data (`True`) or uses all data ( `False`). The default (`True`) helps create different kinds of trees, which is key to how Random Forests work. Only consider **setting it to** `**False**` **when you have very little data** and can’t afford to skip any samples.
*   ```
    n_jobs  
    ```This controls how many processor cores to use during training. Setting it to `-1` uses all available cores, making training faster but using more memory. With big datasets, you might need to use fewer cores to avoid running out of memory.

Shared parameters with Decision Trees
-------------------------------------

The following parameters works the [same way as in Decision Tree](https://towardsdatascience.com/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e).

*   `max_depth`: Maximum tree depth
*   `min_samples_split`: Minimum samples needed to split a node
*   `min_samples_leaf`: Minimum samples required at leaf node

Compared to Decision Tree, here are key differences in parameter importance:

1.  ```
    max_depth  
    ```This matters less in Random Forests because combining many trees helps prevent overfitting, even with deeper trees. You can usually let trees grow deeper to catch complex patterns in your data.
2.  `min_samples_split` and ```
    min_samples_leaf  
    ```These are less important in Random Forests because using many trees naturally helps avoid overfitting. You can usually set these to smaller numbers than you would with a single decision tree.

Pros & Cons
-----------

Pros:
-----

1.  **Strong and Reliable:** Random Forests give accurate results and are less likely to overfit than single decision trees. By using random sampling and mixing up which features each tree considers at each node, they work well across many problems without needing much adjustment.
2.  **Feature Importance:** The model can tell you which features matter most in making predictions by measuring how much each feature helps across all trees. This helps you understand what drives your predictions.
3.  **Minimal Preprocessing:** Random Forests handle both numerical and categorical variables well without much preparation. They work well with missing values and outliers, and can find complex relationships in your data automatically.

Cons:
-----

1.  **Computational Cost:** Training and using the model takes more time as you add more trees or make them deeper. While you can speed up training by using multiple processors, it still needs substantial computing power for big datasets.
2.  **Limited Interpretability:** While you can see which features are important overall, it’s harder to understand exactly why the model made a specific prediction, unlike with single decision trees. This can be a problem when you need to explain each decision.
3.  **Prediction Speed:** To make a prediction, data must go through all trees and then combine their answers. This makes Random Forests slower than simpler models, which might be an issue for real-time applications.

Final Remarks
-------------

I’ve grown to really like Random Forests after seeing how well they work in practice. By combining multiple trees and letting each one learn from different parts of the data, they consistently make better predictions — of course, more than using just one tree alone.

While you do need to adjust some settings like the number of trees, they usually perform well even without much fine-tuning. They do need more computing power (and sometimes struggle with rare cases in the data) but their reliable performance and ease of use make them my go-to choice for many projects. It’s clear why so many data scientists feel the same way!

🌟 Random Forest Classifier Code Summarized
-------------------------------------------

import pandas as pd  
import numpy as np  
from sklearn.model\_selection import train\_test\_split  
from sklearn.metrics import accuracy\_score  
from sklearn.ensemble import RandomForestClassifierdataset\_dict = {  
    'Outlook': \['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast',   
                'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy',  
                'sunny', 'overcast', 'rainy', 'sunny', 'sunny', 'rainy', 'overcast',  
                'rainy', 'sunny', 'overcast', 'sunny', 'overcast', 'rainy', 'overcast'\],  
    'Temperature': \[85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0,  
                   72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0,  
                   88.0, 77.0, 79.0, 80.0, 66.0, 84.0\],  
    'Humidity': \[85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0,  
                 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0,  
                 65.0, 70.0, 60.0, 95.0, 70.0, 78.0\],  
    'Wind': \[False, True, False, False, False, True, True, False, False, False, True,  
             True, False, True, True, False, False, True, False, True, True, False,  
             True, False, False, True, False, False\],  
    'Play': \['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',  
             'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',  
             'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes'\]  
}

df = pd.DataFrame(dataset\_dict)  
df = pd.get\_dummies(df, columns=\['Outlook'\], prefix='', prefix\_sep='', dtype=int)  
df\['Wind'\] = df\['Wind'\].astype(int)  
df\['Play'\] = (df\['Play'\] == 'Yes').astype(int)

column\_order = \['sunny', 'overcast', 'rainy', 'Temperature', 'Humidity', 'Wind', 'Play'\]  
df = df\[column\_order\]

X, y = df.drop('Play', axis=1), df\['Play'\]  
X\_train, X\_test, y\_train, y\_test = train\_test\_split(X, y, train\_size=0.5, shuffle=False)

rf = RandomForestClassifier(n\_estimators=100, max\_features='sqrt', random\_state=42)  
rf.fit(X\_train, y\_train)

y\_pred = rf.predict(X\_test)  
print(f"Accuracy: {accuracy\_score(y\_test, y\_pred)}")

🌟 Random Forest Regressor Code Summarized
------------------------------------------

import pandas as pd  
import numpy as np  
from sklearn.model\_selection import train\_test\_split  
from sklearn.metrics import root\_mean\_squared\_error  
from sklearn.ensemble import RandomForestRegressordataset\_dict = {  
    'Outlook': \['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast',   
                'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain',  
                'sunny', 'overcast', 'rain', 'sunny', 'sunny', 'rain', 'overcast',  
                'rain', 'sunny', 'overcast', 'sunny', 'overcast', 'rain', 'overcast'\],  
    'Temp.': \[85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0,  
              72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0,  
              88.0, 77.0, 79.0, 80.0, 66.0, 84.0\],  
    'Humid.': \[85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0,  
               90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0,  
               65.0, 70.0, 60.0, 95.0, 70.0, 78.0\],  
    'Wind': \[False, True, False, False, False, True, True, False, False, False, True,  
             True, False, True, True, False, False, True, False, True, True, False,  
             True, False, False, True, False, False\],  
    'Num\_Players': \[52, 39, 43, 37, 28, 19, 43, 47, 56, 33, 49, 23, 42, 13, 33, 29,  
                    25, 51, 41, 14, 34, 29, 49, 36, 57, 21, 23, 41\]  
}

df = pd.DataFrame(dataset\_dict)  
df = pd.get\_dummies(df, columns=\['Outlook'\], prefix='', prefix\_sep='')  
df\['Wind'\] = df\['Wind'\].astype(int)

X, y = df.drop('Num\_Players', axis=1), df\['Num\_Players'\]  
X\_train, X\_test, y\_train, y\_test = train\_test\_split(X, y, train\_size=0.5, shuffle=False)

rf = RandomForestRegressor(n\_estimators=100, max\_features='sqrt', random\_state=42)  
rf.fit(X\_train, y\_train)

y\_pred = rf.predict(X\_test)  
rmse = root\_mean\_squared\_error(y\_test, y\_pred)

print(f"Root Mean Squared Error: {rmse:.2f}")

Further Reading
---------------

For a detailed explanation of the [RandomForestClassifier](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) and its implementation in scikit-learn, readers can refer to the official documentation, which provides comprehensive information on its usage and parameters.

Technical Environment
---------------------

This article uses Python 3.7 and scikit-learn 1.5. While the concepts discussed are generally applicable, specific code implementations may vary slightly with different versions.

About the Illustrations
-----------------------

Unless otherwise noted, all images are created by the author, incorporating licensed design elements from Canva Pro.


---

## https://medium.com/towards-data-science/machine-learning-in-fraud-detection-a-primer-8005b8c88cde

Title: Machine Learning in Fraud Detection: A Primer - Towards Data Science

URL Source: https://medium.com/towards-data-science/machine-learning-in-fraud-detection-a-primer-8005b8c88cde

Published Time: 2024-11-12T01:11:59.924Z

Markdown Content:
Machine Learning in Fraud Detection: A Primer | by Samuel Flender | Nov, 2024 | Towards Data Science
===============
 

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

Machine Learning in Fraud Detection: A Primer
=============================================

Balancing automation, accuracy, and customer experience in an ever-evolving adversarial landscape
-------------------------------------------------------------------------------------------------

[![Image 2: Samuel Flender](https://miro.medium.com/v2/resize:fill:88:88/1*IHdofFy_lqh1Dpw4uhZkcw.jpeg)](https://medium.com/@samuel.flender?source=post_page---byline--8005b8c88cde--------------------------------)

[Samuel Flender](https://medium.com/@samuel.flender?source=post_page---byline--8005b8c88cde--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce56d9dcd568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=post_page-ce56d9dcd568--byline--8005b8c88cde---------------------post_header-----------)

[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8005b8c88cde--------------------------------)

23 hours ago

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=---header_actions--8005b8c88cde---------------------clap_footer-----------)

99

2

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=---header_actions--8005b8c88cde---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=---header_actions--8005b8c88cde---------------------post_audio_button-----------)

![Image 4: a bunch of credit cards flying in the air](https://miro.medium.com/v2/resize:fit:700/1*HEiY7mmh8adk3ZIObebB6g.png)

Fraud detection is a cornerstone of modern e-commerce, yet it is also one of the least publicized domains in Machine Learning. That’s for a good reason: it’s an adversarial domain, where fraudsters constantly invent new ways to bypass existing models, and model developers constantly invent new ways to catch them.

The goal of fraud detection systems is to block fraudulent transactions, such as those placed by fake accounts using stolen credit cards, while at the same time preventing any friction to the shopping experience of genuine customers. False negatives (fraud transactions that mistakenly went through the system) result in monetary loss also known as ‘bad debt’ due to chargebacks initiated by the actual credit card owners, while false positives (genuine transactions that were blocked) result in poor customer experience and churn.

Consider that a modern e-commerce provider may process somewhere in the order of tens of Millions of orders per day, and that fraud rates are at the sub-percent level, and you’re starting to see why this is a challenging domain. It’s the ultimate needle-in-a-haystack problem, where the haystacks are overwhelmingly large and…

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde%3Fsource%3D-----8005b8c88cde---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----8005b8c88cde---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde%3Fsource%3D-----8005b8c88cde---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----8005b8c88cde---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde%3Fsource%3D-----8005b8c88cde---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----8005b8c88cde---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=-----8005b8c88cde---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=---footer_actions--8005b8c88cde---------------------clap_footer-----------)

99

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=---footer_actions--8005b8c88cde---------------------clap_footer-----------)

99

2

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=---footer_actions--8005b8c88cde---------------------bookmark_footer-----------)

[![Image 5: Samuel Flender](https://miro.medium.com/v2/resize:fill:144:144/1*IHdofFy_lqh1Dpw4uhZkcw.jpeg)](https://medium.com/@samuel.flender?source=post_page---post_author_info--8005b8c88cde--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce56d9dcd568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=post_page-ce56d9dcd568--post_author_info--8005b8c88cde---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F89b071bfd3ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&newsletterV3=ce56d9dcd568&newsletterV3Id=89b071bfd3ab&user=Samuel+Flender&userId=ce56d9dcd568&source=---post_author_info--8005b8c88cde---------------------subscribe_user-----------)

[Written by Samuel Flender -------------------------](https://medium.com/@samuel.flender?source=post_page---post_author_info--8005b8c88cde--------------------------------)

[3.8K Followers](https://medium.com/@samuel.flender/followers?source=post_page---post_author_info--8005b8c88cde--------------------------------)

[Towards Data Science](https://towardsdatascience.com/?source=post_page---post_author_info--8005b8c88cde--------------------------------)

Cutting-edge ML research, simplified. For the latest, subscribe to my Newsletter: [mlfrontiers.substack.com](http://mlfrontiers.substack.com/)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce56d9dcd568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=post_page-ce56d9dcd568--post_author_info--8005b8c88cde---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F89b071bfd3ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&newsletterV3=ce56d9dcd568&newsletterV3Id=89b071bfd3ab&user=Samuel+Flender&userId=ce56d9dcd568&source=---post_author_info--8005b8c88cde---------------------subscribe_user-----------)

More from Samuel Flender and Towards Data Science
-------------------------------------------------

![Image 7: How I Cracked the Meta Machine Learning Engineering Interview](https://miro.medium.com/v2/resize:fit:679/0*uP6vp3RUAMz5DSkR)

[![Image 8: Samuel Flender](https://miro.medium.com/v2/resize:fill:20:20/1*IHdofFy_lqh1Dpw4uhZkcw.jpeg)](https://medium.com/@samuel.flender?source=author_recirc-----8005b8c88cde----0---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Samuel Flender](https://medium.com/@samuel.flender?source=author_recirc-----8005b8c88cde----0---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----8005b8c88cde----0---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[How I Cracked the Meta Machine Learning Engineering Interview ------------------------------------------------------------- ### Practical tips for the coding, design, and behavior rounds](https://medium.com/how-i-cracked-the-meta-machine-learning-engineering-interview-aa32f64b8e4b?source=author_recirc-----8005b8c88cde----0---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

Oct 25, 2022

[1.99K 11](https://medium.com/how-i-cracked-the-meta-machine-learning-engineering-interview-aa32f64b8e4b?source=author_recirc-----8005b8c88cde----0---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faa32f64b8e4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-cracked-the-meta-machine-learning-engineering-interview-aa32f64b8e4b&source=-----8005b8c88cde----0-----------------bookmark_preview----b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

![Image 9: Advanced Time Series Forecasting With sktime](https://miro.medium.com/v2/resize:fit:679/0*IRO3Gw2zZu4Yk3ne)

[![Image 10: Dr. Robert Kübler](https://miro.medium.com/v2/resize:fill:20:20/2*kfj1GnUxOj_3CjyaJK1dYQ.jpeg)](https://dr-robert-kuebler.medium.com/?source=author_recirc-----8005b8c88cde----1---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Dr. Robert Kübler](https://dr-robert-kuebler.medium.com/?source=author_recirc-----8005b8c88cde----1---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----8005b8c88cde----1---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Advanced Time Series Forecasting With sktime -------------------------------------------- ### Learn how to optimize model hyperparameters and even the architecture in a few lines of code](https://medium.com/advanced-time-series-forecasting-with-sktime-af8eabc76173?source=author_recirc-----8005b8c88cde----1---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[104 1](https://medium.com/advanced-time-series-forecasting-with-sktime-af8eabc76173?source=author_recirc-----8005b8c88cde----1---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf8eabc76173&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-time-series-forecasting-with-sktime-af8eabc76173&source=-----8005b8c88cde----1-----------------bookmark_preview----b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

![Image 11: The Statistical Significance Scam](https://miro.medium.com/v2/resize:fit:679/1*fUigVfmuyNJLUFY6m-lZUw.jpeg)

[![Image 12: Cai Parry-Jones](https://miro.medium.com/v2/resize:fill:20:20/0*GWV4mbIw3Ex5l9PC)](https://medium.com/@caiparryjones96?source=author_recirc-----8005b8c88cde----2---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Cai Parry-Jones](https://medium.com/@caiparryjones96?source=author_recirc-----8005b8c88cde----2---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----8005b8c88cde----2---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[The Statistical Significance Scam --------------------------------- ### A detailed look into the flaws of science’s favorite tool](https://medium.com/the-statistical-significance-scam-db904be36714?source=author_recirc-----8005b8c88cde----2---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[581 4](https://medium.com/the-statistical-significance-scam-db904be36714?source=author_recirc-----8005b8c88cde----2---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdb904be36714&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-statistical-significance-scam-db904be36714&source=-----8005b8c88cde----2-----------------bookmark_preview----b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

![Image 13: Class Imbalance in Machine Learning Problems: A Practical Guide](https://miro.medium.com/v2/resize:fit:679/0*_Dt8SwZ4oNdovZsA)

[![Image 14: Samuel Flender](https://miro.medium.com/v2/resize:fill:20:20/1*IHdofFy_lqh1Dpw4uhZkcw.jpeg)](https://medium.com/@samuel.flender?source=author_recirc-----8005b8c88cde----3---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Samuel Flender](https://medium.com/@samuel.flender?source=author_recirc-----8005b8c88cde----3---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----8005b8c88cde----3---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Class Imbalance in Machine Learning Problems: A Practical Guide --------------------------------------------------------------- ### Five lessons from the trenches of applied data science](https://medium.com/class-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041?source=author_recirc-----8005b8c88cde----3---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

Oct 3, 2022

[521 3](https://medium.com/class-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041?source=author_recirc-----8005b8c88cde----3---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4fb81eee0041&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041&source=-----8005b8c88cde----3-----------------bookmark_preview----b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[See all from Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----8005b8c88cde--------------------------------)

[See all from Towards Data Science](https://towardsdatascience.com/?source=post_page-----8005b8c88cde--------------------------------)

![Image 15: Programming a Service Robot to Do My Chores With Behavior Trees](https://miro.medium.com/v2/resize:fit:679/1*O990kX0_AsScV4P3LHZgDg.png)

[![Image 16: Carlos Argueta](https://miro.medium.com/v2/resize:fill:20:20/1*SEVvEjjsV6WB6SpBz5lubw.jpeg)](https://soulhackerslabs.com/?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Carlos Argueta](https://soulhackerslabs.com/?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Programming a Service Robot to Do My Chores With Behavior Trees --------------------------------------------------------------- ### Learn how Behavior Trees enable complex, flexible robot behaviors for autonomous tasks in robotics. Ideal for AI and ML applications.](https://soulhackerslabs.com/programming-a-service-robot-to-do-my-chores-with-behavior-trees-cbbc7d7ff928?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[272 7](https://soulhackerslabs.com/programming-a-service-robot-to-do-my-chores-with-behavior-trees-cbbc7d7ff928?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcbbc7d7ff928&operation=register&redirect=https%3A%2F%2Fsoulhackerslabs.com%2Fprogramming-a-service-robot-to-do-my-chores-with-behavior-trees-cbbc7d7ff928&source=-----8005b8c88cde----0-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

[![Image 18: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Stackademic](https://blog.stackademic.com/?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[5.1K 23](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----8005b8c88cde----1-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

[![Image 22](https://miro.medium.com/v2/resize:fill:48:48/1*zPtGTCNOwu1p3kzn_sZFVQ.png) ![Image 23](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*kQIvhDkl0ixPpv4z) ![Image 24](https://miro.medium.com/v2/resize:fill:48:48/1*ERYx0IB1pN-5ZX98cKAoUw.png) General Coding Knowledge ------------------------ 20 stories·1719 saves](https://eddiebarth.medium.com/list/general-coding-knowledge-f2d429d4f0cd?source=read_next_recirc-----8005b8c88cde--------------------------------)

[![Image 25](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*gzCeWxDtGmD23QR5) ![Image 26](https://miro.medium.com/v2/resize:fill:48:48/1*di4WDrnS1F6_p9GWnxvPmg.png) ![Image 27](https://miro.medium.com/v2/resize:fill:48:48/1*PzJLbFrFtNkqPsxielO8zA.jpeg) Coding & Development -------------------- 11 stories·895 saves](https://medium.com/@jscribes/list/coding-development-e360d380bb82?source=read_next_recirc-----8005b8c88cde--------------------------------)

![Image 31: 3 Probability Questions I was asked in Walmart Data Scientist Interview](https://miro.medium.com/v2/resize:fit:679/1*5f1WO-mbx8fwBTQSs6F3zg.png)

[![Image 32: Lucas Samba](https://miro.medium.com/v2/resize:fill:20:20/1*R0PCZj_QUhumxixbZeUNAw.jpeg)](https://medium.com/@lucassamba?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Lucas Samba](https://medium.com/@lucassamba?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[3 Probability Questions I was asked in Walmart Data Scientist Interview ----------------------------------------------------------------------- ### Recently I got an opportunity to interview at Walmart for Data Scientist — 3 position. All thanks to a referral by my friend working at…](https://medium.com/@lucassamba/3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

Aug 23

[621 16](https://medium.com/@lucassamba/3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3cddba746d1&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40lucassamba%2F3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1&source=-----8005b8c88cde----0-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

![Image 33: Building Knowledge Graphs with LLM Graph Transformer](https://miro.medium.com/v2/resize:fit:679/0*KHns0-DJoCjfzxyr)

[![Image 34: Tomaz Bratanic](https://miro.medium.com/v2/resize:fill:20:20/1*SnWQP0l4Vg9577WAErbjfw.jpeg)](https://bratanic-tomaz.medium.com/?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Towards Data Science](https://towardsdatascience.com/?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Building Knowledge Graphs with LLM Graph Transformer ---------------------------------------------------- ### A deep dive into LangChain’s implementation of graph construction with LLMs](https://medium.com/building-knowledge-graphs-with-llm-graph-transformer-a91045c49b59?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

Nov 5

[685 6](https://medium.com/building-knowledge-graphs-with-llm-graph-transformer-a91045c49b59?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa91045c49b59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-knowledge-graphs-with-llm-graph-transformer-a91045c49b59&source=-----8005b8c88cde----1-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

![Image 35: 10 Must-Know Machine Learning Algorithms for Data Scientists](https://miro.medium.com/v2/resize:fit:679/1*eOeHQTszOo9ixjrHCDjuBg.png)

[![Image 36: John Vastola](https://miro.medium.com/v2/resize:fill:20:20/1*-Rwj8kAMmd3fmOh_-WOeBw.png)](https://johnvastola.medium.com/?source=read_next_recirc-----8005b8c88cde----2---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[John Vastola](https://johnvastola.medium.com/?source=read_next_recirc-----8005b8c88cde----2---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[10 Must-Know Machine Learning Algorithms for Data Scientists ------------------------------------------------------------ ### Machine learning is the science of getting computers to act without being explicitly programmed.” — Andrew Ng](https://johnvastola.medium.com/10-must-know-machine-learning-algorithms-for-data-scientists-adbf3272398a?source=read_next_recirc-----8005b8c88cde----2---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

Dec 6, 2022

[893 9](https://johnvastola.medium.com/10-must-know-machine-learning-algorithms-for-data-scientists-adbf3272398a?source=read_next_recirc-----8005b8c88cde----2---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fadbf3272398a&operation=register&redirect=https%3A%2F%2Fjohnvastola.medium.com%2F10-must-know-machine-learning-algorithms-for-data-scientists-adbf3272398a&source=-----8005b8c88cde----2-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

![Image 37: Learning To Rank: RankNet Simplified](https://miro.medium.com/v2/resize:fit:679/1*7oZU7qLtUtBNZIt-RwoU-A.png)

[![Image 38: Mandeep Singh](https://miro.medium.com/v2/resize:fill:20:20/1*u-Xx_oQhQ-6174ataDYd6w@2x.jpeg)](https://medium.com/@mandeep0405?source=read_next_recirc-----8005b8c88cde----3---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Mandeep Singh](https://medium.com/@mandeep0405?source=read_next_recirc-----8005b8c88cde----3---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Learning To Rank: RankNet Simplified ------------------------------------ ### Motivation](https://medium.com/@mandeep0405/learning-to-rank-ranknet-simplified-5d7f7334133d?source=read_next_recirc-----8005b8c88cde----3---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

Jul 7

[12](https://medium.com/@mandeep0405/learning-to-rank-ranknet-simplified-5d7f7334133d?source=read_next_recirc-----8005b8c88cde----3---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d7f7334133d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40mandeep0405%2Flearning-to-rank-ranknet-simplified-5d7f7334133d&source=-----8005b8c88cde----3-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

## Visual Content Analysis

### Image Analysis
Title: Machine Learning in Fraud Detection: A Primer - Towards Data Science

URL Source: https://medium.com/towards-data-science/machine-learning-in-fraud-detection-a-primer-8005b8c88cde

Published Time: 2024-11-12T01:11:59.924Z

Markdown Content:
Machine Learning in Fraud Detection: A Primer | by Samuel Flender | Nov, 2024 | Towards Data Science
===============
 

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

Machine Learning in Fraud Detection: A Primer
=============================================

Balancing automation, accuracy, and customer experience in an ever-evolving adversarial landscape
-------------------------------------------------------------------------------------------------

[![Image 2: Samuel Flender](https://miro.medium.com/v2/resize:fill:88:88/1*IHdofFy_lqh1Dpw4uhZkcw.jpeg)](https://medium.com/@samuel.flender?source=post_page---byline--8005b8c88cde--------------------------------)

[Samuel Flender](https://medium.com/@samuel.flender?source=post_page---byline--8005b8c88cde--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce56d9dcd568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=post_page-ce56d9dcd568--byline--8005b8c88cde---------------------post_header-----------)

[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8005b8c88cde--------------------------------)

23 hours ago

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=---header_actions--8005b8c88cde---------------------clap_footer-----------)

99

2

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=---header_actions--8005b8c88cde---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=---header_actions--8005b8c88cde---------------------post_audio_button-----------)

![Image 4: a bunch of credit cards flying in the air](https://miro.medium.com/v2/resize:fit:700/1*HEiY7mmh8adk3ZIObebB6g.png)

Fraud detection is a cornerstone of modern e-commerce, yet it is also one of the least publicized domains in Machine Learning. That’s for a good reason: it’s an adversarial domain, where fraudsters constantly invent new ways to bypass existing models, and model developers constantly invent new ways to catch them.

The goal of fraud detection systems is to block fraudulent transactions, such as those placed by fake accounts using stolen credit cards, while at the same time preventing any friction to the shopping experience of genuine customers. False negatives (fraud transactions that mistakenly went through the system) result in monetary loss also known as ‘bad debt’ due to chargebacks initiated by the actual credit card owners, while false positives (genuine transactions that were blocked) result in poor customer experience and churn.

Consider that a modern e-commerce provider may process somewhere in the order of tens of Millions of orders per day, and that fraud rates are at the sub-percent level, and you’re starting to see why this is a challenging domain. It’s the ultimate needle-in-a-haystack problem, where the haystacks are overwhelmingly large and…

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde%3Fsource%3D-----8005b8c88cde---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----8005b8c88cde---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde%3Fsource%3D-----8005b8c88cde---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----8005b8c88cde---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde%3Fsource%3D-----8005b8c88cde---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----8005b8c88cde---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=-----8005b8c88cde---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=---footer_actions--8005b8c88cde---------------------clap_footer-----------)

99

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=---footer_actions--8005b8c88cde---------------------clap_footer-----------)

99

2

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8005b8c88cde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&source=---footer_actions--8005b8c88cde---------------------bookmark_footer-----------)

[![Image 5: Samuel Flender](https://miro.medium.com/v2/resize:fill:144:144/1*IHdofFy_lqh1Dpw4uhZkcw.jpeg)](https://medium.com/@samuel.flender?source=post_page---post_author_info--8005b8c88cde--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce56d9dcd568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=post_page-ce56d9dcd568--post_author_info--8005b8c88cde---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F89b071bfd3ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&newsletterV3=ce56d9dcd568&newsletterV3Id=89b071bfd3ab&user=Samuel+Flender&userId=ce56d9dcd568&source=---post_author_info--8005b8c88cde---------------------subscribe_user-----------)

[Written by Samuel Flender -------------------------](https://medium.com/@samuel.flender?source=post_page---post_author_info--8005b8c88cde--------------------------------)

[3.8K Followers](https://medium.com/@samuel.flender/followers?source=post_page---post_author_info--8005b8c88cde--------------------------------)

[Towards Data Science](https://towardsdatascience.com/?source=post_page---post_author_info--8005b8c88cde--------------------------------)

Cutting-edge ML research, simplified. For the latest, subscribe to my Newsletter: [mlfrontiers.substack.com](http://mlfrontiers.substack.com/)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce56d9dcd568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&user=Samuel+Flender&userId=ce56d9dcd568&source=post_page-ce56d9dcd568--post_author_info--8005b8c88cde---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F89b071bfd3ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-fraud-detection-a-primer-8005b8c88cde&newsletterV3=ce56d9dcd568&newsletterV3Id=89b071bfd3ab&user=Samuel+Flender&userId=ce56d9dcd568&source=---post_author_info--8005b8c88cde---------------------subscribe_user-----------)

More from Samuel Flender and Towards Data Science
-------------------------------------------------

![Image 7: How I Cracked the Meta Machine Learning Engineering Interview](https://miro.medium.com/v2/resize:fit:679/0*uP6vp3RUAMz5DSkR)

[![Image 8: Samuel Flender](https://miro.medium.com/v2/resize:fill:20:20/1*IHdofFy_lqh1Dpw4uhZkcw.jpeg)](https://medium.com/@samuel.flender?source=author_recirc-----8005b8c88cde----0---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Samuel Flender](https://medium.com/@samuel.flender?source=author_recirc-----8005b8c88cde----0---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----8005b8c88cde----0---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[How I Cracked the Meta Machine Learning Engineering Interview ------------------------------------------------------------- ### Practical tips for the coding, design, and behavior rounds](https://medium.com/how-i-cracked-the-meta-machine-learning-engineering-interview-aa32f64b8e4b?source=author_recirc-----8005b8c88cde----0---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

Oct 25, 2022

[1.99K 11](https://medium.com/how-i-cracked-the-meta-machine-learning-engineering-interview-aa32f64b8e4b?source=author_recirc-----8005b8c88cde----0---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faa32f64b8e4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-cracked-the-meta-machine-learning-engineering-interview-aa32f64b8e4b&source=-----8005b8c88cde----0-----------------bookmark_preview----b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

![Image 9: Advanced Time Series Forecasting With sktime](https://miro.medium.com/v2/resize:fit:679/0*IRO3Gw2zZu4Yk3ne)

[![Image 10: Dr. Robert Kübler](https://miro.medium.com/v2/resize:fill:20:20/2*kfj1GnUxOj_3CjyaJK1dYQ.jpeg)](https://dr-robert-kuebler.medium.com/?source=author_recirc-----8005b8c88cde----1---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Dr. Robert Kübler](https://dr-robert-kuebler.medium.com/?source=author_recirc-----8005b8c88cde----1---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----8005b8c88cde----1---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Advanced Time Series Forecasting With sktime -------------------------------------------- ### Learn how to optimize model hyperparameters and even the architecture in a few lines of code](https://medium.com/advanced-time-series-forecasting-with-sktime-af8eabc76173?source=author_recirc-----8005b8c88cde----1---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[104 1](https://medium.com/advanced-time-series-forecasting-with-sktime-af8eabc76173?source=author_recirc-----8005b8c88cde----1---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf8eabc76173&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-time-series-forecasting-with-sktime-af8eabc76173&source=-----8005b8c88cde----1-----------------bookmark_preview----b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

![Image 11: The Statistical Significance Scam](https://miro.medium.com/v2/resize:fit:679/1*fUigVfmuyNJLUFY6m-lZUw.jpeg)

[![Image 12: Cai Parry-Jones](https://miro.medium.com/v2/resize:fill:20:20/0*GWV4mbIw3Ex5l9PC)](https://medium.com/@caiparryjones96?source=author_recirc-----8005b8c88cde----2---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Cai Parry-Jones](https://medium.com/@caiparryjones96?source=author_recirc-----8005b8c88cde----2---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----8005b8c88cde----2---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[The Statistical Significance Scam --------------------------------- ### A detailed look into the flaws of science’s favorite tool](https://medium.com/the-statistical-significance-scam-db904be36714?source=author_recirc-----8005b8c88cde----2---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[581 4](https://medium.com/the-statistical-significance-scam-db904be36714?source=author_recirc-----8005b8c88cde----2---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdb904be36714&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-statistical-significance-scam-db904be36714&source=-----8005b8c88cde----2-----------------bookmark_preview----b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

![Image 13: Class Imbalance in Machine Learning Problems: A Practical Guide](https://miro.medium.com/v2/resize:fit:679/0*_Dt8SwZ4oNdovZsA)

[![Image 14: Samuel Flender](https://miro.medium.com/v2/resize:fill:20:20/1*IHdofFy_lqh1Dpw4uhZkcw.jpeg)](https://medium.com/@samuel.flender?source=author_recirc-----8005b8c88cde----3---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Samuel Flender](https://medium.com/@samuel.flender?source=author_recirc-----8005b8c88cde----3---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----8005b8c88cde----3---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[Class Imbalance in Machine Learning Problems: A Practical Guide --------------------------------------------------------------- ### Five lessons from the trenches of applied data science](https://medium.com/class-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041?source=author_recirc-----8005b8c88cde----3---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

Oct 3, 2022

[521 3](https://medium.com/class-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041?source=author_recirc-----8005b8c88cde----3---------------------b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4fb81eee0041&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041&source=-----8005b8c88cde----3-----------------bookmark_preview----b26fae2b_cfc1_45ce_a9d9_9fe76ea34bec-------)

[See all from Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----8005b8c88cde--------------------------------)

[See all from Towards Data Science](https://towardsdatascience.com/?source=post_page-----8005b8c88cde--------------------------------)

![Image 15: Programming a Service Robot to Do My Chores With Behavior Trees](https://miro.medium.com/v2/resize:fit:679/1*O990kX0_AsScV4P3LHZgDg.png)

[![Image 16: Carlos Argueta](https://miro.medium.com/v2/resize:fill:20:20/1*SEVvEjjsV6WB6SpBz5lubw.jpeg)](https://soulhackerslabs.com/?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Carlos Argueta](https://soulhackerslabs.com/?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Programming a Service Robot to Do My Chores With Behavior Trees --------------------------------------------------------------- ### Learn how Behavior Trees enable complex, flexible robot behaviors for autonomous tasks in robotics. Ideal for AI and ML applications.](https://soulhackerslabs.com/programming-a-service-robot-to-do-my-chores-with-behavior-trees-cbbc7d7ff928?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[272 7](https://soulhackerslabs.com/programming-a-service-robot-to-do-my-chores-with-behavior-trees-cbbc7d7ff928?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcbbc7d7ff928&operation=register&redirect=https%3A%2F%2Fsoulhackerslabs.com%2Fprogramming-a-service-robot-to-do-my-chores-with-behavior-trees-cbbc7d7ff928&source=-----8005b8c88cde----0-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

[![Image 18: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Stackademic](https://blog.stackademic.com/?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[5.1K 23](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----8005b8c88cde----1-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

[![Image 22](https://miro.medium.com/v2/resize:fill:48:48/1*zPtGTCNOwu1p3kzn_sZFVQ.png) ![Image 23](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*kQIvhDkl0ixPpv4z) ![Image 24](https://miro.medium.com/v2/resize:fill:48:48/1*ERYx0IB1pN-5ZX98cKAoUw.png) General Coding Knowledge ------------------------ 20 stories·1719 saves](https://eddiebarth.medium.com/list/general-coding-knowledge-f2d429d4f0cd?source=read_next_recirc-----8005b8c88cde--------------------------------)

[![Image 25](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*gzCeWxDtGmD23QR5) ![Image 26](https://miro.medium.com/v2/resize:fill:48:48/1*di4WDrnS1F6_p9GWnxvPmg.png) ![Image 27](https://miro.medium.com/v2/resize:fill:48:48/1*PzJLbFrFtNkqPsxielO8zA.jpeg) Coding & Development -------------------- 11 stories·895 saves](https://medium.com/@jscribes/list/coding-development-e360d380bb82?source=read_next_recirc-----8005b8c88cde--------------------------------)

![Image 31: 3 Probability Questions I was asked in Walmart Data Scientist Interview](https://miro.medium.com/v2/resize:fit:679/1*5f1WO-mbx8fwBTQSs6F3zg.png)

[![Image 32: Lucas Samba](https://miro.medium.com/v2/resize:fill:20:20/1*R0PCZj_QUhumxixbZeUNAw.jpeg)](https://medium.com/@lucassamba?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Lucas Samba](https://medium.com/@lucassamba?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[3 Probability Questions I was asked in Walmart Data Scientist Interview ----------------------------------------------------------------------- ### Recently I got an opportunity to interview at Walmart for Data Scientist — 3 position. All thanks to a referral by my friend working at…](https://medium.com/@lucassamba/3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

Aug 23

[621 16](https://medium.com/@lucassamba/3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1?source=read_next_recirc-----8005b8c88cde----0---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3cddba746d1&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40lucassamba%2F3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1&source=-----8005b8c88cde----0-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

![Image 33: Building Knowledge Graphs with LLM Graph Transformer](https://miro.medium.com/v2/resize:fit:679/0*KHns0-DJoCjfzxyr)

[![Image 34: Tomaz Bratanic](https://miro.medium.com/v2/resize:fill:20:20/1*SnWQP0l4Vg9577WAErbjfw.jpeg)](https://bratanic-tomaz.medium.com/?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Towards Data Science](https://towardsdatascience.com/?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Building Knowledge Graphs with LLM Graph Transformer ---------------------------------------------------- ### A deep dive into LangChain’s implementation of graph construction with LLMs](https://medium.com/building-knowledge-graphs-with-llm-graph-transformer-a91045c49b59?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

Nov 5

[685 6](https://medium.com/building-knowledge-graphs-with-llm-graph-transformer-a91045c49b59?source=read_next_recirc-----8005b8c88cde----1---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa91045c49b59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-knowledge-graphs-with-llm-graph-transformer-a91045c49b59&source=-----8005b8c88cde----1-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

![Image 35: 10 Must-Know Machine Learning Algorithms for Data Scientists](https://miro.medium.com/v2/resize:fit:679/1*eOeHQTszOo9ixjrHCDjuBg.png)

[![Image 36: John Vastola](https://miro.medium.com/v2/resize:fill:20:20/1*-Rwj8kAMmd3fmOh_-WOeBw.png)](https://johnvastola.medium.com/?source=read_next_recirc-----8005b8c88cde----2---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[John Vastola](https://johnvastola.medium.com/?source=read_next_recirc-----8005b8c88cde----2---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[10 Must-Know Machine Learning Algorithms for Data Scientists ------------------------------------------------------------ ### Machine learning is the science of getting computers to act without being explicitly programmed.” — Andrew Ng](https://johnvastola.medium.com/10-must-know-machine-learning-algorithms-for-data-scientists-adbf3272398a?source=read_next_recirc-----8005b8c88cde----2---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

Dec 6, 2022

[893 9](https://johnvastola.medium.com/10-must-know-machine-learning-algorithms-for-data-scientists-adbf3272398a?source=read_next_recirc-----8005b8c88cde----2---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fadbf3272398a&operation=register&redirect=https%3A%2F%2Fjohnvastola.medium.com%2F10-must-know-machine-learning-algorithms-for-data-scientists-adbf3272398a&source=-----8005b8c88cde----2-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)

![Image 37: Learning To Rank: RankNet Simplified](https://miro.medium.com/v2/resize:fit:679/1*7oZU7qLtUtBNZIt-RwoU-A.png)

[![Image 38: Mandeep Singh](https://miro.medium.com/v2/resize:fill:20:20/1*u-Xx_oQhQ-6174ataDYd6w@2x.jpeg)](https://medium.com/@mandeep0405?source=read_next_recirc-----8005b8c88cde----3---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Mandeep Singh](https://medium.com/@mandeep0405?source=read_next_recirc-----8005b8c88cde----3---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[Learning To Rank: RankNet Simplified ------------------------------------ ### Motivation](https://medium.com/@mandeep0405/learning-to-rank-ranknet-simplified-5d7f7334133d?source=read_next_recirc-----8005b8c88cde----3---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

Jul 7

[12](https://medium.com/@mandeep0405/learning-to-rank-ranknet-simplified-5d7f7334133d?source=read_next_recirc-----8005b8c88cde----3---------------------727953d5_33ce_4f48_8367_5da84e781fc7-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d7f7334133d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40mandeep0405%2Flearning-to-rank-ranknet-simplified-5d7f7334133d&source=-----8005b8c88cde----3-----------------bookmark_preview----727953d5_33ce_4f48_8367_5da84e781fc7-------)


---

## https://medium.com/towards-data-science/normalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75

Title: Normalized Discounted Cumulative Gain (NDCG) — The Ultimate Ranking Metric

URL Source: https://medium.com/towards-data-science/normalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75

Published Time: 2024-10-15T20:44:51.473Z

Markdown Content:
Normalized Discounted Cumulative Gain (NDCG) — The Ultimate Ranking Metric | by Saankhya Mondal | Oct, 2024 | Towards Data Science
===============
 

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

Normalized Discounted Cumulative Gain (NDCG) — The Ultimate Ranking Metric
==========================================================================

NDCG — the rank-aware metric for evaluating recommendation systems
------------------------------------------------------------------

[![Image 2: Saankhya Mondal](https://miro.medium.com/v2/resize:fill:88:88/1*TADxXNj_Fq5BqXipXvp1QQ.jpeg)](https://saankhya.medium.com/?source=post_page---byline--437b03529f75--------------------------------)

[Saankhya Mondal](https://saankhya.medium.com/?source=post_page---byline--437b03529f75--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59f51d8e0df4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=post_page-59f51d8e0df4--byline--437b03529f75---------------------post_header-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=---header_actions--437b03529f75---------------------clap_footer-----------)

328

7

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=---header_actions--437b03529f75---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=---header_actions--437b03529f75---------------------post_audio_button-----------)

Recommendation systems are everywhere. Since you’re reading this article, there’s a good chance Medium recommended it on your feed. This article will explore NDCG — Normalized Discounted Cumulative Gain, the rank-aware metric for evaluating any recommendation system model.

![Image 4: social media marketing concept with social icons and icons](https://miro.medium.com/v2/resize:fit:700/0*U7MA1X95LAKAdchq)

Image AI-Generated using Gemini

What are Recommendation Systems?
================================

Recommendation systems help users discover relevant items like products, profiles, posts, videos, ads, or information based on their preferences or behavior. These platforms handle millions of items, and displaying the most relevant ones is key to boosting user engagement and business metrics. Companies such as Amazon, LinkedIn, Twitter, Instagram, Reddit, Spotify, YouTube, Netflix, Medium, and Quora use recommendation systems in their apps.

These systems are typically two-stage systems consisting of a retrieval model followed by a ranking model. The retrieval model funnels down the most relevant items from millions of items based on a similarity metric and passes them to the ranking model. The ranking model ranks the items on a more granular level.

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75%3Fsource%3D-----437b03529f75---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----437b03529f75---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75%3Fsource%3D-----437b03529f75---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----437b03529f75---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75%3Fsource%3D-----437b03529f75---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----437b03529f75---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=-----437b03529f75---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=---footer_actions--437b03529f75---------------------clap_footer-----------)

328

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=---footer_actions--437b03529f75---------------------clap_footer-----------)

328

7

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=---footer_actions--437b03529f75---------------------bookmark_footer-----------)

[![Image 5: Saankhya Mondal](https://miro.medium.com/v2/resize:fill:144:144/1*TADxXNj_Fq5BqXipXvp1QQ.jpeg)](https://saankhya.medium.com/?source=post_page---post_author_info--437b03529f75--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59f51d8e0df4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=post_page-59f51d8e0df4--post_author_info--437b03529f75---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2189c683abab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&newsletterV3=59f51d8e0df4&newsletterV3Id=2189c683abab&user=Saankhya+Mondal&userId=59f51d8e0df4&source=---post_author_info--437b03529f75---------------------subscribe_user-----------)

Data Scientist @ Meesho, M. Tech in AI, IISc, Bengaluru.

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59f51d8e0df4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=post_page-59f51d8e0df4--post_author_info--437b03529f75---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2189c683abab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&newsletterV3=59f51d8e0df4&newsletterV3Id=2189c683abab&user=Saankhya+Mondal&userId=59f51d8e0df4&source=---post_author_info--437b03529f75---------------------subscribe_user-----------)

![Image 7: Kickstart Your Data Science Journey —  A  Guide for Aspiring Data Scientists](https://miro.medium.com/v2/resize:fit:679/1*o06jXpJ_dMBlIwnR1P7XwQ.png)

[![Image 8: Saankhya Mondal](https://miro.medium.com/v2/resize:fill:20:20/1*TADxXNj_Fq5BqXipXvp1QQ.jpeg)](https://saankhya.medium.com/?source=author_recirc-----437b03529f75----0---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Saankhya Mondal](https://saankhya.medium.com/?source=author_recirc-----437b03529f75----0---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----437b03529f75----0---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Kickstart Your Data Science Journey — A Guide for Aspiring Data Scientists --------------------------------------------------------------------------- ### Key Technical Skills You Need to Kick-start Your Career in Data Science](https://medium.com/kickstart-your-data-science-journey-a-guide-for-aspiring-data-scientists-96e5072bd19a?source=author_recirc-----437b03529f75----0---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[418 11](https://medium.com/kickstart-your-data-science-journey-a-guide-for-aspiring-data-scientists-96e5072bd19a?source=author_recirc-----437b03529f75----0---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96e5072bd19a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkickstart-your-data-science-journey-a-guide-for-aspiring-data-scientists-96e5072bd19a&source=-----437b03529f75----0-----------------bookmark_preview----43bf5719_f386_485f_880d_dd41b5e3853f-------)

[![Image 10: Dr. Robert Kübler](https://miro.medium.com/v2/resize:fill:20:20/2*kfj1GnUxOj_3CjyaJK1dYQ.jpeg)](https://dr-robert-kuebler.medium.com/?source=author_recirc-----437b03529f75----1---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Dr. Robert Kübler](https://dr-robert-kuebler.medium.com/?source=author_recirc-----437b03529f75----1---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----437b03529f75----1---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[104 1](https://medium.com/advanced-time-series-forecasting-with-sktime-af8eabc76173?source=author_recirc-----437b03529f75----1---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf8eabc76173&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-time-series-forecasting-with-sktime-af8eabc76173&source=-----437b03529f75----1-----------------bookmark_preview----43bf5719_f386_485f_880d_dd41b5e3853f-------)

[![Image 12: Cai Parry-Jones](https://miro.medium.com/v2/resize:fill:20:20/0*GWV4mbIw3Ex5l9PC)](https://medium.com/@caiparryjones96?source=author_recirc-----437b03529f75----2---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Cai Parry-Jones](https://medium.com/@caiparryjones96?source=author_recirc-----437b03529f75----2---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----437b03529f75----2---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[The Statistical Significance Scam --------------------------------- ### A detailed look into the flaws of science’s favorite tool](https://medium.com/the-statistical-significance-scam-db904be36714?source=author_recirc-----437b03529f75----2---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[581 4](https://medium.com/the-statistical-significance-scam-db904be36714?source=author_recirc-----437b03529f75----2---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdb904be36714&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-statistical-significance-scam-db904be36714&source=-----437b03529f75----2-----------------bookmark_preview----43bf5719_f386_485f_880d_dd41b5e3853f-------)

![Image 13: Game Theory, Part 1 — The Prisoner’s Dilemma Problem](https://miro.medium.com/v2/resize:fit:679/0*mWNHxZMOZ8NhYPnt)

[![Image 14: Saankhya Mondal](https://miro.medium.com/v2/resize:fill:20:20/1*TADxXNj_Fq5BqXipXvp1QQ.jpeg)](https://saankhya.medium.com/?source=author_recirc-----437b03529f75----3---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Saankhya Mondal](https://saankhya.medium.com/?source=author_recirc-----437b03529f75----3---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----437b03529f75----3---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Game Theory, Part 1 — The Prisoner’s Dilemma Problem ---------------------------------------------------- ### Game theory is prevalent in real-life scenarios and decision-making](https://medium.com/game-theory-part-1-the-prisoners-dilemma-problem-18b216d3b523?source=author_recirc-----437b03529f75----3---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[113 2](https://medium.com/game-theory-part-1-the-prisoners-dilemma-problem-18b216d3b523?source=author_recirc-----437b03529f75----3---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18b216d3b523&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgame-theory-part-1-the-prisoners-dilemma-problem-18b216d3b523&source=-----437b03529f75----3-----------------bookmark_preview----43bf5719_f386_485f_880d_dd41b5e3853f-------)

[See all from Saankhya Mondal](https://saankhya.medium.com/?source=post_page-----437b03529f75--------------------------------)

[![Image 16: AI Rabbit](https://miro.medium.com/v2/resize:fill:20:20/1*1cIrPiG5AyUHt-rt6gh_Vw.jpeg)](https://medium.com/@airabbitX?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[AI Rabbit](https://medium.com/@airabbitX?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[CodeX](https://medium.com/codex?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[1.4K 22](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc1ada7a8d91&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fhas-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91&source=-----437b03529f75----0-----------------bookmark_preview----41067589_42e0_4ec7_b000_73dec5382500-------)

[![Image 18: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Stackademic](https://blog.stackademic.com/?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[5.1K 23](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----437b03529f75----1-----------------bookmark_preview----41067589_42e0_4ec7_b000_73dec5382500-------)

[![Image 32: Don Lim](https://miro.medium.com/v2/resize:fill:20:20/1*SkAt7uMC11I7WgRXlBMiPA.jpeg)](https://medium.com/@don-lim?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Don Lim](https://medium.com/@don-lim?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[705 13](https://medium.com/@don-lim/gpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f90e5362408&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40don-lim%2Fgpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408&source=-----437b03529f75----0-----------------bookmark_preview----41067589_42e0_4ec7_b000_73dec5382500-------)

[![Image 34: Isaac Saul](https://miro.medium.com/v2/resize:fill:20:20/1*5bMy4uvQlQxjhi_xhBlJJQ.jpeg)](https://medium.com/@isaac_1884?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Isaac Saul](https://medium.com/@isaac_1884?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[The Political Prism](https://medium.com/the-political-prism?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[22 Thoughts about Trump’s Win ----------------------------- ### Reflecting on the election and looking forward to what may come](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[7.8K 263](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F610bbb304850&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fthe-political-prism%2F22-thoughts-about-trumps-win-610bbb304850&source=-----437b03529f75----1-----------------bookmark_preview----41067589_42e0_4ec7_b000_73dec5382500-------)

[![Image 36: Lucas Samba](https://miro.medium.com/v2/resize:fill:20:20/1*R0PCZj_QUhumxixbZeUNAw.jpeg)](https://medium.com/@lucassamba?source=read_next_recirc-----437b03529f75----2---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Lucas Samba](https://medium.com/@lucassamba?source=read_next_recirc-----437b03529f75----2---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[621 16](https://medium.com/@lucassamba/3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1?source=read_next_recirc-----437b03529f75----2---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3cddba746d1&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40lucassamba%2F3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1&source=-----437b03529f75----2-----------------bookmark_preview----41067589_42e0_4ec7_b000_73dec5382500-------)

[![Image 38: Richardson Gunde](https://miro.medium.com/v2/resize:fill:20:20/1*tp2uj3tur89cbR2GW0SrDQ.png)](https://medium.com/@honeyricky1m3?source=read_next_recirc-----437b03529f75----3---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Richardson Gunde](https://medium.com/@honeyricky1m3?source=read_next_recirc-----437b03529f75----3---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[AI Advances](https://ai.gopubby.com/?source=read_next_recirc-----437b03529f75----3---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[1K 13](https://ai.gopubby.com/the-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8?source=read_next_recirc-----437b03529f75----3---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

## Visual Content Analysis

### Image Analysis
Title: Normalized Discounted Cumulative Gain (NDCG) — The Ultimate Ranking Metric

URL Source: https://medium.com/towards-data-science/normalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75

Published Time: 2024-10-15T20:44:51.473Z

Markdown Content:
Normalized Discounted Cumulative Gain (NDCG) — The Ultimate Ranking Metric | by Saankhya Mondal | Oct, 2024 | Towards Data Science
===============
 

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

Normalized Discounted Cumulative Gain (NDCG) — The Ultimate Ranking Metric
==========================================================================

NDCG — the rank-aware metric for evaluating recommendation systems
------------------------------------------------------------------

[![Image 2: Saankhya Mondal](https://miro.medium.com/v2/resize:fill:88:88/1*TADxXNj_Fq5BqXipXvp1QQ.jpeg)](https://saankhya.medium.com/?source=post_page---byline--437b03529f75--------------------------------)

[Saankhya Mondal](https://saankhya.medium.com/?source=post_page---byline--437b03529f75--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59f51d8e0df4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=post_page-59f51d8e0df4--byline--437b03529f75---------------------post_header-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=---header_actions--437b03529f75---------------------clap_footer-----------)

328

7

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=---header_actions--437b03529f75---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=---header_actions--437b03529f75---------------------post_audio_button-----------)

Recommendation systems are everywhere. Since you’re reading this article, there’s a good chance Medium recommended it on your feed. This article will explore NDCG — Normalized Discounted Cumulative Gain, the rank-aware metric for evaluating any recommendation system model.

![Image 4: social media marketing concept with social icons and icons](https://miro.medium.com/v2/resize:fit:700/0*U7MA1X95LAKAdchq)

Image AI-Generated using Gemini

What are Recommendation Systems?
================================

Recommendation systems help users discover relevant items like products, profiles, posts, videos, ads, or information based on their preferences or behavior. These platforms handle millions of items, and displaying the most relevant ones is key to boosting user engagement and business metrics. Companies such as Amazon, LinkedIn, Twitter, Instagram, Reddit, Spotify, YouTube, Netflix, Medium, and Quora use recommendation systems in their apps.

These systems are typically two-stage systems consisting of a retrieval model followed by a ranking model. The retrieval model funnels down the most relevant items from millions of items based on a similarity metric and passes them to the ranking model. The ranking model ranks the items on a more granular level.

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75%3Fsource%3D-----437b03529f75---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----437b03529f75---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75%3Fsource%3D-----437b03529f75---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----437b03529f75---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75%3Fsource%3D-----437b03529f75---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----437b03529f75---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=-----437b03529f75---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=---footer_actions--437b03529f75---------------------clap_footer-----------)

328

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=---footer_actions--437b03529f75---------------------clap_footer-----------)

328

7

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F437b03529f75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&source=---footer_actions--437b03529f75---------------------bookmark_footer-----------)

[![Image 5: Saankhya Mondal](https://miro.medium.com/v2/resize:fill:144:144/1*TADxXNj_Fq5BqXipXvp1QQ.jpeg)](https://saankhya.medium.com/?source=post_page---post_author_info--437b03529f75--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59f51d8e0df4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=post_page-59f51d8e0df4--post_author_info--437b03529f75---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2189c683abab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&newsletterV3=59f51d8e0df4&newsletterV3Id=2189c683abab&user=Saankhya+Mondal&userId=59f51d8e0df4&source=---post_author_info--437b03529f75---------------------subscribe_user-----------)

Data Scientist @ Meesho, M. Tech in AI, IISc, Bengaluru.

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59f51d8e0df4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&user=Saankhya+Mondal&userId=59f51d8e0df4&source=post_page-59f51d8e0df4--post_author_info--437b03529f75---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2189c683abab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnormalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75&newsletterV3=59f51d8e0df4&newsletterV3Id=2189c683abab&user=Saankhya+Mondal&userId=59f51d8e0df4&source=---post_author_info--437b03529f75---------------------subscribe_user-----------)

![Image 7: Kickstart Your Data Science Journey —  A  Guide for Aspiring Data Scientists](https://miro.medium.com/v2/resize:fit:679/1*o06jXpJ_dMBlIwnR1P7XwQ.png)

[![Image 8: Saankhya Mondal](https://miro.medium.com/v2/resize:fill:20:20/1*TADxXNj_Fq5BqXipXvp1QQ.jpeg)](https://saankhya.medium.com/?source=author_recirc-----437b03529f75----0---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Saankhya Mondal](https://saankhya.medium.com/?source=author_recirc-----437b03529f75----0---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----437b03529f75----0---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Kickstart Your Data Science Journey — A Guide for Aspiring Data Scientists --------------------------------------------------------------------------- ### Key Technical Skills You Need to Kick-start Your Career in Data Science](https://medium.com/kickstart-your-data-science-journey-a-guide-for-aspiring-data-scientists-96e5072bd19a?source=author_recirc-----437b03529f75----0---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[418 11](https://medium.com/kickstart-your-data-science-journey-a-guide-for-aspiring-data-scientists-96e5072bd19a?source=author_recirc-----437b03529f75----0---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96e5072bd19a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkickstart-your-data-science-journey-a-guide-for-aspiring-data-scientists-96e5072bd19a&source=-----437b03529f75----0-----------------bookmark_preview----43bf5719_f386_485f_880d_dd41b5e3853f-------)

[![Image 10: Dr. Robert Kübler](https://miro.medium.com/v2/resize:fill:20:20/2*kfj1GnUxOj_3CjyaJK1dYQ.jpeg)](https://dr-robert-kuebler.medium.com/?source=author_recirc-----437b03529f75----1---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Dr. Robert Kübler](https://dr-robert-kuebler.medium.com/?source=author_recirc-----437b03529f75----1---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----437b03529f75----1---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[104 1](https://medium.com/advanced-time-series-forecasting-with-sktime-af8eabc76173?source=author_recirc-----437b03529f75----1---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf8eabc76173&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-time-series-forecasting-with-sktime-af8eabc76173&source=-----437b03529f75----1-----------------bookmark_preview----43bf5719_f386_485f_880d_dd41b5e3853f-------)

[![Image 12: Cai Parry-Jones](https://miro.medium.com/v2/resize:fill:20:20/0*GWV4mbIw3Ex5l9PC)](https://medium.com/@caiparryjones96?source=author_recirc-----437b03529f75----2---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Cai Parry-Jones](https://medium.com/@caiparryjones96?source=author_recirc-----437b03529f75----2---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----437b03529f75----2---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[The Statistical Significance Scam --------------------------------- ### A detailed look into the flaws of science’s favorite tool](https://medium.com/the-statistical-significance-scam-db904be36714?source=author_recirc-----437b03529f75----2---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[581 4](https://medium.com/the-statistical-significance-scam-db904be36714?source=author_recirc-----437b03529f75----2---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdb904be36714&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-statistical-significance-scam-db904be36714&source=-----437b03529f75----2-----------------bookmark_preview----43bf5719_f386_485f_880d_dd41b5e3853f-------)

![Image 13: Game Theory, Part 1 — The Prisoner’s Dilemma Problem](https://miro.medium.com/v2/resize:fit:679/0*mWNHxZMOZ8NhYPnt)

[![Image 14: Saankhya Mondal](https://miro.medium.com/v2/resize:fill:20:20/1*TADxXNj_Fq5BqXipXvp1QQ.jpeg)](https://saankhya.medium.com/?source=author_recirc-----437b03529f75----3---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Saankhya Mondal](https://saankhya.medium.com/?source=author_recirc-----437b03529f75----3---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----437b03529f75----3---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[Game Theory, Part 1 — The Prisoner’s Dilemma Problem ---------------------------------------------------- ### Game theory is prevalent in real-life scenarios and decision-making](https://medium.com/game-theory-part-1-the-prisoners-dilemma-problem-18b216d3b523?source=author_recirc-----437b03529f75----3---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[113 2](https://medium.com/game-theory-part-1-the-prisoners-dilemma-problem-18b216d3b523?source=author_recirc-----437b03529f75----3---------------------43bf5719_f386_485f_880d_dd41b5e3853f-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18b216d3b523&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgame-theory-part-1-the-prisoners-dilemma-problem-18b216d3b523&source=-----437b03529f75----3-----------------bookmark_preview----43bf5719_f386_485f_880d_dd41b5e3853f-------)

[See all from Saankhya Mondal](https://saankhya.medium.com/?source=post_page-----437b03529f75--------------------------------)

[![Image 16: AI Rabbit](https://miro.medium.com/v2/resize:fill:20:20/1*1cIrPiG5AyUHt-rt6gh_Vw.jpeg)](https://medium.com/@airabbitX?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[AI Rabbit](https://medium.com/@airabbitX?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[CodeX](https://medium.com/codex?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[1.4K 22](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc1ada7a8d91&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fhas-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91&source=-----437b03529f75----0-----------------bookmark_preview----41067589_42e0_4ec7_b000_73dec5382500-------)

[![Image 18: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Stackademic](https://blog.stackademic.com/?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[5.1K 23](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----437b03529f75----1-----------------bookmark_preview----41067589_42e0_4ec7_b000_73dec5382500-------)

[![Image 32: Don Lim](https://miro.medium.com/v2/resize:fill:20:20/1*SkAt7uMC11I7WgRXlBMiPA.jpeg)](https://medium.com/@don-lim?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Don Lim](https://medium.com/@don-lim?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[705 13](https://medium.com/@don-lim/gpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408?source=read_next_recirc-----437b03529f75----0---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f90e5362408&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40don-lim%2Fgpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408&source=-----437b03529f75----0-----------------bookmark_preview----41067589_42e0_4ec7_b000_73dec5382500-------)

[![Image 34: Isaac Saul](https://miro.medium.com/v2/resize:fill:20:20/1*5bMy4uvQlQxjhi_xhBlJJQ.jpeg)](https://medium.com/@isaac_1884?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Isaac Saul](https://medium.com/@isaac_1884?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[The Political Prism](https://medium.com/the-political-prism?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[22 Thoughts about Trump’s Win ----------------------------- ### Reflecting on the election and looking forward to what may come](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[7.8K 263](https://medium.com/the-political-prism/22-thoughts-about-trumps-win-610bbb304850?source=read_next_recirc-----437b03529f75----1---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F610bbb304850&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fthe-political-prism%2F22-thoughts-about-trumps-win-610bbb304850&source=-----437b03529f75----1-----------------bookmark_preview----41067589_42e0_4ec7_b000_73dec5382500-------)

[![Image 36: Lucas Samba](https://miro.medium.com/v2/resize:fill:20:20/1*R0PCZj_QUhumxixbZeUNAw.jpeg)](https://medium.com/@lucassamba?source=read_next_recirc-----437b03529f75----2---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Lucas Samba](https://medium.com/@lucassamba?source=read_next_recirc-----437b03529f75----2---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[621 16](https://medium.com/@lucassamba/3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1?source=read_next_recirc-----437b03529f75----2---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3cddba746d1&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40lucassamba%2F3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1&source=-----437b03529f75----2-----------------bookmark_preview----41067589_42e0_4ec7_b000_73dec5382500-------)

[![Image 38: Richardson Gunde](https://miro.medium.com/v2/resize:fill:20:20/1*tp2uj3tur89cbR2GW0SrDQ.png)](https://medium.com/@honeyricky1m3?source=read_next_recirc-----437b03529f75----3---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[Richardson Gunde](https://medium.com/@honeyricky1m3?source=read_next_recirc-----437b03529f75----3---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[AI Advances](https://ai.gopubby.com/?source=read_next_recirc-----437b03529f75----3---------------------41067589_42e0_4ec7_b000_73dec5382500-------)

[1K 13](https://ai.gopubby.com/the-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8?source=read_next_recirc-----437b03529f75----3---------------------41067589_42e0_4ec7_b000_73dec5382500-------)


---

## https://medium.com/stackademic/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63

Title: 20 Python Scripts To Automate Your Daily Tasks - Stackademic

URL Source: https://medium.com/stackademic/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63

Published Time: 2024-10-07T03:18:42.230Z

Markdown Content:
20 Python Scripts To Automate Your Daily Tasks | by Abdur Rahman | Oct, 2024 | Stackademic
===============
 

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

20 Python Scripts To Automate Your Daily Tasks
==============================================

A must-have collection for every developer
------------------------------------------

[![Image 2: Abdur Rahman](https://miro.medium.com/v2/resize:fill:88:88/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=post_page---byline--4c6f4b15fe63--------------------------------)

[![Image 3: Stackademic](https://miro.medium.com/v2/resize:fill:48:48/1*U-kjsW7IZUobnoy1gAp1UQ.png)](https://blog.stackademic.com/?source=post_page---byline--4c6f4b15fe63--------------------------------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=post_page---byline--4c6f4b15fe63--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--byline--4c6f4b15fe63---------------------post_header-----------)

[Stackademic](https://blog.stackademic.com/?source=post_page---byline--4c6f4b15fe63--------------------------------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fstackademic%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=---header_actions--4c6f4b15fe63---------------------clap_footer-----------)

2.7K

25

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=---header_actions--4c6f4b15fe63---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=---header_actions--4c6f4b15fe63---------------------post_audio_button-----------)

![Image 4: a man is sitting in front of a computer](https://miro.medium.com/v2/resize:fit:700/1*iGrbJxU6oV3q7LeNV28gWg.jpeg)

AI generated Image

Not a member yet, read it [_here_](https://medium.com/stackademic/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?sk=3dbcee612f6e06225dd660e4a669bd7f)_._

I assume you have been coding in Python for a while and you think you are pretty good at it. Or you still just navigate the endless stream of StackOverflow pages. Either way I can bet that you are craving for scripts that’ll make you look like a coding wizard.

I have got 20 Python scripts that’ll have you impressing your colleagues, automating the un-automatable, and solving problems you didn’t even know you had.

Let’s get to it!

1\. File Duplication Finder (Save Your Hard Drive’s Life)
---------------------------------------------------------

You ever look at your hard drive and wonder, _Why do I only have 100MB left?_ File duplicates. They’re sneaky. Here’s a script to find and delete them:

import os  
import hashlib  
  
def hash\_file(filename):  
    h = hashlib.md5()  
    with open(filename, 'rb') as file:  
        while chunk := file.read(8192):  
            h.update(chunk)  
    return h.hexdigest()  
  
def find\_duplicates(folder):  
    hashes = {}  
    for dirpath, \_, filenames in os.walk(folder):  
        for f in filenames:  
            full\_path = os.path.join(dirpath, f)  
            file\_hash = hash\_file(full\_path)  
            if file\_hash in…

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63%3Fsource%3D-----4c6f4b15fe63---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----4c6f4b15fe63---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63%3Fsource%3D-----4c6f4b15fe63---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----4c6f4b15fe63---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63%3Fsource%3D-----4c6f4b15fe63---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----4c6f4b15fe63---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=-----4c6f4b15fe63---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fstackademic%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=---footer_actions--4c6f4b15fe63---------------------clap_footer-----------)

2.7K

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fstackademic%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=---footer_actions--4c6f4b15fe63---------------------clap_footer-----------)

2.7K

25

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=---footer_actions--4c6f4b15fe63---------------------bookmark_footer-----------)

[![Image 5: Abdur Rahman](https://miro.medium.com/v2/resize:fill:144:144/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=post_page---post_author_info--4c6f4b15fe63--------------------------------)

[![Image 6: Stackademic](https://miro.medium.com/v2/resize:fill:64:64/1*U-kjsW7IZUobnoy1gAp1UQ.png)](https://blog.stackademic.com/?source=post_page---post_author_info--4c6f4b15fe63--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--post_author_info--4c6f4b15fe63---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F844f13e47e8e&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&newsletterV3=7d16279b0e18&newsletterV3Id=844f13e47e8e&user=Abdur+Rahman&userId=7d16279b0e18&source=---post_author_info--4c6f4b15fe63---------------------subscribe_user-----------)

[Stackademic](https://blog.stackademic.com/?source=post_page---post_author_info--4c6f4b15fe63--------------------------------)

𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐚𝐧𝐝 𝐒𝐡𝐚𝐫𝐢𝐧𝐠 𝐊𝐧𝐨𝐰𝐥𝐞𝐝𝐠𝐞 𝐄𝐯𝐞𝐫𝐲𝐝𝐚𝐲 | 𝐏𝐲𝐭𝐡𝐨𝐧 𝐢𝐬 ❤️ | 𝐌𝐮𝐬𝐥𝐢𝐦 | #𝐢𝐬𝐭𝐚𝐧𝐝𝐰𝐢𝐭𝐡𝐩𝐚𝐥𝐞𝐬𝐭𝐢𝐧𝐞🍉

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--post_author_info--4c6f4b15fe63---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F844f13e47e8e&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&newsletterV3=7d16279b0e18&newsletterV3Id=844f13e47e8e&user=Abdur+Rahman&userId=7d16279b0e18&source=---post_author_info--4c6f4b15fe63---------------------subscribe_user-----------)

More from Abdur Rahman and Stackademic
--------------------------------------

[![Image 8: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----4c6f4b15fe63----0---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----4c6f4b15fe63----0---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----4c6f4b15fe63----0---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://medium.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=author_recirc-----4c6f4b15fe63----0---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[5.1K 23](https://medium.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=author_recirc-----4c6f4b15fe63----0---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----4c6f4b15fe63----0-----------------bookmark_preview----79efcc56_e370_47c6_bf7c_ca528309cda8-------)

![Image 9: 20 Git Command-Line Tricks Every Developer Should Know](https://miro.medium.com/v2/resize:fit:679/1*lyEwUyQSkpm0rb4yvn80qA.png)

[![Image 10: Crafting-Code](https://miro.medium.com/v2/resize:fill:20:20/1*CyROwr3ZEi4KqVBfjqHHeg.png)](https://medium.com/@craftingcode?source=author_recirc-----4c6f4b15fe63----1---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Crafting-Code](https://medium.com/@craftingcode?source=author_recirc-----4c6f4b15fe63----1---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----4c6f4b15fe63----1---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[20 Git Command-Line Tricks Every Developer Should Know ------------------------------------------------------ ### Git Smarter, Code Faster](https://medium.com/20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9?source=author_recirc-----4c6f4b15fe63----1---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[1.5K 20](https://medium.com/20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9?source=author_recirc-----4c6f4b15fe63----1---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf817e83d6b9&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9&source=-----4c6f4b15fe63----1-----------------bookmark_preview----79efcc56_e370_47c6_bf7c_ca528309cda8-------)

![Image 11: Title Image](https://miro.medium.com/v2/resize:fit:679/0*02Rxo8X6uaLmkCX3.png)

[![Image 12: Madza](https://miro.medium.com/v2/resize:fill:20:20/1*SCx6IqmQJAzddxnBTcXlFg.png)](https://madzadev.medium.com/?source=author_recirc-----4c6f4b15fe63----2---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Madza](https://madzadev.medium.com/?source=author_recirc-----4c6f4b15fe63----2---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----4c6f4b15fe63----2---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[16 Open-Source Projects to Improve Your Developer Workflow 👨‍💻🔥 ------------------------------------------------------------------](https://medium.com/16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57?source=author_recirc-----4c6f4b15fe63----2---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[969 10](https://medium.com/16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57?source=author_recirc-----4c6f4b15fe63----2---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffdd3b8c16e57&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57&source=-----4c6f4b15fe63----2-----------------bookmark_preview----79efcc56_e370_47c6_bf7c_ca528309cda8-------)

![Image 13: 5 Overrated Python Libraries (And What You Should Use Instead)](https://miro.medium.com/v2/resize:fit:679/1*fX-RNRwwSujOY05gXdoAlQ.jpeg)

[![Image 14: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----4c6f4b15fe63----3---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----4c6f4b15fe63----3---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Python in Plain English](https://python.plainenglish.io/?source=author_recirc-----4c6f4b15fe63----3---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[5 Overrated Python Libraries (And What You Should Use Instead) -------------------------------------------------------------- ### Traditional Devs, Look Away — This One’s Not for You!](https://python.plainenglish.io/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180?source=author_recirc-----4c6f4b15fe63----3---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

Nov 3

[1.5K 12](https://python.plainenglish.io/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180?source=author_recirc-----4c6f4b15fe63----3---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=-----4c6f4b15fe63----3-----------------bookmark_preview----79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[See all from Abdur Rahman](https://medium.com/@abdur-rahman?source=post_page-----4c6f4b15fe63--------------------------------)

[See all from Stackademic](https://blog.stackademic.com/?source=post_page-----4c6f4b15fe63--------------------------------)

[![Image 16: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Stackademic](https://blog.stackademic.com/?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://medium.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[5.1K 23](https://medium.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----4c6f4b15fe63----0-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[![Image 18: Harendra](https://miro.medium.com/v2/resize:fill:20:20/1*uTEzlRvlNBr3ralJoTQkmg.jpeg)](https://medium.com/@harendra21?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Harendra](https://medium.com/@harendra21?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[4.1K 50](https://medium.com/@harendra21/how-i-am-using-a-lifetime-100-free-server-bd241e3a347a?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd241e3a347a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40harendra21%2Fhow-i-am-using-a-lifetime-100-free-server-bd241e3a347a&source=-----4c6f4b15fe63----1-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

![Image 31: 7 Productivity Hacks I Stole From a Principal Software Engineer](https://miro.medium.com/v2/resize:fit:679/1*s3aLPx2uW1ZPb0LkBAO1hg.jpeg)

[![Image 32: Nidhi Jain 👩‍💻](https://miro.medium.com/v2/resize:fill:20:20/1*uyl1LwZSTVTyiSkKNCjrCQ.png)](https://medium.com/@nidhijain23?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Nidhi Jain 👩‍💻](https://medium.com/@nidhijain23?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Code Like A Girl](https://code.likeagirl.io/?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[7 Productivity Hacks I Stole From a Principal Software Engineer --------------------------------------------------------------- ### Golden tips and tricks that can make you unstoppable](https://code.likeagirl.io/7-productivity-hacks-i-stole-from-a-principal-software-engineer-6a8825157198?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[4.3K 81](https://code.likeagirl.io/7-productivity-hacks-i-stole-from-a-principal-software-engineer-6a8825157198?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a8825157198&operation=register&redirect=https%3A%2F%2Fcode.likeagirl.io%2F7-productivity-hacks-i-stole-from-a-principal-software-engineer-6a8825157198&source=-----4c6f4b15fe63----0-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

![Image 33: Can you solve this famous interview question?](https://miro.medium.com/v2/resize:fit:679/1*ojvznevS00pnY77w0jnxPg.jpeg)

[![Image 34: Paolo Molignini, PhD](https://miro.medium.com/v2/resize:fill:20:20/1*G00MhBr4w2Ja-mXFgZ6g1Q.jpeg)](https://medium.com/@moligninip?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Paolo Molignini, PhD](https://medium.com/@moligninip?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Puzzle Sphere](https://medium.com/puzzle-sphere?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Can you solve this famous interview question? --------------------------------------------- ### 100 passengers, 100 seats — but the first one sits randomly! What’s the chance the last passenger ends up in their own seat? Find out here!](https://medium.com/puzzle-sphere/can-you-solve-this-famous-interview-question-91d0db846935?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

Oct 5

[2.3K 60](https://medium.com/puzzle-sphere/can-you-solve-this-famous-interview-question-91d0db846935?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F91d0db846935&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fpuzzle-sphere%2Fcan-you-solve-this-famous-interview-question-91d0db846935&source=-----4c6f4b15fe63----1-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

![Image 35: 12 Production-Grade Python Code Styles I’ve Picked Up From Work](https://miro.medium.com/v2/resize:fit:679/1*5llI8jewhOwDTGzh_r5ObQ.png)

[![Image 36: Liu Zuo Lin](https://miro.medium.com/v2/resize:fill:20:20/1*Z5dMY4-vS6G69lMMdn3xIQ.jpeg)](https://zlliu.medium.com/?source=read_next_recirc-----4c6f4b15fe63----2---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Liu Zuo Lin](https://zlliu.medium.com/?source=read_next_recirc-----4c6f4b15fe63----2---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Level Up Coding](https://levelup.gitconnected.com/?source=read_next_recirc-----4c6f4b15fe63----2---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[12 Production-Grade Python Code Styles I’ve Picked Up From Work --------------------------------------------------------------- ### Read Free…](https://levelup.gitconnected.com/12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d?source=read_next_recirc-----4c6f4b15fe63----2---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

Nov 2

[2.2K 21](https://levelup.gitconnected.com/12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d?source=read_next_recirc-----4c6f4b15fe63----2---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fad32d8ae630d&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2F12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d&source=-----4c6f4b15fe63----2-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

![Image 37: OnlyFans is Finally Dead](https://miro.medium.com/v2/resize:fit:679/1*tHQBDWibz-kXlEGN7AqUcQ.jpeg)

[![Image 38: Desiree Peralta](https://miro.medium.com/v2/resize:fill:20:20/1*6mgEZmtgEIYKM-aqXYAgMA@2x.jpeg)](https://dessyperalt.medium.com/?source=read_next_recirc-----4c6f4b15fe63----3---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Desiree Peralta](https://dessyperalt.medium.com/?source=read_next_recirc-----4c6f4b15fe63----3---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Publishous](https://medium.com/publishous?source=read_next_recirc-----4c6f4b15fe63----3---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[OnlyFans is Finally Dead ------------------------ ### And I’m happy about it.](https://medium.com/publishous/onlyfans-is-finally-dead-9c1e24dc31b2?source=read_next_recirc-----4c6f4b15fe63----3---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

Oct 8

[18.6K 377](https://medium.com/publishous/onlyfans-is-finally-dead-9c1e24dc31b2?source=read_next_recirc-----4c6f4b15fe63----3---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c1e24dc31b2&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fpublishous%2Fonlyfans-is-finally-dead-9c1e24dc31b2&source=-----4c6f4b15fe63----3-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

## Visual Content Analysis

### Image Analysis
Title: 20 Python Scripts To Automate Your Daily Tasks - Stackademic

URL Source: https://medium.com/stackademic/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63

Published Time: 2024-10-07T03:18:42.230Z

Markdown Content:
20 Python Scripts To Automate Your Daily Tasks | by Abdur Rahman | Oct, 2024 | Stackademic
===============
 

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

20 Python Scripts To Automate Your Daily Tasks
==============================================

A must-have collection for every developer
------------------------------------------

[![Image 2: Abdur Rahman](https://miro.medium.com/v2/resize:fill:88:88/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=post_page---byline--4c6f4b15fe63--------------------------------)

[![Image 3: Stackademic](https://miro.medium.com/v2/resize:fill:48:48/1*U-kjsW7IZUobnoy1gAp1UQ.png)](https://blog.stackademic.com/?source=post_page---byline--4c6f4b15fe63--------------------------------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=post_page---byline--4c6f4b15fe63--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--byline--4c6f4b15fe63---------------------post_header-----------)

[Stackademic](https://blog.stackademic.com/?source=post_page---byline--4c6f4b15fe63--------------------------------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fstackademic%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=---header_actions--4c6f4b15fe63---------------------clap_footer-----------)

2.7K

25

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=---header_actions--4c6f4b15fe63---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=---header_actions--4c6f4b15fe63---------------------post_audio_button-----------)

![Image 4: a man is sitting in front of a computer](https://miro.medium.com/v2/resize:fit:700/1*iGrbJxU6oV3q7LeNV28gWg.jpeg)

AI generated Image

Not a member yet, read it [_here_](https://medium.com/stackademic/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?sk=3dbcee612f6e06225dd660e4a669bd7f)_._

I assume you have been coding in Python for a while and you think you are pretty good at it. Or you still just navigate the endless stream of StackOverflow pages. Either way I can bet that you are craving for scripts that’ll make you look like a coding wizard.

I have got 20 Python scripts that’ll have you impressing your colleagues, automating the un-automatable, and solving problems you didn’t even know you had.

Let’s get to it!

1\. File Duplication Finder (Save Your Hard Drive’s Life)
---------------------------------------------------------

You ever look at your hard drive and wonder, _Why do I only have 100MB left?_ File duplicates. They’re sneaky. Here’s a script to find and delete them:

import os  
import hashlib  
  
def hash\_file(filename):  
    h = hashlib.md5()  
    with open(filename, 'rb') as file:  
        while chunk := file.read(8192):  
            h.update(chunk)  
    return h.hexdigest()  
  
def find\_duplicates(folder):  
    hashes = {}  
    for dirpath, \_, filenames in os.walk(folder):  
        for f in filenames:  
            full\_path = os.path.join(dirpath, f)  
            file\_hash = hash\_file(full\_path)  
            if file\_hash in…

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63%3Fsource%3D-----4c6f4b15fe63---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----4c6f4b15fe63---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63%3Fsource%3D-----4c6f4b15fe63---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----4c6f4b15fe63---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63%3Fsource%3D-----4c6f4b15fe63---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----4c6f4b15fe63---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=-----4c6f4b15fe63---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fstackademic%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=---footer_actions--4c6f4b15fe63---------------------clap_footer-----------)

2.7K

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fstackademic%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=---footer_actions--4c6f4b15fe63---------------------clap_footer-----------)

2.7K

25

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=---footer_actions--4c6f4b15fe63---------------------bookmark_footer-----------)

[![Image 5: Abdur Rahman](https://miro.medium.com/v2/resize:fill:144:144/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=post_page---post_author_info--4c6f4b15fe63--------------------------------)

[![Image 6: Stackademic](https://miro.medium.com/v2/resize:fill:64:64/1*U-kjsW7IZUobnoy1gAp1UQ.png)](https://blog.stackademic.com/?source=post_page---post_author_info--4c6f4b15fe63--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--post_author_info--4c6f4b15fe63---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F844f13e47e8e&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&newsletterV3=7d16279b0e18&newsletterV3Id=844f13e47e8e&user=Abdur+Rahman&userId=7d16279b0e18&source=---post_author_info--4c6f4b15fe63---------------------subscribe_user-----------)

[Stackademic](https://blog.stackademic.com/?source=post_page---post_author_info--4c6f4b15fe63--------------------------------)

𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐚𝐧𝐝 𝐒𝐡𝐚𝐫𝐢𝐧𝐠 𝐊𝐧𝐨𝐰𝐥𝐞𝐝𝐠𝐞 𝐄𝐯𝐞𝐫𝐲𝐝𝐚𝐲 | 𝐏𝐲𝐭𝐡𝐨𝐧 𝐢𝐬 ❤️ | 𝐌𝐮𝐬𝐥𝐢𝐦 | #𝐢𝐬𝐭𝐚𝐧𝐝𝐰𝐢𝐭𝐡𝐩𝐚𝐥𝐞𝐬𝐭𝐢𝐧𝐞🍉

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--post_author_info--4c6f4b15fe63---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F844f13e47e8e&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&newsletterV3=7d16279b0e18&newsletterV3Id=844f13e47e8e&user=Abdur+Rahman&userId=7d16279b0e18&source=---post_author_info--4c6f4b15fe63---------------------subscribe_user-----------)

More from Abdur Rahman and Stackademic
--------------------------------------

[![Image 8: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----4c6f4b15fe63----0---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----4c6f4b15fe63----0---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----4c6f4b15fe63----0---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://medium.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=author_recirc-----4c6f4b15fe63----0---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[5.1K 23](https://medium.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=author_recirc-----4c6f4b15fe63----0---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----4c6f4b15fe63----0-----------------bookmark_preview----79efcc56_e370_47c6_bf7c_ca528309cda8-------)

![Image 9: 20 Git Command-Line Tricks Every Developer Should Know](https://miro.medium.com/v2/resize:fit:679/1*lyEwUyQSkpm0rb4yvn80qA.png)

[![Image 10: Crafting-Code](https://miro.medium.com/v2/resize:fill:20:20/1*CyROwr3ZEi4KqVBfjqHHeg.png)](https://medium.com/@craftingcode?source=author_recirc-----4c6f4b15fe63----1---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Crafting-Code](https://medium.com/@craftingcode?source=author_recirc-----4c6f4b15fe63----1---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----4c6f4b15fe63----1---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[20 Git Command-Line Tricks Every Developer Should Know ------------------------------------------------------ ### Git Smarter, Code Faster](https://medium.com/20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9?source=author_recirc-----4c6f4b15fe63----1---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[1.5K 20](https://medium.com/20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9?source=author_recirc-----4c6f4b15fe63----1---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf817e83d6b9&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9&source=-----4c6f4b15fe63----1-----------------bookmark_preview----79efcc56_e370_47c6_bf7c_ca528309cda8-------)

![Image 11: Title Image](https://miro.medium.com/v2/resize:fit:679/0*02Rxo8X6uaLmkCX3.png)

[![Image 12: Madza](https://miro.medium.com/v2/resize:fill:20:20/1*SCx6IqmQJAzddxnBTcXlFg.png)](https://madzadev.medium.com/?source=author_recirc-----4c6f4b15fe63----2---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Madza](https://madzadev.medium.com/?source=author_recirc-----4c6f4b15fe63----2---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----4c6f4b15fe63----2---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[16 Open-Source Projects to Improve Your Developer Workflow 👨‍💻🔥 ------------------------------------------------------------------](https://medium.com/16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57?source=author_recirc-----4c6f4b15fe63----2---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[969 10](https://medium.com/16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57?source=author_recirc-----4c6f4b15fe63----2---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffdd3b8c16e57&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57&source=-----4c6f4b15fe63----2-----------------bookmark_preview----79efcc56_e370_47c6_bf7c_ca528309cda8-------)

![Image 13: 5 Overrated Python Libraries (And What You Should Use Instead)](https://miro.medium.com/v2/resize:fit:679/1*fX-RNRwwSujOY05gXdoAlQ.jpeg)

[![Image 14: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----4c6f4b15fe63----3---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----4c6f4b15fe63----3---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[Python in Plain English](https://python.plainenglish.io/?source=author_recirc-----4c6f4b15fe63----3---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[5 Overrated Python Libraries (And What You Should Use Instead) -------------------------------------------------------------- ### Traditional Devs, Look Away — This One’s Not for You!](https://python.plainenglish.io/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180?source=author_recirc-----4c6f4b15fe63----3---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

Nov 3

[1.5K 12](https://python.plainenglish.io/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180?source=author_recirc-----4c6f4b15fe63----3---------------------79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=-----4c6f4b15fe63----3-----------------bookmark_preview----79efcc56_e370_47c6_bf7c_ca528309cda8-------)

[See all from Abdur Rahman](https://medium.com/@abdur-rahman?source=post_page-----4c6f4b15fe63--------------------------------)

[See all from Stackademic](https://blog.stackademic.com/?source=post_page-----4c6f4b15fe63--------------------------------)

[![Image 16: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Stackademic](https://blog.stackademic.com/?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://medium.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[5.1K 23](https://medium.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----4c6f4b15fe63----0-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[![Image 18: Harendra](https://miro.medium.com/v2/resize:fill:20:20/1*uTEzlRvlNBr3ralJoTQkmg.jpeg)](https://medium.com/@harendra21?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Harendra](https://medium.com/@harendra21?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[4.1K 50](https://medium.com/@harendra21/how-i-am-using-a-lifetime-100-free-server-bd241e3a347a?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd241e3a347a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40harendra21%2Fhow-i-am-using-a-lifetime-100-free-server-bd241e3a347a&source=-----4c6f4b15fe63----1-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

![Image 31: 7 Productivity Hacks I Stole From a Principal Software Engineer](https://miro.medium.com/v2/resize:fit:679/1*s3aLPx2uW1ZPb0LkBAO1hg.jpeg)

[![Image 32: Nidhi Jain 👩‍💻](https://miro.medium.com/v2/resize:fill:20:20/1*uyl1LwZSTVTyiSkKNCjrCQ.png)](https://medium.com/@nidhijain23?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Nidhi Jain 👩‍💻](https://medium.com/@nidhijain23?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Code Like A Girl](https://code.likeagirl.io/?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[7 Productivity Hacks I Stole From a Principal Software Engineer --------------------------------------------------------------- ### Golden tips and tricks that can make you unstoppable](https://code.likeagirl.io/7-productivity-hacks-i-stole-from-a-principal-software-engineer-6a8825157198?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[4.3K 81](https://code.likeagirl.io/7-productivity-hacks-i-stole-from-a-principal-software-engineer-6a8825157198?source=read_next_recirc-----4c6f4b15fe63----0---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a8825157198&operation=register&redirect=https%3A%2F%2Fcode.likeagirl.io%2F7-productivity-hacks-i-stole-from-a-principal-software-engineer-6a8825157198&source=-----4c6f4b15fe63----0-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

![Image 33: Can you solve this famous interview question?](https://miro.medium.com/v2/resize:fit:679/1*ojvznevS00pnY77w0jnxPg.jpeg)

[![Image 34: Paolo Molignini, PhD](https://miro.medium.com/v2/resize:fill:20:20/1*G00MhBr4w2Ja-mXFgZ6g1Q.jpeg)](https://medium.com/@moligninip?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Paolo Molignini, PhD](https://medium.com/@moligninip?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Puzzle Sphere](https://medium.com/puzzle-sphere?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Can you solve this famous interview question? --------------------------------------------- ### 100 passengers, 100 seats — but the first one sits randomly! What’s the chance the last passenger ends up in their own seat? Find out here!](https://medium.com/puzzle-sphere/can-you-solve-this-famous-interview-question-91d0db846935?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

Oct 5

[2.3K 60](https://medium.com/puzzle-sphere/can-you-solve-this-famous-interview-question-91d0db846935?source=read_next_recirc-----4c6f4b15fe63----1---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F91d0db846935&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fpuzzle-sphere%2Fcan-you-solve-this-famous-interview-question-91d0db846935&source=-----4c6f4b15fe63----1-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

![Image 35: 12 Production-Grade Python Code Styles I’ve Picked Up From Work](https://miro.medium.com/v2/resize:fit:679/1*5llI8jewhOwDTGzh_r5ObQ.png)

[![Image 36: Liu Zuo Lin](https://miro.medium.com/v2/resize:fill:20:20/1*Z5dMY4-vS6G69lMMdn3xIQ.jpeg)](https://zlliu.medium.com/?source=read_next_recirc-----4c6f4b15fe63----2---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Liu Zuo Lin](https://zlliu.medium.com/?source=read_next_recirc-----4c6f4b15fe63----2---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Level Up Coding](https://levelup.gitconnected.com/?source=read_next_recirc-----4c6f4b15fe63----2---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[12 Production-Grade Python Code Styles I’ve Picked Up From Work --------------------------------------------------------------- ### Read Free…](https://levelup.gitconnected.com/12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d?source=read_next_recirc-----4c6f4b15fe63----2---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

Nov 2

[2.2K 21](https://levelup.gitconnected.com/12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d?source=read_next_recirc-----4c6f4b15fe63----2---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fad32d8ae630d&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2F12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d&source=-----4c6f4b15fe63----2-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)

![Image 37: OnlyFans is Finally Dead](https://miro.medium.com/v2/resize:fit:679/1*tHQBDWibz-kXlEGN7AqUcQ.jpeg)

[![Image 38: Desiree Peralta](https://miro.medium.com/v2/resize:fill:20:20/1*6mgEZmtgEIYKM-aqXYAgMA@2x.jpeg)](https://dessyperalt.medium.com/?source=read_next_recirc-----4c6f4b15fe63----3---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Desiree Peralta](https://dessyperalt.medium.com/?source=read_next_recirc-----4c6f4b15fe63----3---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[Publishous](https://medium.com/publishous?source=read_next_recirc-----4c6f4b15fe63----3---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[OnlyFans is Finally Dead ------------------------ ### And I’m happy about it.](https://medium.com/publishous/onlyfans-is-finally-dead-9c1e24dc31b2?source=read_next_recirc-----4c6f4b15fe63----3---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

Oct 8

[18.6K 377](https://medium.com/publishous/onlyfans-is-finally-dead-9c1e24dc31b2?source=read_next_recirc-----4c6f4b15fe63----3---------------------309f4a00_8460_44a0_8b7d_91c0491c8387-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c1e24dc31b2&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fpublishous%2Fonlyfans-is-finally-dead-9c1e24dc31b2&source=-----4c6f4b15fe63----3-----------------bookmark_preview----309f4a00_8460_44a0_8b7d_91c0491c8387-------)


---

## https://medium.com/stackademic/is-python-still-the-king-of-data-science-476f1e3191b3

Title: Python is No More The King of Data Science - Stackademic

URL Source: https://medium.com/stackademic/is-python-still-the-king-of-data-science-476f1e3191b3

Python is No More The King of Data Science
==========================================

5 Reasons Why Python is Losing Its Crown
----------------------------------------

5.1K

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=---header_actions--476f1e3191b3---------------------post_audio_button-----------)

![Image 4: a cartoon of a king sitting on a throne](https://miro.medium.com/v2/resize:fit:700/1*uiA0nCufUQs-K64ebSUhew.jpeg)

AI Generated using Ideogram 2.0

Non-member? Read it [_here_](https://medium.com/stackademic/is-python-still-the-king-of-data-science-476f1e3191b3?sk=1ade22551310fc165a94c8af6c8093d5) for free

If you are reading this, then there is a high chance that Python is your go-to language when anyone talks about data science, and honestly, no one can argue with that. Python has remained the king of the Data Science Kingdom because of its excellent libraries, such as `Numpy`, `Pandas` and `scikit-learn`.

But if something has always been on top, that does not mean that it is safe up there forever. You hear whispers; you see the rise of new languages — maybe you’re wondering,

> Is Python’s time running out?

Okay, before you throw your Jupyter notebook on my face, let me make something very clear: I do think Python is the GOAT. I don’t deny that. Yet, it doesn’t come without flaws either. It might not lose its place in one night, but there are cracks forming.

> **Edit:** Hey everyone, this article reflects my **personal opinion**, and I fully respect that others may disagree. Healthy debate is welcome — after all, different perspectives are what drive progress!

Alright, so let’s see 5 reasons that suggest Python isn’t going to stay on top forever!

1\. Performance Bottlenecks: Python’s…
--------------------------------------

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3%3Fsource%3D-----476f1e3191b3---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----476f1e3191b3---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3%3Fsource%3D-----476f1e3191b3---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----476f1e3191b3---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3%3Fsource%3D-----476f1e3191b3---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----476f1e3191b3---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----476f1e3191b3---------------------post_regwall-----------)

5.1K

5.1K

![Image 7: 20 Python Scripts To Automate Your Daily Tasks](https://miro.medium.com/v2/resize:fit:679/1*iGrbJxU6oV3q7LeNV28gWg.jpeg)

[![Image 8: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----476f1e3191b3----0---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----476f1e3191b3----0---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----476f1e3191b3----0---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[20 Python Scripts To Automate Your Daily Tasks ---------------------------------------------- ### A must-have collection for every developer](https://medium.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=author_recirc-----476f1e3191b3----0---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[2.7K 25](https://medium.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=author_recirc-----476f1e3191b3----0---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=-----476f1e3191b3----0-----------------bookmark_preview----ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[![Image 10: Crafting-Code](https://miro.medium.com/v2/resize:fill:20:20/1*CyROwr3ZEi4KqVBfjqHHeg.png)](https://medium.com/@craftingcode?source=author_recirc-----476f1e3191b3----1---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Crafting-Code](https://medium.com/@craftingcode?source=author_recirc-----476f1e3191b3----1---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----476f1e3191b3----1---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[20 Git Command-Line Tricks Every Developer Should Know ------------------------------------------------------ ### Git Smarter, Code Faster](https://medium.com/20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9?source=author_recirc-----476f1e3191b3----1---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[1.5K 20](https://medium.com/20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9?source=author_recirc-----476f1e3191b3----1---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf817e83d6b9&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9&source=-----476f1e3191b3----1-----------------bookmark_preview----ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[![Image 12: Madza](https://miro.medium.com/v2/resize:fill:20:20/1*SCx6IqmQJAzddxnBTcXlFg.png)](https://madzadev.medium.com/?source=author_recirc-----476f1e3191b3----2---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Madza](https://madzadev.medium.com/?source=author_recirc-----476f1e3191b3----2---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----476f1e3191b3----2---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[16 Open-Source Projects to Improve Your Developer Workflow 👨‍💻🔥 ------------------------------------------------------------------](https://medium.com/16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57?source=author_recirc-----476f1e3191b3----2---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[969 10](https://medium.com/16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57?source=author_recirc-----476f1e3191b3----2---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffdd3b8c16e57&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57&source=-----476f1e3191b3----2-----------------bookmark_preview----ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[![Image 14: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----476f1e3191b3----3---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----476f1e3191b3----3---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Python in Plain English](https://python.plainenglish.io/?source=author_recirc-----476f1e3191b3----3---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[1.5K 12](https://python.plainenglish.io/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180?source=author_recirc-----476f1e3191b3----3---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=-----476f1e3191b3----3-----------------bookmark_preview----ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

![Image 15: 20 Python Scripts To Automate Your Daily Tasks](https://miro.medium.com/v2/resize:fit:679/1*iGrbJxU6oV3q7LeNV28gWg.jpeg)

[![Image 16: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[20 Python Scripts To Automate Your Daily Tasks ---------------------------------------------- ### A must-have collection for every developer](https://medium.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[2.7K 25](https://medium.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=-----476f1e3191b3----0-----------------bookmark_preview----807b7326_58ef_4790_9520_bd9a981f1057-------)

[![Image 18: Harendra](https://miro.medium.com/v2/resize:fill:20:20/1*uTEzlRvlNBr3ralJoTQkmg.jpeg)](https://medium.com/@harendra21?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Harendra](https://medium.com/@harendra21?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[4.1K 50](https://medium.com/@harendra21/how-i-am-using-a-lifetime-100-free-server-bd241e3a347a?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd241e3a347a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40harendra21%2Fhow-i-am-using-a-lifetime-100-free-server-bd241e3a347a&source=-----476f1e3191b3----1-----------------bookmark_preview----807b7326_58ef_4790_9520_bd9a981f1057-------)

[![Image 32: Paolo Molignini, PhD](https://miro.medium.com/v2/resize:fill:20:20/1*G00MhBr4w2Ja-mXFgZ6g1Q.jpeg)](https://medium.com/@moligninip?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Paolo Molignini, PhD](https://medium.com/@moligninip?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Puzzle Sphere](https://medium.com/puzzle-sphere?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[2.3K 60](https://medium.com/puzzle-sphere/can-you-solve-this-famous-interview-question-91d0db846935?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F91d0db846935&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fpuzzle-sphere%2Fcan-you-solve-this-famous-interview-question-91d0db846935&source=-----476f1e3191b3----0-----------------bookmark_preview----807b7326_58ef_4790_9520_bd9a981f1057-------)

[![Image 34: AI Rabbit](https://miro.medium.com/v2/resize:fill:20:20/1*1cIrPiG5AyUHt-rt6gh_Vw.jpeg)](https://medium.com/@airabbitX?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[AI Rabbit](https://medium.com/@airabbitX?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[CodeX](https://medium.com/codex?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[1.4K 22](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc1ada7a8d91&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fhas-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91&source=-----476f1e3191b3----1-----------------bookmark_preview----807b7326_58ef_4790_9520_bd9a981f1057-------)

[![Image 36: Lucas Samba](https://miro.medium.com/v2/resize:fill:20:20/1*R0PCZj_QUhumxixbZeUNAw.jpeg)](https://medium.com/@lucassamba?source=read_next_recirc-----476f1e3191b3----2---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Lucas Samba](https://medium.com/@lucassamba?source=read_next_recirc-----476f1e3191b3----2---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[621 16](https://medium.com/@lucassamba/3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1?source=read_next_recirc-----476f1e3191b3----2---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[![Image 38: Liu Zuo Lin](https://miro.medium.com/v2/resize:fill:20:20/1*Z5dMY4-vS6G69lMMdn3xIQ.jpeg)](https://zlliu.medium.com/?source=read_next_recirc-----476f1e3191b3----3---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Liu Zuo Lin](https://zlliu.medium.com/?source=read_next_recirc-----476f1e3191b3----3---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Level Up Coding](https://levelup.gitconnected.com/?source=read_next_recirc-----476f1e3191b3----3---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[2.2K 21](https://levelup.gitconnected.com/12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d?source=read_next_recirc-----476f1e3191b3----3---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fad32d8ae630d&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2F12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d&source=-----476f1e3191b3----3-----------------bookmark_preview----807b7326_58ef_4790_9520_bd9a981f1057-------)

## Visual Content Analysis

### Image Analysis
Title: Python is No More The King of Data Science - Stackademic

URL Source: https://medium.com/stackademic/is-python-still-the-king-of-data-science-476f1e3191b3

Python is No More The King of Data Science
==========================================

5 Reasons Why Python is Losing Its Crown
----------------------------------------

5.1K

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=---header_actions--476f1e3191b3---------------------post_audio_button-----------)

![Image 4: a cartoon of a king sitting on a throne](https://miro.medium.com/v2/resize:fit:700/1*uiA0nCufUQs-K64ebSUhew.jpeg)

AI Generated using Ideogram 2.0

Non-member? Read it [_here_](https://medium.com/stackademic/is-python-still-the-king-of-data-science-476f1e3191b3?sk=1ade22551310fc165a94c8af6c8093d5) for free

If you are reading this, then there is a high chance that Python is your go-to language when anyone talks about data science, and honestly, no one can argue with that. Python has remained the king of the Data Science Kingdom because of its excellent libraries, such as `Numpy`, `Pandas` and `scikit-learn`.

But if something has always been on top, that does not mean that it is safe up there forever. You hear whispers; you see the rise of new languages — maybe you’re wondering,

> Is Python’s time running out?

Okay, before you throw your Jupyter notebook on my face, let me make something very clear: I do think Python is the GOAT. I don’t deny that. Yet, it doesn’t come without flaws either. It might not lose its place in one night, but there are cracks forming.

> **Edit:** Hey everyone, this article reflects my **personal opinion**, and I fully respect that others may disagree. Healthy debate is welcome — after all, different perspectives are what drive progress!

Alright, so let’s see 5 reasons that suggest Python isn’t going to stay on top forever!

1\. Performance Bottlenecks: Python’s…
--------------------------------------

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3%3Fsource%3D-----476f1e3191b3---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----476f1e3191b3---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3%3Fsource%3D-----476f1e3191b3---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----476f1e3191b3---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3%3Fsource%3D-----476f1e3191b3---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----476f1e3191b3---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----476f1e3191b3---------------------post_regwall-----------)

5.1K

5.1K

![Image 7: 20 Python Scripts To Automate Your Daily Tasks](https://miro.medium.com/v2/resize:fit:679/1*iGrbJxU6oV3q7LeNV28gWg.jpeg)

[![Image 8: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----476f1e3191b3----0---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----476f1e3191b3----0---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----476f1e3191b3----0---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[20 Python Scripts To Automate Your Daily Tasks ---------------------------------------------- ### A must-have collection for every developer](https://medium.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=author_recirc-----476f1e3191b3----0---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[2.7K 25](https://medium.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=author_recirc-----476f1e3191b3----0---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=-----476f1e3191b3----0-----------------bookmark_preview----ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[![Image 10: Crafting-Code](https://miro.medium.com/v2/resize:fill:20:20/1*CyROwr3ZEi4KqVBfjqHHeg.png)](https://medium.com/@craftingcode?source=author_recirc-----476f1e3191b3----1---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Crafting-Code](https://medium.com/@craftingcode?source=author_recirc-----476f1e3191b3----1---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----476f1e3191b3----1---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[20 Git Command-Line Tricks Every Developer Should Know ------------------------------------------------------ ### Git Smarter, Code Faster](https://medium.com/20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9?source=author_recirc-----476f1e3191b3----1---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[1.5K 20](https://medium.com/20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9?source=author_recirc-----476f1e3191b3----1---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf817e83d6b9&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-git-command-line-tricks-every-developer-should-know-bf817e83d6b9&source=-----476f1e3191b3----1-----------------bookmark_preview----ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[![Image 12: Madza](https://miro.medium.com/v2/resize:fill:20:20/1*SCx6IqmQJAzddxnBTcXlFg.png)](https://madzadev.medium.com/?source=author_recirc-----476f1e3191b3----2---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Madza](https://madzadev.medium.com/?source=author_recirc-----476f1e3191b3----2---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----476f1e3191b3----2---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[16 Open-Source Projects to Improve Your Developer Workflow 👨‍💻🔥 ------------------------------------------------------------------](https://medium.com/16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57?source=author_recirc-----476f1e3191b3----2---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[969 10](https://medium.com/16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57?source=author_recirc-----476f1e3191b3----2---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffdd3b8c16e57&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F16-open-source-projects-to-improve-your-developer-workflow-fdd3b8c16e57&source=-----476f1e3191b3----2-----------------bookmark_preview----ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[![Image 14: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----476f1e3191b3----3---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----476f1e3191b3----3---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[Python in Plain English](https://python.plainenglish.io/?source=author_recirc-----476f1e3191b3----3---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[1.5K 12](https://python.plainenglish.io/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180?source=author_recirc-----476f1e3191b3----3---------------------ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=-----476f1e3191b3----3-----------------bookmark_preview----ee65c5c0_faec_41ea_b26a_837ccd9a33e5-------)

![Image 15: 20 Python Scripts To Automate Your Daily Tasks](https://miro.medium.com/v2/resize:fit:679/1*iGrbJxU6oV3q7LeNV28gWg.jpeg)

[![Image 16: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[20 Python Scripts To Automate Your Daily Tasks ---------------------------------------------- ### A must-have collection for every developer](https://medium.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[2.7K 25](https://medium.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=-----476f1e3191b3----0-----------------bookmark_preview----807b7326_58ef_4790_9520_bd9a981f1057-------)

[![Image 18: Harendra](https://miro.medium.com/v2/resize:fill:20:20/1*uTEzlRvlNBr3ralJoTQkmg.jpeg)](https://medium.com/@harendra21?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Harendra](https://medium.com/@harendra21?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[4.1K 50](https://medium.com/@harendra21/how-i-am-using-a-lifetime-100-free-server-bd241e3a347a?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd241e3a347a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40harendra21%2Fhow-i-am-using-a-lifetime-100-free-server-bd241e3a347a&source=-----476f1e3191b3----1-----------------bookmark_preview----807b7326_58ef_4790_9520_bd9a981f1057-------)

[![Image 32: Paolo Molignini, PhD](https://miro.medium.com/v2/resize:fill:20:20/1*G00MhBr4w2Ja-mXFgZ6g1Q.jpeg)](https://medium.com/@moligninip?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Paolo Molignini, PhD](https://medium.com/@moligninip?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Puzzle Sphere](https://medium.com/puzzle-sphere?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[2.3K 60](https://medium.com/puzzle-sphere/can-you-solve-this-famous-interview-question-91d0db846935?source=read_next_recirc-----476f1e3191b3----0---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F91d0db846935&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fpuzzle-sphere%2Fcan-you-solve-this-famous-interview-question-91d0db846935&source=-----476f1e3191b3----0-----------------bookmark_preview----807b7326_58ef_4790_9520_bd9a981f1057-------)

[![Image 34: AI Rabbit](https://miro.medium.com/v2/resize:fill:20:20/1*1cIrPiG5AyUHt-rt6gh_Vw.jpeg)](https://medium.com/@airabbitX?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[AI Rabbit](https://medium.com/@airabbitX?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[CodeX](https://medium.com/codex?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[1.4K 22](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----476f1e3191b3----1---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc1ada7a8d91&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fhas-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91&source=-----476f1e3191b3----1-----------------bookmark_preview----807b7326_58ef_4790_9520_bd9a981f1057-------)

[![Image 36: Lucas Samba](https://miro.medium.com/v2/resize:fill:20:20/1*R0PCZj_QUhumxixbZeUNAw.jpeg)](https://medium.com/@lucassamba?source=read_next_recirc-----476f1e3191b3----2---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Lucas Samba](https://medium.com/@lucassamba?source=read_next_recirc-----476f1e3191b3----2---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[621 16](https://medium.com/@lucassamba/3-probability-questions-i-was-asked-in-walmart-data-scientist-interview-f3cddba746d1?source=read_next_recirc-----476f1e3191b3----2---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[![Image 38: Liu Zuo Lin](https://miro.medium.com/v2/resize:fill:20:20/1*Z5dMY4-vS6G69lMMdn3xIQ.jpeg)](https://zlliu.medium.com/?source=read_next_recirc-----476f1e3191b3----3---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Liu Zuo Lin](https://zlliu.medium.com/?source=read_next_recirc-----476f1e3191b3----3---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[Level Up Coding](https://levelup.gitconnected.com/?source=read_next_recirc-----476f1e3191b3----3---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[2.2K 21](https://levelup.gitconnected.com/12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d?source=read_next_recirc-----476f1e3191b3----3---------------------807b7326_58ef_4790_9520_bd9a981f1057-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fad32d8ae630d&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2F12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d&source=-----476f1e3191b3----3-----------------bookmark_preview----807b7326_58ef_4790_9520_bd9a981f1057-------)


---

## https://medium.com/python-in-plain-english/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180

Title: 5 Overrated Python Libraries (And What You Should Use Instead)

URL Source: https://medium.com/python-in-plain-english/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180

Published Time: 2024-11-03T05:32:54.717Z

Markdown Content:
5 Overrated Python Libraries (And What You Should Use Instead) | by Abdur Rahman | Nov, 2024 | Python in Plain English
===============
 

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

5 Overrated Python Libraries (And What You Should Use Instead)
==============================================================

Traditional Devs, Look Away — This One’s Not for You!
-----------------------------------------------------

[![Image 3: Python in Plain English](https://miro.medium.com/v2/resize:fill:48:48/1*VA3oGfprJgj5fRsTjXp6fA@2x.png)](https://python.plainenglish.io/?source=post_page---byline--106bd9ded180--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--byline--106bd9ded180---------------------post_header-----------)

[Python in Plain English](https://python.plainenglish.io/?source=post_page---byline--106bd9ded180--------------------------------)

Nov 3, 2024

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fpython-in-plain-english%2F106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=---header_actions--106bd9ded180---------------------clap_footer-----------)

1.5K

12

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=---header_actions--106bd9ded180---------------------post_audio_button-----------)

![Image 4](https://miro.medium.com/v2/resize:fit:1000/1*fX-RNRwwSujOY05gXdoAlQ.jpeg)

> **Not a member, yet? Read it free** [**_here_**](https://medium.com/@abdur-rahman/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180?sk=ffa347734cb26468c24d29021c9dc5e9)

Python’s vast ecosystem of libraries can feel like an amusement park for developers. With so many flashy rides, err, libraries to choose from, it’s easy to get swept up in the hype. But some libraries get more attention than they deserve. Whether they’re overhyped by “hot takes” on social media or just suffer from outdated design, a few commonly recommended tools aren’t always the best options out there. So, let’s take a look at some of Python’s most overrated libraries — and I’ll share alternatives that might actually serve you better.

> **Note:** This doesn’t mean these libraries aren’t valuable — quite the opposite! But for specific tasks, there are lighter, faster options that can do the trick just as well, sometimes even better.

1\. **Requests (Yes, Really!)**
===============================

Look, there is nothing inherently wrong with `Requests`. It’s intuitive, it has a great API, and it’s practically the mascot of Python HTTP libraries. But it’s overkill for when you just need to make simple GET/POST requests, and it will lag in environments where you want asynchronous performance.

**Why It’s Overrated:**
-----------------------

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180%3Fsource%3D-----106bd9ded180---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----106bd9ded180---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180%3Fsource%3D-----106bd9ded180---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----106bd9ded180---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180%3Fsource%3D-----106bd9ded180---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----106bd9ded180---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=-----106bd9ded180---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fpython-in-plain-english%2F106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=---footer_actions--106bd9ded180---------------------clap_footer-----------)

1.5K

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fpython-in-plain-english%2F106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=---footer_actions--106bd9ded180---------------------clap_footer-----------)

1.5K

12

[![Image 6: Python in Plain English](https://miro.medium.com/v2/resize:fill:64:64/1*VA3oGfprJgj5fRsTjXp6fA@2x.png)](https://python.plainenglish.io/?source=post_page---post_author_info--106bd9ded180--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--post_author_info--106bd9ded180---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F844f13e47e8e&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&newsletterV3=7d16279b0e18&newsletterV3Id=844f13e47e8e&user=Abdur+Rahman&userId=7d16279b0e18&source=---post_author_info--106bd9ded180---------------------subscribe_user-----------)

[Python in Plain English](https://python.plainenglish.io/?source=post_page---post_author_info--106bd9ded180--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--post_author_info--106bd9ded180---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F844f13e47e8e&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&newsletterV3=7d16279b0e18&newsletterV3Id=844f13e47e8e&user=Abdur+Rahman&userId=7d16279b0e18&source=---post_author_info--106bd9ded180---------------------subscribe_user-----------)

More from Abdur Rahman and Python in Plain English
--------------------------------------------------

[![Image 8: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----0---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----0---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----106bd9ded180----0---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=author_recirc-----106bd9ded180----0---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[5.1K 23](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=author_recirc-----106bd9ded180----0---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----106bd9ded180----0-----------------bookmark_preview----9fb44720_ed66_42f8_bee7_211542341fa5-------)

![Image 9: Why PyMuPDF4LLM is the Best Tool for Extracting Data from PDFs (Even if You Didn’t Know You Needed…](https://miro.medium.com/v2/resize:fit:679/0*_h8XywGiTHmSkmmU)

[![Image 10: Anoop Maurya](https://miro.medium.com/v2/resize:fill:20:20/1*GpLTfdPuDfw-8acfG4GhZg.jpeg)](https://medium.com/@mauryaanoop3?source=author_recirc-----106bd9ded180----1---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Anoop Maurya](https://medium.com/@mauryaanoop3?source=author_recirc-----106bd9ded180----1---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Python in Plain English](https://python.plainenglish.io/?source=author_recirc-----106bd9ded180----1---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Why PyMuPDF4LLM is the Best Tool for Extracting Data from PDFs (Even if You Didn’t Know You Needed… --------------------------------------------------------------------------------------------------- ### Stuck behind a paywall? Read for Free!](https://medium.com/why-pymupdf4llm-is-the-best-tool-for-extracting-data-from-pdfs-even-if-you-didnt-know-you-needed-7bff75313691?source=author_recirc-----106bd9ded180----1---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[1.5K 15](https://medium.com/why-pymupdf4llm-is-the-best-tool-for-extracting-data-from-pdfs-even-if-you-didnt-know-you-needed-7bff75313691?source=author_recirc-----106bd9ded180----1---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7bff75313691&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2Fwhy-pymupdf4llm-is-the-best-tool-for-extracting-data-from-pdfs-even-if-you-didnt-know-you-needed-7bff75313691&source=-----106bd9ded180----1-----------------bookmark_preview----9fb44720_ed66_42f8_bee7_211542341fa5-------)

![Image 11: 10 AI-Powered Python Libraries to Boost Your Next Project](https://miro.medium.com/v2/resize:fit:679/1*isqWuyZYRx2-sbFIuLwUJg.jpeg)

[![Image 12: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----2---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----2---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Python in Plain English](https://python.plainenglish.io/?source=author_recirc-----106bd9ded180----2---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[10 AI-Powered Python Libraries to Boost Your Next Project --------------------------------------------------------- ### From “Eh, pretty cool” to “Wow, how’d you do that?!”](https://medium.com/10-ai-powered-python-libraries-to-boost-your-next-project-ac74d614e3b8?source=author_recirc-----106bd9ded180----2---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[1K 3](https://medium.com/10-ai-powered-python-libraries-to-boost-your-next-project-ac74d614e3b8?source=author_recirc-----106bd9ded180----2---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac74d614e3b8&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F10-ai-powered-python-libraries-to-boost-your-next-project-ac74d614e3b8&source=-----106bd9ded180----2-----------------bookmark_preview----9fb44720_ed66_42f8_bee7_211542341fa5-------)

[![Image 14: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----3---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----3---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----106bd9ded180----3---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[20 Python Scripts To Automate Your Daily Tasks ---------------------------------------------- ### A must-have collection for every developer](https://blog.stackademic.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=author_recirc-----106bd9ded180----3---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[2.7K 25](https://blog.stackademic.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=author_recirc-----106bd9ded180----3---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=-----106bd9ded180----3-----------------bookmark_preview----9fb44720_ed66_42f8_bee7_211542341fa5-------)

[See all from Python in Plain English](https://python.plainenglish.io/?source=post_page-----106bd9ded180--------------------------------)

[![Image 16: Liu Zuo Lin](https://miro.medium.com/v2/resize:fill:20:20/1*Z5dMY4-vS6G69lMMdn3xIQ.jpeg)](https://zlliu.medium.com/?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Liu Zuo Lin](https://zlliu.medium.com/?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Level Up Coding](https://levelup.gitconnected.com/?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[2.2K 21](https://levelup.gitconnected.com/12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fad32d8ae630d&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2F12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d&source=-----106bd9ded180----0-----------------bookmark_preview----4cadf492_c11a_498c_bf25_52677407961d-------)

[![Image 18: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Stackademic](https://blog.stackademic.com/?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[5.1K 23](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----106bd9ded180----1-----------------bookmark_preview----4cadf492_c11a_498c_bf25_52677407961d-------)

[![Image 32: Harendra](https://miro.medium.com/v2/resize:fill:20:20/1*uTEzlRvlNBr3ralJoTQkmg.jpeg)](https://medium.com/@harendra21?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Harendra](https://medium.com/@harendra21?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[4.1K 50](https://medium.com/@harendra21/how-i-am-using-a-lifetime-100-free-server-bd241e3a347a?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd241e3a347a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40harendra21%2Fhow-i-am-using-a-lifetime-100-free-server-bd241e3a347a&source=-----106bd9ded180----0-----------------bookmark_preview----4cadf492_c11a_498c_bf25_52677407961d-------)

[![Image 34: AI Rabbit](https://miro.medium.com/v2/resize:fill:20:20/1*1cIrPiG5AyUHt-rt6gh_Vw.jpeg)](https://medium.com/@airabbitX?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[AI Rabbit](https://medium.com/@airabbitX?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[CodeX](https://medium.com/codex?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[1.4K 22](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc1ada7a8d91&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fhas-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91&source=-----106bd9ded180----1-----------------bookmark_preview----4cadf492_c11a_498c_bf25_52677407961d-------)

[![Image 36: Don Lim](https://miro.medium.com/v2/resize:fill:20:20/1*SkAt7uMC11I7WgRXlBMiPA.jpeg)](https://medium.com/@don-lim?source=read_next_recirc-----106bd9ded180----2---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Don Lim](https://medium.com/@don-lim?source=read_next_recirc-----106bd9ded180----2---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[705 13](https://medium.com/@don-lim/gpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408?source=read_next_recirc-----106bd9ded180----2---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[![Image 38: Richardson Gunde](https://miro.medium.com/v2/resize:fill:20:20/1*tp2uj3tur89cbR2GW0SrDQ.png)](https://medium.com/@honeyricky1m3?source=read_next_recirc-----106bd9ded180----3---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Richardson Gunde](https://medium.com/@honeyricky1m3?source=read_next_recirc-----106bd9ded180----3---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[AI Advances](https://ai.gopubby.com/?source=read_next_recirc-----106bd9ded180----3---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[1K 13](https://ai.gopubby.com/the-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8?source=read_next_recirc-----106bd9ded180----3---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe57882dee7f8&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fthe-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8&source=-----106bd9ded180----3-----------------bookmark_preview----4cadf492_c11a_498c_bf25_52677407961d-------)

## Visual Content Analysis

### Image Analysis
Title: 5 Overrated Python Libraries (And What You Should Use Instead)

URL Source: https://medium.com/python-in-plain-english/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180

Published Time: 2024-11-03T05:32:54.717Z

Markdown Content:
5 Overrated Python Libraries (And What You Should Use Instead) | by Abdur Rahman | Nov, 2024 | Python in Plain English
===============
 

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

5 Overrated Python Libraries (And What You Should Use Instead)
==============================================================

Traditional Devs, Look Away — This One’s Not for You!
-----------------------------------------------------

[![Image 3: Python in Plain English](https://miro.medium.com/v2/resize:fill:48:48/1*VA3oGfprJgj5fRsTjXp6fA@2x.png)](https://python.plainenglish.io/?source=post_page---byline--106bd9ded180--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--byline--106bd9ded180---------------------post_header-----------)

[Python in Plain English](https://python.plainenglish.io/?source=post_page---byline--106bd9ded180--------------------------------)

Nov 3, 2024

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fpython-in-plain-english%2F106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=---header_actions--106bd9ded180---------------------clap_footer-----------)

1.5K

12

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=---header_actions--106bd9ded180---------------------post_audio_button-----------)

![Image 4](https://miro.medium.com/v2/resize:fit:1000/1*fX-RNRwwSujOY05gXdoAlQ.jpeg)

> **Not a member, yet? Read it free** [**_here_**](https://medium.com/@abdur-rahman/5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180?sk=ffa347734cb26468c24d29021c9dc5e9)

Python’s vast ecosystem of libraries can feel like an amusement park for developers. With so many flashy rides, err, libraries to choose from, it’s easy to get swept up in the hype. But some libraries get more attention than they deserve. Whether they’re overhyped by “hot takes” on social media or just suffer from outdated design, a few commonly recommended tools aren’t always the best options out there. So, let’s take a look at some of Python’s most overrated libraries — and I’ll share alternatives that might actually serve you better.

> **Note:** This doesn’t mean these libraries aren’t valuable — quite the opposite! But for specific tasks, there are lighter, faster options that can do the trick just as well, sometimes even better.

1\. **Requests (Yes, Really!)**
===============================

Look, there is nothing inherently wrong with `Requests`. It’s intuitive, it has a great API, and it’s practically the mascot of Python HTTP libraries. But it’s overkill for when you just need to make simple GET/POST requests, and it will lag in environments where you want asynchronous performance.

**Why It’s Overrated:**
-----------------------

[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180%3Fsource%3D-----106bd9ded180---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----106bd9ded180---------------------post_regwall-----------)

[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180%3Fsource%3D-----106bd9ded180---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----106bd9ded180---------------------post_regwall-----------)

[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180%3Fsource%3D-----106bd9ded180---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----106bd9ded180---------------------post_regwall-----------)

Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&source=-----106bd9ded180---------------------post_regwall-----------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fpython-in-plain-english%2F106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=---footer_actions--106bd9ded180---------------------clap_footer-----------)

1.5K

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fpython-in-plain-english%2F106bd9ded180&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=---footer_actions--106bd9ded180---------------------clap_footer-----------)

1.5K

12

[![Image 6: Python in Plain English](https://miro.medium.com/v2/resize:fill:64:64/1*VA3oGfprJgj5fRsTjXp6fA@2x.png)](https://python.plainenglish.io/?source=post_page---post_author_info--106bd9ded180--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--post_author_info--106bd9ded180---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F844f13e47e8e&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&newsletterV3=7d16279b0e18&newsletterV3Id=844f13e47e8e&user=Abdur+Rahman&userId=7d16279b0e18&source=---post_author_info--106bd9ded180---------------------subscribe_user-----------)

[Python in Plain English](https://python.plainenglish.io/?source=post_page---post_author_info--106bd9ded180--------------------------------)

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d16279b0e18&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&user=Abdur+Rahman&userId=7d16279b0e18&source=post_page-7d16279b0e18--post_author_info--106bd9ded180---------------------follow_profile-----------)

[](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F844f13e47e8e&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F5-overrated-python-libraries-and-what-you-should-use-instead-106bd9ded180&newsletterV3=7d16279b0e18&newsletterV3Id=844f13e47e8e&user=Abdur+Rahman&userId=7d16279b0e18&source=---post_author_info--106bd9ded180---------------------subscribe_user-----------)

More from Abdur Rahman and Python in Plain English
--------------------------------------------------

[![Image 8: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----0---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----0---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----106bd9ded180----0---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=author_recirc-----106bd9ded180----0---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[5.1K 23](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=author_recirc-----106bd9ded180----0---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----106bd9ded180----0-----------------bookmark_preview----9fb44720_ed66_42f8_bee7_211542341fa5-------)

![Image 9: Why PyMuPDF4LLM is the Best Tool for Extracting Data from PDFs (Even if You Didn’t Know You Needed…](https://miro.medium.com/v2/resize:fit:679/0*_h8XywGiTHmSkmmU)

[![Image 10: Anoop Maurya](https://miro.medium.com/v2/resize:fill:20:20/1*GpLTfdPuDfw-8acfG4GhZg.jpeg)](https://medium.com/@mauryaanoop3?source=author_recirc-----106bd9ded180----1---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Anoop Maurya](https://medium.com/@mauryaanoop3?source=author_recirc-----106bd9ded180----1---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Python in Plain English](https://python.plainenglish.io/?source=author_recirc-----106bd9ded180----1---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Why PyMuPDF4LLM is the Best Tool for Extracting Data from PDFs (Even if You Didn’t Know You Needed… --------------------------------------------------------------------------------------------------- ### Stuck behind a paywall? Read for Free!](https://medium.com/why-pymupdf4llm-is-the-best-tool-for-extracting-data-from-pdfs-even-if-you-didnt-know-you-needed-7bff75313691?source=author_recirc-----106bd9ded180----1---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[1.5K 15](https://medium.com/why-pymupdf4llm-is-the-best-tool-for-extracting-data-from-pdfs-even-if-you-didnt-know-you-needed-7bff75313691?source=author_recirc-----106bd9ded180----1---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7bff75313691&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2Fwhy-pymupdf4llm-is-the-best-tool-for-extracting-data-from-pdfs-even-if-you-didnt-know-you-needed-7bff75313691&source=-----106bd9ded180----1-----------------bookmark_preview----9fb44720_ed66_42f8_bee7_211542341fa5-------)

![Image 11: 10 AI-Powered Python Libraries to Boost Your Next Project](https://miro.medium.com/v2/resize:fit:679/1*isqWuyZYRx2-sbFIuLwUJg.jpeg)

[![Image 12: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----2---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----2---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Python in Plain English](https://python.plainenglish.io/?source=author_recirc-----106bd9ded180----2---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[10 AI-Powered Python Libraries to Boost Your Next Project --------------------------------------------------------- ### From “Eh, pretty cool” to “Wow, how’d you do that?!”](https://medium.com/10-ai-powered-python-libraries-to-boost-your-next-project-ac74d614e3b8?source=author_recirc-----106bd9ded180----2---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[1K 3](https://medium.com/10-ai-powered-python-libraries-to-boost-your-next-project-ac74d614e3b8?source=author_recirc-----106bd9ded180----2---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac74d614e3b8&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2F10-ai-powered-python-libraries-to-boost-your-next-project-ac74d614e3b8&source=-----106bd9ded180----2-----------------bookmark_preview----9fb44720_ed66_42f8_bee7_211542341fa5-------)

[![Image 14: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----3---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=author_recirc-----106bd9ded180----3---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[Stackademic](https://blog.stackademic.com/?source=author_recirc-----106bd9ded180----3---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[20 Python Scripts To Automate Your Daily Tasks ---------------------------------------------- ### A must-have collection for every developer](https://blog.stackademic.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=author_recirc-----106bd9ded180----3---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[2.7K 25](https://blog.stackademic.com/20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63?source=author_recirc-----106bd9ded180----3---------------------9fb44720_ed66_42f8_bee7_211542341fa5-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c6f4b15fe63&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2F20-python-scripts-that-will-give-you-superpowers-4c6f4b15fe63&source=-----106bd9ded180----3-----------------bookmark_preview----9fb44720_ed66_42f8_bee7_211542341fa5-------)

[See all from Python in Plain English](https://python.plainenglish.io/?source=post_page-----106bd9ded180--------------------------------)

[![Image 16: Liu Zuo Lin](https://miro.medium.com/v2/resize:fill:20:20/1*Z5dMY4-vS6G69lMMdn3xIQ.jpeg)](https://zlliu.medium.com/?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Liu Zuo Lin](https://zlliu.medium.com/?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Level Up Coding](https://levelup.gitconnected.com/?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[2.2K 21](https://levelup.gitconnected.com/12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fad32d8ae630d&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2F12-production-grade-python-code-styles-ive-picked-up-from-work-ad32d8ae630d&source=-----106bd9ded180----0-----------------bookmark_preview----4cadf492_c11a_498c_bf25_52677407961d-------)

[![Image 18: Abdur Rahman](https://miro.medium.com/v2/resize:fill:20:20/1*dl3HiS_DMv2laLpaKyTBFg.jpeg)](https://medium.com/@abdur-rahman?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Abdur Rahman](https://medium.com/@abdur-rahman?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Stackademic](https://blog.stackademic.com/?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Python is No More The King of Data Science ------------------------------------------ ### 5 Reasons Why Python is Losing Its Crown](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[5.1K 23](https://blog.stackademic.com/is-python-still-the-king-of-data-science-476f1e3191b3?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F476f1e3191b3&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fis-python-still-the-king-of-data-science-476f1e3191b3&source=-----106bd9ded180----1-----------------bookmark_preview----4cadf492_c11a_498c_bf25_52677407961d-------)

[![Image 32: Harendra](https://miro.medium.com/v2/resize:fill:20:20/1*uTEzlRvlNBr3ralJoTQkmg.jpeg)](https://medium.com/@harendra21?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Harendra](https://medium.com/@harendra21?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[4.1K 50](https://medium.com/@harendra21/how-i-am-using-a-lifetime-100-free-server-bd241e3a347a?source=read_next_recirc-----106bd9ded180----0---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd241e3a347a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40harendra21%2Fhow-i-am-using-a-lifetime-100-free-server-bd241e3a347a&source=-----106bd9ded180----0-----------------bookmark_preview----4cadf492_c11a_498c_bf25_52677407961d-------)

[![Image 34: AI Rabbit](https://miro.medium.com/v2/resize:fill:20:20/1*1cIrPiG5AyUHt-rt6gh_Vw.jpeg)](https://medium.com/@airabbitX?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[AI Rabbit](https://medium.com/@airabbitX?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[CodeX](https://medium.com/codex?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[1.4K 22](https://medium.com/codex/has-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91?source=read_next_recirc-----106bd9ded180----1---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc1ada7a8d91&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fhas-anthropic-claude-just-wiped-out-an-entire-industry-fc1ada7a8d91&source=-----106bd9ded180----1-----------------bookmark_preview----4cadf492_c11a_498c_bf25_52677407961d-------)

[![Image 36: Don Lim](https://miro.medium.com/v2/resize:fill:20:20/1*SkAt7uMC11I7WgRXlBMiPA.jpeg)](https://medium.com/@don-lim?source=read_next_recirc-----106bd9ded180----2---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Don Lim](https://medium.com/@don-lim?source=read_next_recirc-----106bd9ded180----2---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[705 13](https://medium.com/@don-lim/gpt-5-is-finally-here-what-to-expect-and-what-not-to-expect-9f90e5362408?source=read_next_recirc-----106bd9ded180----2---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[![Image 38: Richardson Gunde](https://miro.medium.com/v2/resize:fill:20:20/1*tp2uj3tur89cbR2GW0SrDQ.png)](https://medium.com/@honeyricky1m3?source=read_next_recirc-----106bd9ded180----3---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[Richardson Gunde](https://medium.com/@honeyricky1m3?source=read_next_recirc-----106bd9ded180----3---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[AI Advances](https://ai.gopubby.com/?source=read_next_recirc-----106bd9ded180----3---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[1K 13](https://ai.gopubby.com/the-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8?source=read_next_recirc-----106bd9ded180----3---------------------4cadf492_c11a_498c_bf25_52677407961d-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe57882dee7f8&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fthe-pdf-extraction-revolution-why-pymupdf4llm-is-your-new-best-friend-and-llamaparse-is-crying-e57882dee7f8&source=-----106bd9ded180----3-----------------bookmark_preview----4cadf492_c11a_498c_bf25_52677407961d-------)


---

